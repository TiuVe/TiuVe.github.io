<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="努力成为一名实力很强的小白"><title>《Parameter-Efficient Transfer from Sequential Behaviors for User Modeling and Recommendation》论文阅读 | TiuVe</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=2.0.1"><link rel="stylesheet" type="text/css" href="/css/highlight.css?v=2.0.1"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="stylesheet" type="text/css" href="/css/donate.css"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">《Parameter-Efficient Transfer from Sequential Behaviors for User Modeling and Recommendation》论文阅读</h1><a id="logo" href="/.">TiuVe</a><p class="description">气蒸云梦泽，波撼岳阳城</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/./archives/"><i class="fa fa-archive"> 归档</i></a><a href="/./about/about.html"><i class="fa fa-user"> 关于</i></a><a href="/./project/project.html"><i class="fa fa-archive"> work</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="搜索"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">《Parameter-Efficient Transfer from Sequential Behaviors for User Modeling and Recommendation》论文阅读</h1><div class="post-meta"><a href="/2022/08/10/《Parameter-Efficient-Transfer-from-Sequential-Behaviors-for-User-Modeling-and-Recommendation》论文阅读/#comments" class="comment-count"></a><p><span class="date">Aug 10, 2022</span><span><a href="/categories/深度学习/" class="category">深度学习</a></span></p></div><div class="post-content"><img src="/images/2022/peterRec.png">

<p>归纳迁移学习对计算机视觉和 NLP 领域产生了重大影响，但尚未用于推荐系统领域。虽然已经有大量基于建模user-item交互序列做推荐任务的研究，但很少有人尝试表征和迁移这些模型到仅存在有限数据的下游任务。本文深入研究了如何有效地学习单个用户表征，并将该表征应用于各种任务，从跨域推荐到用户属性预测。微调大型预训练网络并使其适应下游任务是解决此类任务的有效方法。但是考虑到每个新任务都需要重新训练整个模型，微调的参数效率很低。为了克服这个问题，论文提出了一种参数有效的迁移学习架构，称为 PeterRec，它可以动态配置到各种下游任务。具体来说，PeterRec 通过注入一系列重新学习的神经网络，允许预训练的参数在微调期间保持不变，这些神经网络虽小但与学习整个网络一样具有表现力。论文通过一系列消融实验展示了用户表征在五个下游任务中的有效性。此外，作者证明了 PeterRec在多个领域迁移学习的有效性，与微调整个模型参数相比，PeterRec实现了相当或更好的性能。代码和数据集可在 <a href="https://github.com/fajieyuan/sigir2020_peterrec" target="_blank" rel="noopener">https://github.com/fajieyuan/sigir2020_peterrec</a> 获得。</p>
<a id="more"></a>

<h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a>1 介绍</h2><p>在过去10年的工作中，社交平台产生了各种各样丰富的item序列，然而大部分工作集中在同平台&#x2F;领域的序列推荐任务，很少有工作利用这些数据学习用户的通用表征，用于其它下游任务，例如不同推荐平台的用户冷启动和用户属性预测等。</p>
<p>作者希望通过学习用户的通用表征用于下游各种任务。具体地，作者尝试使用神经网络，从具有丰富user-item交互序列的源域出发，以无监督（自监督）的方式进行预训练得到用户的embedding，用于目标域的各种任务（目标域的用户是新&#x2F;冷的）。为此需要解决以下问题：</p>
<ul>
<li>构造一个高效通用的预训练模型，可以在无监督情况下建模非常长的user-item交互序列；</li>
<li>开发一个微调架构，可以将预训练的用户表征用于下游任务；</li>
<li>引入一种自适应方法，使得微调架构在所有下游任务中共享大部分参数。目的是在昂贵的计算代价和效果之间做折中。</li>
</ul>
<p>为了解决第三个问题，两种迁移技术被广泛使用：</p>
<ol>
<li>微调额外的输出层将知识从源于迁移到目标域；</li>
<li>微调最后一个或几个隐藏层和输出层</li>
</ol>
<p>事实上，仅对输出层进行微调通常在推荐场景中效果不佳，适当微调最后几层有时效果会更好，但是这需要大量手动工作，因为要调整的层数取决于预训练和模型和目标任务。在实践中，层数的选择往往依赖于低效的超参数搜索，另外这也并没有实现共享预训练模型大多数参数的目标。</p>
<p>为了实现前两个目标，作者提出了两阶段的训练过程。</p>
<ul>
<li>基于顺序神经网络nextItnet对用户的点击序列做序列推荐任务（next item）；</li>
<li>使用监督目标让预训练模型适应下游任务。</li>
</ul>
<p>为了实现第三个目标，即实现微调模型在不同域之间的高度参数共享，作者借鉴了learn-to-learn方法（参考文献【Learning feed-forward one-shot learners】），learn-to-learn的思想是神经网络的参数可以从另一个神经网络预测得到。此外，【Predicting parameters in deep learning】证明了给定神经网络一个层中5%的参数，剩下95%的参数可以预测得到。作者将这个思路用到了推荐系统的迁移学习任务。具体地，作者提出了一个嫁接神经网络（也被叫做模型补丁），使预训练模型中每个卷积层的参数适应目标任务。每个模型补丁由原始卷积层不到10%的参数组成。通过将这些模型补丁插入到预训练模型中，微调网络不需要改变预训练参数，就可以成功应用到下游任务而不降低性能。作者将提出的模型命名为PeterRec。</p>
<p>本文的主要贡献如下：</p>
<ul>
<li>提出了一种通用的用户表征架构，自称是第一个将得到的用户表征用于用户基础信息的预测（性别年龄等）；</li>
<li>提出了一个简单但有效的嫁接网络，允许微调网络不改变预训练参数就可以应用于下游任务；</li>
<li>提出了两种将模型补丁嵌入到预训练模型中的方法：串行插入和并行插入。</li>
<li>微调时对五中不同任务做了广泛的消融分析；</li>
<li>发布了用于迁移学习的高质量数据集。这是第一个用于迁移和多领域学习的大规模推荐数据集。</li>
</ul>
<h2 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2 相关工作"></a>2 相关工作</h2><h3 id="2-1-序列推荐模型"><a href="#2-1-序列推荐模型" class="headerlink" title="2.1 序列推荐模型"></a>2.1 序列推荐模型</h3><p>序列推荐（SR）模型是将用户对物品的交互序列作为输入，预测用户喜欢的下一个物品。在对用户的序列动作建模时，相比于传统的基于内容的推荐方法，SR被证明有明显的准确率提升；SR的另一个优点是不需要用户的基础信息。对于SR问题，研究人员主要关注三个方面的工作：</p>
<ul>
<li>基于RNN的建模。训练过程中严重依赖于顺序，无法充分利用并行计算架构GPU，而基于CNN和基于attention的推荐方法在训练过程中可以观察到整个序列，所以不存在这个问题。</li>
<li>基于CNN的建模。kernel较小导致感受野有限，无法成为强序列模型。膨胀卷积解决了这个问题，可以在kernel大小不变的情况下指数级增加感受野大小。</li>
<li>基于attention机制的建模。可能存在时间复杂度和内存问题，其随序列长度呈现二次方增长。</li>
</ul>
<p>综上，作者选择了基于CNN（膨胀卷积）的方式建模。具体地，选择了因果卷积（nextItNet）和非因果卷积（GRec的双向编码器）构建预训练模型。</p>
<h3 id="2-2-迁移学习和域适应"><a href="#2-2-迁移学习和域适应" class="headerlink" title="2.2 迁移学习和域适应"></a>2.2 迁移学习和域适应</h3><p>迁移学习（TL）是从源域中获取知识，去解决不同但相关的目标域问题，而目标域中只有少量的标记数据（监督信号）。和早期专注于浅层分类器的工作不同（例如矩阵分解），现在的TL研究转向DNN作为分类器，这产生了更好的准确率。然而也带来了一些挑战：</p>
<ul>
<li>如何在有限的资源下进行高效的迁移学习；</li>
<li>在目标域的监督信号稀疏情况下，如何避免过拟合问题。</li>
</ul>
<p>上述研究尚未进行有效探索，甚至不确定是否可以仅通过用户的行为来学习到有效的用户表征，以及是否可以迁移这些表征以改进下游任务。最近的一个相关工作是代表深度用户感知网络的 DUPN 模型。 DUPN 通过多任务学习用户的通用表征，这造成一个局限，就是需要依靠许多附加特征进行预训练；另外对于迁移学习问题，DUPN只考虑了微调所有预训练参数和最终分类层，成本较高。相比之下，PeterRec 通过单loss进行预训练用于下游多个任务，且PeterRec只微调了一小部分注入参数，但与微调所有参数相比，获得了相当或更好的结果。。为此，我们将本文中的任务定义为多域学习问题，这与 DUPN 中的多任务学习不同。CoNet [16] 是另一个使用神经网络作为基础模型的跨域推荐模型。为了实现知识迁移，CoNet联合训练了两个目标函数，其中一个代表源网络，另一个代表目标网络。 CoNet 的作者得出的一个有趣结论是，根据经验观察，他们论文中的预训练和微调范式效果不佳。事实上，CoNet 和 DUPN 都没有提供证据表明使用预训练网络进行微调比从头开始微调效果更好，这无疑是推荐系统中 TL 的基本假设。本文证明了PeterRec相对于从头开始训练并对预训练模型微调的方式，显着提高了下游推荐任务的准确性。</p>
<h2 id="3-PeterRec"><a href="#3-PeterRec" class="headerlink" title="3 PeterRec"></a>3 PeterRec</h2><h3 id="3-1-定义"><a href="#3-1-定义" class="headerlink" title="3.1 定义"></a>3.1 定义</h3><ul>
<li><p>源域：$S$，由用户id和用户交互的序列$x^u&#x3D;\lbrace x^u_1,…,x^u_n \rbrace$组成；</p>
</li>
<li><p>目标域：$T$，由用户id和监督标签y组成。</p>
<p>下面介绍下peterRec的模型设计。如下图所示，左边是预训练模型，右边是微调模型。在预训练模型中，$\tilde{\Theta}$包括embedding和卷积层的参数，$H(\tilde{\Theta})$是预训练网络，$w(\hat{\Theta})$是是预训练网络的分类层。$\tilde{H}(\tilde{\Theta}; \vartheta)$是微调网络，微调网络中的$\tilde{\Theta}$指的是预训练好的embedding和卷积层的参数，$\vartheta$是模型补丁。$H(\tilde{\Theta})$和$\tilde{H}(\tilde{\Theta}; \vartheta)$共享相同的预训练网络参数，但模型补丁的参数不共享。[TCL]是一个特殊的token作为分类标记，具体可以参考下文介绍的nextItNet网络结构。</p>
</li>
</ul>
<img src="/images/2022/peterRec.png">

<h3 id="3-2-预训练的用户表征"><a href="#3-2-预训练的用户表征" class="headerlink" title="3.2 预训练的用户表征"></a>3.2 预训练的用户表征</h3><p><strong>1 预训练目标</strong></p>
<p>和NextItNet类似，peterRec的预训练目标是根据用户的交互序列预测下一个用户感兴趣的item。其概率表示如下：</p>
<img src="/images/2022/next_item_prob.png" width="60%" height="60%">

<p>$\Theta$是预训练模型参数，包括预训练网络参数和分类层参数。如公式所示，相比于DUPN简单将用户交互序列当做特征，这种方式更能充分建模用户的交互序列。论文提到，PeterRec是推荐系统领域的第一个基于无监督自回归的迁移学习模型。</p>
<p>另外，有研究表明，用户的交互序列在表达用户兴趣偏好时并不需要是严格有序的，例如用户点击序列a,b,c和c,a,b其实表达的信息量是等同的。为了缓解严格有序的问题，作者随机mask掉的一些item。</p>
<img src="/images/2022/mask_loss.png" width="60%" height="60%">

<p>论文没有提出一种新的预训练目标函数，而是介绍了用户表征领域的一些预训练目标函数。</p>
<p><strong>2 预训练网络架构</strong></p>
<p>预训练网络架构是由空洞卷积（DC）层堆叠而成的。每两个DC层由残差模块组成，而每个DC层后面有一个LN层和非线性激活层ReLU（如图3a所示）。</p>
<img src="/images/2022/fig3_model_patch.png" width="100%" height="100%">

<p>另外，预训练网络通过因果CNN和非因果CNN两种方式被构建，公式如下：</p>
<img src="/images/2022/causal_cnn.png" width="60%" height="60%">

<p>下面是预训练方式。</p>
<img src="/images/2022/fig2_fine_tuning_arch.png" width="100%" height="100%">

<h3 id="3-3-用户表征迁移"><a href="#3-3-用户表征迁移" class="headerlink" title="3.3 用户表征迁移"></a>3.3 用户表征迁移</h3><p>PeterRec迁移架构包括三部分：</p>
<ul>
<li>预训练模型（分类层除外）</li>
<li>作用于下游任务的分类层</li>
<li>模型补丁</li>
</ul>
<p><strong>1 微调架构</strong></p>
<p>首先介绍下预训练模型的架构。以因果CNN为例（图2a）。对于每个样本(X，Y)，增加一个[TCL]标识到序列X的末尾，即$x^u&#x3D;\lbrace x_1^u,..,x_n^u,[TCL] \rbrace$，然后对$x^u$做一系列卷积操作，得到token对应的embedding矩阵，然后在[TCL]对应的embedding  $h_n$后面增加一个分类层，得到各个label的score。</p>
<p>非因果CNN也类似，区别在于非因果CNN是在$x^u$的首尾都增加了[TCL]标识。</p>
<img src="/images/2022/peterrec_causal_cnn_arch.png" width="75%" height="75%">

<p>另外值得一提的是，论文对不同的下游任务使用了不同的loss。对于topN推荐任务使用了BPR损失，对于用户属性预测任务使用了交叉熵损失。</p>
<img src="/images/2022/peter_loss.png" width="75%" height="75%">

<p><strong>2 模型补丁</strong></p>
<p>模型补丁其实也是一个神经网络，其目的是使预训练的DC残差块适应下游任务。最近一个learn-to-learn的研究表明，可以根据模型5%的参数预测剩下95%的参数。作者希望不微调所有参数，二是通过微调部分参数在下游任务中实现更好的性能。模型补丁的结构如图3f所示，由两个卷积层（kernel 1×1，维度k，通道d），一个Relu激活层和一个残差结构组成。这里使用其它的模型补丁也是可以的。</p>
<p><strong>3 插入方法</strong></p>
<p>作者介绍了两种插入方法，串行和并行，如图3bcde所示。</p>
<ul>
<li>对于串行插入，插入位置非常灵活，因此可以在层标准化之前或之后注入嫁接补丁，如（b）和（c）所示。</li>
<li>对于串行插入，每个 DC 残差块的补丁数量非常灵活，可以注入一个或两个补丁。 如果 (c) 中的 k 是 (b) 中的 k 的两倍，它会给出几乎相同的结果。</li>
<li>对于平行插入，PeterRec 对插入位置很敏感，如 (d) 和 (e) 所示。 具体来说，在层归一化之前注入的模型补丁（即（d））比层归一化和激活函数之间的模型补丁表现更好，后者的性能大大优于激活函数之后的模型补丁（即（e））。</li>
<li>对于并行插入，在 DC 块中插入两个补丁的 PeterRec 通常比只插入一个补丁的效果略好</li>
</ul>
<p>最终需要微调的参数减少到1.7%。</p>
<h2 id="4-实验"><a href="#4-实验" class="headerlink" title="4 实验"></a>4 实验</h2><p>实验环节，作者重点论述了四个问题：</p>
<ul>
<li>自监督学习用户表示真的对下游任务有帮助吗？ 作为推荐系统领域迁移学习的基础研究问题，这在以前从未得到验证。</li>
<li>与微调最后一层和整个模型相比，PeterRec 提出的模型补丁的效果如何？</li>
<li>PeterRec 可以估计哪些用户属性？ 当用户在目标域中是冷的或新用户时，PeterRec 是否能正常工作。</li>
<li>是否能通过 PeterRec 的消融分析得出其它有趣的结论？</li>
</ul>
<p>以上问题的回答可以看下论文。</p>
<h3 id="4-1-数据集"><a href="#4-1-数据集" class="headerlink" title="4.1 数据集"></a>4.1 数据集</h3><p>数据集来自腾讯业务，源域数据是QQ浏览器的新闻推荐数据，目标域数据是QQ看点的新闻交互数据。源域数据比较丰富，人均50个标签；目标域数据比较稀疏，大概人均5个标签。</p>
<h3 id="4-2-评估"><a href="#4-2-评估" class="headerlink" title="4.2 评估"></a>4.2 评估</h3><p>为了评估 PeterRec 在下游任务中的性能，作者将目标数据集随机分为训练集（70%）、验证集（3%）和测试集（27%），使用两个流行的 top-5 指标（MRR@5和 HR@5），用于冷启动推荐数据集（即 ColdRecs）；准确率指标用于其它三个数据集。</p>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>


<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
</div><div class="tags"><a href="/tags/universal-embedding/">universal embedding</a><a href="/tags/迁移学习/">迁移学习</a></div><script type="text/javascript" src="/js/jquery.js?v=2.0.1" async></script><div class="post-donate"><div id="donate_board" class="donate_bar center"><a id="btn_donate" href="javascript:;" title="打赏" class="btn_donate"></a><div class="donate_txt"> &uarr;<br>谢谢~ 您的支持将鼓励我继续创作！<br></div></div><div id="donate_guide" class="donate_bar center hidden pay"><img src="/img/weChatMoney.png" title="微信打赏" alt="微信打赏"><img src="/img/alipayMoney.png" title="支付宝打赏" alt="支付宝打赏"></div><script type="text/javascript">document.getElementById('btn_donate').onclick = function(){
    $('#donate_board').addClass('hidden');
    $('#donate_guide').removeClass('hidden');
}</script></div><div class="post-share"><div class="bdsharebuttonbox"><span style="float:left;line-height: 28px;height: 28px;font-size:16px;font-weight:blod">分享到：</span><a href="#" data-cmd="more" class="bds_more"></a><a href="#" data-cmd="mshare" title="分享到一键分享" class="bds_mshare"></a><a href="#" data-cmd="fbook" title="分享到Facebook" class="bds_fbook"></a><a href="#" data-cmd="twi" title="分享到Twitter" class="bds_twi"></a><a href="#" data-cmd="linkedin" title="分享到linkedin" class="bds_linkedin"></a><a href="#" data-cmd="youdao" title="分享到有道云笔记" class="bds_youdao"></a><a href="#" data-cmd="evernotecn" title="分享到印象笔记" class="bds_evernotecn"></a><a href="#" data-cmd="weixin" title="分享到微信" class="bds_weixin"></a><a href="#" data-cmd="qzone" title="分享到QQ空间" class="bds_qzone"></a><a href="#" data-cmd="tsina" title="分享到新浪微博" class="bds_tsina"></a></div></div><div class="post-nav"><a href="/2022/09/07/《KDD2018-Perceive-Your-Users-in-Depth-Learning-Universal-User-Representations-from-Multiple-E-commerce-Tasks》阅读笔记/" class="pre">《KDD2018 Perceive Your Users in Depth Learning Universal User Representations from Multiple E-commerce Tasks》阅读笔记</a><a href="/2022/07/03/《Towards-Universal-Sequence-Representation-Learning-for-Recommender-Systems》论文阅读笔记/" class="next">《Towards Universal Sequence Representation Learning for Recommender Systems》论文阅读笔记</a></div><div id="comments"><div id="lv-container" data-id="city" data-uid="MTAyMC80MTIyOC8xNzc3Ng=="></div></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">文章目录</i></div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-介绍"><span class="toc-text">1 介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-相关工作"><span class="toc-text">2 相关工作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-序列推荐模型"><span class="toc-text">2.1 序列推荐模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-迁移学习和域适应"><span class="toc-text">2.2 迁移学习和域适应</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-PeterRec"><span class="toc-text">3 PeterRec</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-定义"><span class="toc-text">3.1 定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-预训练的用户表征"><span class="toc-text">3.2 预训练的用户表征</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-用户表征迁移"><span class="toc-text">3.3 用户表征迁移</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-实验"><span class="toc-text">4 实验</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-数据集"><span class="toc-text">4.1 数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-评估"><span class="toc-text">4.2 评估</span></a></li></ol></li></ol></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2023/03/29/《Contrastive-Learning-for-Cold-Start-Recommendation》阅读笔记/">《ACM MM2021 Contrastive Learning for Cold-Start Recommendation》阅读笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/09/07/《KDD2018-Perceive-Your-Users-in-Depth-Learning-Universal-User-Representations-from-Multiple-E-commerce-Tasks》阅读笔记/">《KDD2018 Perceive Your Users in Depth Learning Universal User Representations from Multiple E-commerce Tasks》阅读笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/08/10/《Parameter-Efficient-Transfer-from-Sequential-Behaviors-for-User-Modeling-and-Recommendation》论文阅读/">《Parameter-Efficient Transfer from Sequential Behaviors for User Modeling and Recommendation》论文阅读</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/07/03/《Towards-Universal-Sequence-Representation-Learning-for-Recommender-Systems》论文阅读笔记/">《Towards Universal Sequence Representation Learning for Recommender Systems》论文阅读笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/01/07/NLP相关资料整理/">NLP相关资料整理</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/01/05/hexo博客链接在微信被屏蔽的解决办法/">hexo博客链接在微信被屏蔽的解决办法</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/01/05/TensorFlow的自动求导具体是在哪部分代码里实现的？/">TensorFlow的自动求导具体是在哪部分代码里实现的？</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/01/05/tf中如何修改tensor的值/">tf中如何修改tensor的值</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/01/04/解决tf1-15中tf-scatter-update-函数没有定义梯度的问题/">解决tf1.15中tf.scatter_update()函数没有定义梯度的问题</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/12/31/解决hexo博客代码在IOS下字体过大的问题/">解决hexo博客代码在IOS下字体过大的问题</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-gui"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Algorithm/">Algorithm</a><span class="category-list-count">22</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/DMMLAI/">DMMLAI</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo主题/">Hexo主题</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hive/">Hive</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/PL/">PL</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Story/">Story</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/hole/">hole</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/linux/">linux</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/mac/">mac</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/pytorch/">pytorch</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/sklearn/">sklearn</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/tensorflow/">tensorflow</a><span class="category-list-count">10</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/例行化/">例行化</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/大数据/">大数据</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/开发/">开发</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/开发工具/">开发工具</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/推荐/">推荐</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/摄影/">摄影</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据获取/">数据获取</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/深度学习/">深度学习</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/游记/">游记</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/爬虫/">爬虫</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/统计学/">统计学</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/计划/">计划</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/计算广告/">计算广告</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/高并发/">高并发</a><span class="category-list-count">1</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> 标签</i></div><div class="tagcloud"><a href="/tags/思考/" style="font-size: 15px;">思考</a> <a href="/tags/cold/" style="font-size: 15px;">cold</a> <a href="/tags/gwen/" style="font-size: 15px;">gwen</a> <a href="/tags/C-C/" style="font-size: 15px;">C/C++</a> <a href="/tags/FTRL/" style="font-size: 15px;">FTRL</a> <a href="/tags/hive/" style="font-size: 15px;">hive</a> <a href="/tags/Java编程思想/" style="font-size: 15px;">Java编程思想</a> <a href="/tags/kmp/" style="font-size: 15px;">kmp</a> <a href="/tags/字符串匹配/" style="font-size: 15px;">字符串匹配</a> <a href="/tags/L2范数，范数/" style="font-size: 15px;">L2范数，范数</a> <a href="/tags/linux性能管理/" style="font-size: 15px;">linux性能管理</a> <a href="/tags/NLP/" style="font-size: 15px;">NLP</a> <a href="/tags/tensorflow/" style="font-size: 15px;">tensorflow</a> <a href="/tags/自动求导，自动微分/" style="font-size: 15px;">自动求导，自动微分</a> <a href="/tags/sublime/" style="font-size: 15px;">sublime</a> <a href="/tags/TFRecord/" style="font-size: 15px;">TFRecord</a> <a href="/tags/FM/" style="font-size: 15px;">FM</a> <a href="/tags/指标/" style="font-size: 15px;">指标</a> <a href="/tags/auc/" style="font-size: 15px;">auc</a> <a href="/tags/zookepper/" style="font-size: 15px;">zookepper</a> <a href="/tags/centos7/" style="font-size: 15px;">centos7</a> <a href="/tags/cpm/" style="font-size: 15px;">cpm</a> <a href="/tags/opcm/" style="font-size: 15px;">opcm</a> <a href="/tags/ecpm/" style="font-size: 15px;">ecpm</a> <a href="/tags/hexo，微信屏蔽/" style="font-size: 15px;">hexo，微信屏蔽</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/tf/" style="font-size: 15px;">tf</a> <a href="/tags/正则表达式/" style="font-size: 15px;">正则表达式</a> <a href="/tags/leetcode/" style="font-size: 15px;">leetcode</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/重装系统/" style="font-size: 15px;">重装系统</a> <a href="/tags/maven/" style="font-size: 15px;">maven</a> <a href="/tags/OJ/" style="font-size: 15px;">OJ</a> <a href="/tags/dfs/" style="font-size: 15px;">dfs</a> <a href="/tags/递归/" style="font-size: 15px;">递归</a> <a href="/tags/poj/" style="font-size: 15px;">poj</a> <a href="/tags/回文字符串/" style="font-size: 15px;">回文字符串</a> <a href="/tags/dp/" style="font-size: 15px;">dp</a> <a href="/tags/暴力/" style="font-size: 15px;">暴力</a> <a href="/tags/棋盘规则/" style="font-size: 15px;">棋盘规则</a> <a href="/tags/状态压缩/" style="font-size: 15px;">状态压缩</a> <a href="/tags/BFS/" style="font-size: 15px;">BFS</a> <a href="/tags/位运算/" style="font-size: 15px;">位运算</a> <a href="/tags/pytorch/" style="font-size: 15px;">pytorch</a> <a href="/tags/module/" style="font-size: 15px;">module</a> <a href="/tags/爬虫/" style="font-size: 15px;">爬虫</a> <a href="/tags/shell/" style="font-size: 15px;">shell</a> <a href="/tags/质数/" style="font-size: 15px;">质数</a> <a href="/tags/素数/" style="font-size: 15px;">素数</a> <a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/sklearn/" style="font-size: 15px;">sklearn</a> <a href="/tags/hole/" style="font-size: 15px;">hole</a> <a href="/tags/spark/" style="font-size: 15px;">spark</a> <a href="/tags/打散/" style="font-size: 15px;">打散</a> <a href="/tags/roc-auc-score/" style="font-size: 15px;">roc_auc_score</a> <a href="/tags/svm多类别分类/" style="font-size: 15px;">svm多类别分类</a> <a href="/tags/网格搜索/" style="font-size: 15px;">网格搜索</a> <a href="/tags/textFile/" style="font-size: 15px;">textFile</a> <a href="/tags/源码剖析/" style="font-size: 15px;">源码剖析</a> <a href="/tags/rdd计算/" style="font-size: 15px;">rdd计算</a> <a href="/tags/smoothing/" style="font-size: 15px;">smoothing</a> <a href="/tags/tensorboard/" style="font-size: 15px;">tensorboard</a> <a href="/tags/test-in-ubuntu/" style="font-size: 15px;">test in ubuntu</a> <a href="/tags/tf-nn/" style="font-size: 15px;">tf.nn</a> <a href="/tags/tensor/" style="font-size: 15px;">tensor</a> <a href="/tags/gather/" style="font-size: 15px;">gather</a> <a href="/tags/cnn/" style="font-size: 15px;">cnn</a> <a href="/tags/transformer/" style="font-size: 15px;">transformer</a> <a href="/tags/nlp/" style="font-size: 15px;">nlp</a> <a href="/tags/trie/" style="font-size: 15px;">trie</a> <a href="/tags/推荐，对比学习，冷启动/" style="font-size: 15px;">推荐，对比学习，冷启动</a> <a href="/tags/word2vec/" style="font-size: 15px;">word2vec</a> <a href="/tags/torch/" style="font-size: 15px;">torch</a> <a href="/tags/torch-geometric/" style="font-size: 15px;">torch-geometric</a> <a href="/tags/多任务学习/" style="font-size: 15px;">多任务学习</a> <a href="/tags/图网络/" style="font-size: 15px;">图网络</a> <a href="/tags/矩阵补全/" style="font-size: 15px;">矩阵补全</a> <a href="/tags/推荐/" style="font-size: 15px;">推荐</a> <a href="/tags/NAS/" style="font-size: 15px;">NAS</a> <a href="/tags/网络修剪/" style="font-size: 15px;">网络修剪</a> <a href="/tags/知识迁移/" style="font-size: 15px;">知识迁移</a> <a href="/tags/神经架构搜索/" style="font-size: 15px;">神经架构搜索</a> <a href="/tags/async/" style="font-size: 15px;">async</a> <a href="/tags/异步/" style="font-size: 15px;">异步</a> <a href="/tags/多进程/" style="font-size: 15px;">多进程</a> <a href="/tags/流数据/" style="font-size: 15px;">流数据</a> <a href="/tags/概念漂移/" style="font-size: 15px;">概念漂移</a> <a href="/tags/二分搜索/" style="font-size: 15px;">二分搜索</a> <a href="/tags/univesal-embedding/" style="font-size: 15px;">univesal embedding</a> <a href="/tags/机器学习工具/" style="font-size: 15px;">机器学习工具</a> <a href="/tags/universal-embedding/" style="font-size: 15px;">universal embedding</a> <a href="/tags/迁移学习/" style="font-size: 15px;">迁移学习</a> <a href="/tags/逻辑/" style="font-size: 15px;">逻辑</a> <a href="/tags/github-blog/" style="font-size: 15px;">github blog</a> <a href="/tags/例行化/" style="font-size: 15px;">例行化</a> <a href="/tags/协同过滤/" style="font-size: 15px;">协同过滤</a> <a href="/tags/GCN/" style="font-size: 15px;">GCN</a> <a href="/tags/图卷积/" style="font-size: 15px;">图卷积</a> <a href="/tags/github/" style="font-size: 15px;">github</a> <a href="/tags/在线学习/" style="font-size: 15px;">在线学习</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> 归档</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/03/">三月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/09/">九月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/08/">八月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/07/">七月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/01/">一月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/12/">十二月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">十一月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/10/">十月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/09/">九月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/08/">八月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/02/">二月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/12/">十二月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/11/">十一月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/10/">十月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">九月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">七月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">六月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">四月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">三月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">二月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">十一月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">十月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">八月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">七月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">五月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">十二月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">十一月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">十月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">七月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">四月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">十一月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">八月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">四月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">十二月 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">十一月 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">十月 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/05/">五月 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/04/">四月 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/12/">十二月 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/11/">十一月 2014</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-you"> 友情链接</i></div><ul></ul><a href="https://petr-mitrichev.blogspot.com/" title="petr" target="_blank">petr</a><ul></ul><a href="http://blog.pluskid.org/" title="Free Mind" target="_blank">Free Mind</a><ul></ul><a href="http://www.flickering.cn/" title="火光摇曳" target="_blank">火光摇曳</a><ul></ul><a href="https://recsys.acm.org/" title="recsys" target="_blank">recsys</a><ul></ul><a href="https://sites.google.com/site/xreborner/" title="Xreborner" target="_blank">Xreborner</a><ul></ul><a href="http://blog.watashi.ws/" title="watashi" target="_blank">watashi</a><ul></ul><a href="https://toc.csail.mit.edu/user/306" title="WJMZBMR" target="_blank">WJMZBMR</a><ul></ul><a href="http://dongxicheng.org/" title="dongxicheng" target="_blank">dongxicheng</a><ul></ul><a href="https://www.byvoid.com/zht/" title="byvoid" target="_blank">byvoid</a></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p><a href="/baidusitemap.xml">Baidu Site Haritası</a> |  <a href="/atom.xml">订阅</a> |  <a href="/about/">关于</a></p><p><span> Copyright &copy;<a href="/." rel="nofollow">TiuVe.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/chaooo/hexo-theme-BlueLake"> BlueLake.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script type="text/javascript" src="/js/search.json.js?v=2.0.1"></script><!-- 页面点击小红心，在末尾添加，避免找不到 -->
<script type="text/javascript" src="/js/love.js"></script>
<!-- 背景彩带, true打开，false关闭 --><script type="text/javascript" src="/js/toctotop.js?v=2.0.1" async></script><script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":["mshare","weixin","tsina","qzone","linkedin","fbook","twi","print","renren","sqq","evernotecn","bdysc","tqq","tqf","bdxc","kaixin001","tieba","douban","bdhome","thx","ibaidu","meilishuo","mogujie","diandian","huaban","duitang","hx","fx","youdao","sdo","qingbiji","people","xinhua","mail","isohu","yaolan","wealink","ty","iguba","h163","copy"],"bdPic":"","bdStyle":"1","bdSize":"16"},"share":{},"image":{"viewList":["tsina","qzone","weixin","fbook","twi","linkedin","youdao","evernotecn","mshare"],"viewText":"分享到：","viewSize":"16"},"selectShare":{"bdContainerClass":null,"bdSelectMiniList":["tsina","qzone","weixin","fbook","twi","linkedin","youdao","evernotecn","mshare"]}};with(document)0[(getElementsByTagName('head')[0]||head).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
</script><script>(function(d, s) {
  var j, e = d.getElementsByTagName('body')[0];
  if (typeof LivereTower === 'function') { return; }
  j = d.createElement(s);
  j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
  j.async = true;
  e.appendChild(j);
})(document, 'script');
</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/Epsilon2.1.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>