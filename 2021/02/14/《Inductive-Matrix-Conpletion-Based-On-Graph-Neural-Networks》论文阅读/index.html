<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="努力成为一名实力很强的小白"><title>《Inductive Matrix Conpletion Based On Graph Neural Network》论文阅读 | TiuVe</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=2.0.1"><link rel="stylesheet" type="text/css" href="/css/highlight.css?v=2.0.1"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="stylesheet" type="text/css" href="/css/donate.css"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">《Inductive Matrix Conpletion Based On Graph Neural Network》论文阅读</h1><a id="logo" href="/.">TiuVe</a><p class="description">气蒸云梦泽，波撼岳阳城</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/./archives/"><i class="fa fa-archive"> 归档</i></a><a href="/./about/about.html"><i class="fa fa-user"> 关于</i></a><a href="/./project/project.html"><i class="fa fa-archive"> work</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="搜索"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">《Inductive Matrix Conpletion Based On Graph Neural Network》论文阅读</h1><div class="post-meta"><a href="/2021/02/14/《Inductive-Matrix-Conpletion-Based-On-Graph-Neural-Networks》论文阅读/#comments" class="comment-count"></a><p><span class="date">Feb 14, 2021</span><span><a href="/categories/机器学习/" class="category">机器学习</a></span></p></div><div class="post-content"><p><img src="/images/image-20210214183028688.png" alt="image-20210214183028688"></p>
<a id="more"></a>

<p>论文提出了一种不使用辅助信息的归纳(<em>inductive</em>)矩阵补全模型。通过将评分矩阵分解为行（用户）和列（物品）的低维隐向量的乘积，现有的大多数矩阵补全方法都是可转导(<em>transductive</em>)的，因为学习的向量无法泛化为看不见的行&#x2F;列或新矩阵。为了使矩阵补全具有归纳性，之前大多数的工作都使用内容（辅助信息）进行预测，例如用户的年龄或电影类型。但是，内容并不总是高质量的，并且可能难以提取。在极端的情况下，除了要补全的矩阵之外没有其他辅助信息可用，这时我们就无法学习归纳矩阵补全模型。本文提出了一种基于归纳图的矩阵补全（IGMC）模型来解决此问题。 IGMC基于一跳子图训练图神经网络（GNN），并将这些子图映射到其对应的评分，一跳子图基于评分矩阵生成的用户-物品pair对生成。IGMC相比于最新的<em>transductive</em>基线实现了更好的性能。此外，IGMC是归纳性的，它可以推广到训练时未看到的用户&#x2F;物品（假设二者存在相互作用），甚至可以推广到新任务上。我们的迁移学习实验表明，从MovieLens数据集中训练出的模型可以直接用于预测豆瓣电影收视率，并且性能出奇地好。我们的工作表明：1）可以在不使用辅助信息的情况下训练归纳矩阵补全模型，同时获得与最新的<em>transductive</em>方法相似或更好的性能； 2）用户-物品pair对周围的局部图模式是该用户对该物品评分的有效预测指标；和3）建模推荐系统时可能不需要长期依赖。</p>
<p>先说下inductive学习和transductive学习的区别 ：</p>
<ul>
<li><p><em>inductive</em>学习，指的是训练数据和测试数据互斥的学习。模型从训练数据学习规律，然后在测试数据预测，训练数据和测试数据互斥。这样训练得到的模型泛化能力更强。</p>
</li>
<li><p><em>transductive</em>学习，指的是训练数据和测试数据有重叠的学习。模型训练时会基于训练数据和测试数据的部分信息（不包括label信息）进行联合建模，然后在测试数据上预测label，例如在聚类学习中，分析X的分布然后预测Y，这点可以参考知乎用户<a href="https://www.zhihu.com/people/lin-a-bi-78" target="_blank" rel="noopener">望尼玛</a>的回答《<a href="https://www.zhihu.com/question/68275921/answer/1574682746" target="_blank" rel="noopener">如何理解 inductive learning 与 transductive learning?</a>》。</p>
</li>
</ul>
<h3 id="1-构造二部图"><a href="#1-构造二部图" class="headerlink" title="1 构造二部图"></a>1 构造二部图</h3><p>定义图G为无向二部图，其来源于评分矩阵R。在图G中，节点代表用户（u表示，代表评分矩阵中的一行）或者物品（v表示，代表评分矩阵中的一列），用户和物品之间存在边，但是用户之间和物品之间不能存在边。每条边的值r&#x3D;$R_{u,v}$代表该用户对该物品的评分，定义$R$代表评分值的集合，例如在MovieLenszhong ,R&#x3D;{1，2，3，4，5}。定义$N_{r(u)}$为节点u的以r类型的边连接的邻居。</p>
<h3 id="2-提取子图"><a href="#2-提取子图" class="headerlink" title="2 提取子图"></a>2 提取子图</h3><p>IGMC的第一部分是提取封闭子图。对于每个观测到的评分值$R_{u,v}$，从G中提取一个从u到v的h跳封闭子图，算法1描述了提取h跳封闭子图的BFS算法。然后把这些子图喂到GNN中，然后回归其评分。对于测试集中的每个(u-v) pair对，同样从G中提取h跳封闭子图，然后使用训练得到的GNN模型预测其评分。<strong>需要注意的是，在提取了(u,v)的训练封闭子图之后，需要将(u,v)的边移除，因为目标是预测。</strong></p>
<p><img src="/images/image-20210215120155735.png" alt="image-20210215120155735"></p>
<h3 id="3-节点学习"><a href="#3-节点学习" class="headerlink" title="3 节点学习"></a>3 节点学习</h3><p>IGMC第二部分是节点标记。因为封闭子图提取出来之后要喂给GNN，GNN无法区分不同的节点，所以需要对节点进行标记，1是要区分目标节点和上下文节点（目标节点指的是我们将要预测的用户对物品的评分）；2是要区分用户节点和物品节点。为此论文提出了一种节点标记方法：首先定义目标用户和目标物品的标签为0和1，对i跳的上下文用户标记为2i，对i跳的上下文物品标记为2i+1。然后将这些标记转化为one-hot向量，将其节点的初始特征输入GNN。这里同时也区分了不同阶的节点，因为不同阶的节点对目标节点的贡献程度不同。</p>
<p>需要注意的是，虽然我们已经证明了上述方法具有很好的性能，但它并不是唯一的节点标记方法。这些节点标签的one-hot编码将被用于子图节点特征的初始化，然后喂给GNN。节点标签完全依赖于封闭子图，和全局二部图无关。给定一个封闭子图，即使它的节点来自于不同的二部图，我们也可以预测其评分，因为IGMC完全依赖于局部封闭子图的图模式，而没有利用任何二部图的全局信息。节点标签也不同于在GC-MC中使用全局节点ID，Using one-hot encoding of global IDs is essentially transforming the first message passing layer’s parameters into latent node embedding associated with each particular ID (equivalent to an embedding lookup table). Such a model cannot generalize to nodes whose IDs are out of range, thus is transductive.</p>
<p><img src="/images/image-20210214183028688.png" alt="image-20210214183028688"></p>
<h3 id="4-图神经网络架构"><a href="#4-图神经网络架构" class="headerlink" title="4 图神经网络架构"></a>4 图神经网络架构</h3><p>IGMC的第三部分是训练图神经网络模型预测封闭子图的评分。在以前基于节点的方法中，例如GC-MC，一个节点级的GNN应用于整个二部图以提取节点向量。然后，节点u和v的向量被输入到内积或者双线性算子中（bilinear operator），以重建(u,v)评分。而IGMC是将图级别的GNN应用于(u, v)的封闭子图，并将子图映射到评分。因此，IGMC的GNN有两个组件：（1）消息传递层，为子图中的每个节点提取一个特征向量；（2）一个池化层，抽象这些节点特征的子图表达。</p>
<p>为了从不同的边类型中学习丰富的图模式，这里采用了R-GCN(relational graph convolutional operator)算子作为GNN的消息传递层，形式如下：</p>
<p><img src="/images/image-20210217133743944.png" alt="image-20210217133743944"></p>
<p>其中$X^l_i$表示节点i在$l$层的特征向量，$W_0^l$和 $W_r^l|r \in R$是可学习的参数矩阵。由于连接邻居j到节点i的边r是由不同的参数矩阵$W^l_r$，我们可以从边类型中学习丰富的图模式，例如目标用户对物品的平均评分，目标物品得到的平均分，两个目标节点通过哪条路径连接，等等。</p>
<p>这里我们简要介绍下RGCN。RGCN的目的是解决GCN忽略不同边关系对节点的影响的问题，其主要形式如下：</p>
<p><img src="/images/image-20210223101321182.png" alt="image-20210223101321182"></p>
<p>$N_i^r$表示节点i的关系为r的邻居节点集合，$c_{i,r}$是一个正则化常量， 其中$c_{i,r}$的取值是$|N_i^r|$。$W_r^{(l)}$是线性转化函数，将同类型边的邻居节点，使用用一个参数矩阵$W_r^{(l)}$进行转化。此公式和GCN不同的是，不同边类型所连接的邻居节点，进行一个线性转化，$W_r^{(l)}$的个数也就是边类型的个数，论文中称为relation-specific。这里还可以设置更加灵活的函数，例如多层神经网络[1]。</p>
<p>我们在两个层之间堆叠具有tanh激活的L个消息传递层。（follow Zhang等人，2018； Xu等人，2018的工作），来自不同层的节点i的特征向量被拼接起来作为其最终表达形式$h_i$：</p>
<p><img src="/images/image-20210217160326156.png" alt="image-20210217160326156"></p>
<p>接下来，我们对节点表达进行池化得到一个图级别的特征向量。池化方式有多种，例如求和，均值，SortPooling（Zhang et al., 2018），DiffPooling (Ying et al., 2018b)。在论文中使用了一个和上述不同的池化层，其拼接目标用户和物品的最终表达作为图表达。</p>
<p><img src="/images/image-20210217160751366.png" alt="image-20210217160751366"></p>
<p>$h_u$表示目标用户的最终表达，$h_v$是目标物品的最终表达。之所以要这么做（拼接目标用户和物品的最终表达作为图表达），是因为与其它上下文相比，这两个节点更重要，尽管这样做很简单，但是我们验证了在矩阵补全任务中，这种方式的性能明显优于其它池化层。</p>
<p>在得到最终的图表达之后，使用MLP输出预测评分：</p>
<p><img src="/images/image-20210217161514470.png" alt="image-20210217161514470"></p>
<p>W和w是MLP的参数，$\hat{r}$是标量评分，$\sigma$是激活函数，论文中使用了ReLU。</p>
<h3 id="5-模型训练"><a href="#5-模型训练" class="headerlink" title="5 模型训练"></a>5 模型训练</h3><p><strong>损失函数</strong>，最小化预测得分和真实得分的均方误差(MSE):</p>
<p><img src="/images/image-20210217162119480.png" alt="image-20210217162119480"></p>
<p>$R_{u,v}$表示真实得分，$\hat{R}_{u,v}$是预测得分。$\Omega$是0&#x2F;1掩码矩阵，表示评分矩阵R中的可观测条目。</p>
<p><strong>相邻评分正则化</strong>，GNN中使用的R-GCN层，（1）对于不同的评级类型具有不同的参数$W_r$。 一个缺点是它没有考虑到评分值的大小。 例如，MovieLens中的4级和5级都表示用户喜欢该电影，而1级则表明用户不喜欢该电影。 理想情况下，我们希望我们的模型意识到这样一个事实，即4评分比1更接近5。 但是，在R-GCN中，评分值1，4和5仅被视为三种独立的边缘类型，评分值的大小和顺序信息完全丢失。 为了解决这个问题，论文提出了一种相邻的评分正则化（ARR）技术，该技术使得相近的评分具有相似的参数矩阵。 假设R中的评分具有$r_1$，$r_2$，…$r|R|$的顺序， 这表明用户对商品的偏好越来越高。 然后，ARR正则化器为：</p>
<p><img src="/images/image-20210217162817899.png" alt="image-20210217162817899"></p>
<p>其中${\lVert \cdot \lVert}_F$表示矩阵的Frobenius范数。 上述正则化器可抑制相近评分参数矩阵之间的差异过大，这不仅考虑了评分顺序，而且还通过迁移相近评分的知识来帮助优化那些不经常使用的评分。 最终损失函数由下式给出：</p>
<p><img src="/images/image-20210217162855771.png" alt="image-20210217162855771"></p>
<p>$\lambda$权衡了MSE损失和ARR调整器的重要性。 还有很多方法可以对评分值的大小和顺序进行建模，这些方法留待以后的工作。</p>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] <a href="https://zhuanlan.zhihu.com/p/157902271" target="_blank" rel="noopener">[论文笔记] RGCN ：GCN 在多边类型的应用</a></p>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
</div><div class="tags"><a href="/tags/图网络/">图网络</a><a href="/tags/矩阵补全/">矩阵补全</a><a href="/tags/推荐/">推荐</a></div><script type="text/javascript" src="/js/jquery.js?v=2.0.1" async></script><div class="post-donate"><div id="donate_board" class="donate_bar center"><a id="btn_donate" href="javascript:;" title="打赏" class="btn_donate"></a><div class="donate_txt"> &uarr;<br>谢谢~ 您的支持将鼓励我继续创作！<br></div></div><div id="donate_guide" class="donate_bar center hidden pay"><img src="/img/weChatMoney.png" title="微信打赏" alt="微信打赏"><img src="/img/alipayMoney.png" title="支付宝打赏" alt="支付宝打赏"></div><script type="text/javascript">document.getElementById('btn_donate').onclick = function(){
    $('#donate_board').addClass('hidden');
    $('#donate_guide').removeClass('hidden');
}</script></div><div class="post-share"><div class="bdsharebuttonbox"><span style="float:left;line-height: 28px;height: 28px;font-size:16px;font-weight:blod">分享到：</span><a href="#" data-cmd="more" class="bds_more"></a><a href="#" data-cmd="mshare" title="分享到一键分享" class="bds_mshare"></a><a href="#" data-cmd="fbook" title="分享到Facebook" class="bds_fbook"></a><a href="#" data-cmd="twi" title="分享到Twitter" class="bds_twi"></a><a href="#" data-cmd="linkedin" title="分享到linkedin" class="bds_linkedin"></a><a href="#" data-cmd="youdao" title="分享到有道云笔记" class="bds_youdao"></a><a href="#" data-cmd="evernotecn" title="分享到印象笔记" class="bds_evernotecn"></a><a href="#" data-cmd="weixin" title="分享到微信" class="bds_weixin"></a><a href="#" data-cmd="qzone" title="分享到QQ空间" class="bds_qzone"></a><a href="#" data-cmd="tsina" title="分享到新浪微博" class="bds_tsina"></a></div></div><div class="post-nav"><a href="/2021/02/23/windows下如何安装torch-geometric/" class="pre">windows下如何安装torch-geometric</a><a href="/2021/02/11/协同过滤/" class="next">协同过滤</a></div><div id="comments"><div id="lv-container" data-id="city" data-uid="MTAyMC80MTIyOC8xNzc3Ng=="></div></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">文章目录</i></div><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-构造二部图"><span class="toc-text">1 构造二部图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-提取子图"><span class="toc-text">2 提取子图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-节点学习"><span class="toc-text">3 节点学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-图神经网络架构"><span class="toc-text">4 图神经网络架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-模型训练"><span class="toc-text">5 模型训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#参考文献"><span class="toc-text">参考文献</span></a></li></ol></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2023/03/29/《Contrastive-Learning-for-Cold-Start-Recommendation》阅读笔记/">《ACM MM2021 Contrastive Learning for Cold-Start Recommendation》阅读笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/09/07/《KDD2018-Perceive-Your-Users-in-Depth-Learning-Universal-User-Representations-from-Multiple-E-commerce-Tasks》阅读笔记/">《KDD2018 Perceive Your Users in Depth Learning Universal User Representations from Multiple E-commerce Tasks》阅读笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/08/10/《Parameter-Efficient-Transfer-from-Sequential-Behaviors-for-User-Modeling-and-Recommendation》论文阅读/">《Parameter-Efficient Transfer from Sequential Behaviors for User Modeling and Recommendation》论文阅读</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/07/03/《Towards-Universal-Sequence-Representation-Learning-for-Recommender-Systems》论文阅读笔记/">《Towards Universal Sequence Representation Learning for Recommender Systems》论文阅读笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/01/07/NLP相关资料整理/">NLP相关资料整理</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/01/05/hexo博客链接在微信被屏蔽的解决办法/">hexo博客链接在微信被屏蔽的解决办法</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/01/05/TensorFlow的自动求导具体是在哪部分代码里实现的？/">TensorFlow的自动求导具体是在哪部分代码里实现的？</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/01/05/tf中如何修改tensor的值/">tf中如何修改tensor的值</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/01/04/解决tf1-15中tf-scatter-update-函数没有定义梯度的问题/">解决tf1.15中tf.scatter_update()函数没有定义梯度的问题</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/12/31/解决hexo博客代码在IOS下字体过大的问题/">解决hexo博客代码在IOS下字体过大的问题</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-gui"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Algorithm/">Algorithm</a><span class="category-list-count">22</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/DMMLAI/">DMMLAI</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo主题/">Hexo主题</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hive/">Hive</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/PL/">PL</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Story/">Story</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/hole/">hole</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/linux/">linux</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/mac/">mac</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/pytorch/">pytorch</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/sklearn/">sklearn</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/tensorflow/">tensorflow</a><span class="category-list-count">10</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/例行化/">例行化</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/大数据/">大数据</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/开发/">开发</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/开发工具/">开发工具</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/推荐/">推荐</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/摄影/">摄影</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据获取/">数据获取</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/深度学习/">深度学习</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/游记/">游记</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/爬虫/">爬虫</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/统计学/">统计学</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/计划/">计划</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/计算广告/">计算广告</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/高并发/">高并发</a><span class="category-list-count">1</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> 标签</i></div><div class="tagcloud"><a href="/tags/思考/" style="font-size: 15px;">思考</a> <a href="/tags/cold/" style="font-size: 15px;">cold</a> <a href="/tags/gwen/" style="font-size: 15px;">gwen</a> <a href="/tags/C-C/" style="font-size: 15px;">C/C++</a> <a href="/tags/FTRL/" style="font-size: 15px;">FTRL</a> <a href="/tags/hive/" style="font-size: 15px;">hive</a> <a href="/tags/Java编程思想/" style="font-size: 15px;">Java编程思想</a> <a href="/tags/kmp/" style="font-size: 15px;">kmp</a> <a href="/tags/字符串匹配/" style="font-size: 15px;">字符串匹配</a> <a href="/tags/L2范数，范数/" style="font-size: 15px;">L2范数，范数</a> <a href="/tags/linux性能管理/" style="font-size: 15px;">linux性能管理</a> <a href="/tags/NLP/" style="font-size: 15px;">NLP</a> <a href="/tags/tensorflow/" style="font-size: 15px;">tensorflow</a> <a href="/tags/自动求导，自动微分/" style="font-size: 15px;">自动求导，自动微分</a> <a href="/tags/sublime/" style="font-size: 15px;">sublime</a> <a href="/tags/TFRecord/" style="font-size: 15px;">TFRecord</a> <a href="/tags/FM/" style="font-size: 15px;">FM</a> <a href="/tags/指标/" style="font-size: 15px;">指标</a> <a href="/tags/auc/" style="font-size: 15px;">auc</a> <a href="/tags/zookepper/" style="font-size: 15px;">zookepper</a> <a href="/tags/centos7/" style="font-size: 15px;">centos7</a> <a href="/tags/cpm/" style="font-size: 15px;">cpm</a> <a href="/tags/opcm/" style="font-size: 15px;">opcm</a> <a href="/tags/ecpm/" style="font-size: 15px;">ecpm</a> <a href="/tags/hexo，微信屏蔽/" style="font-size: 15px;">hexo，微信屏蔽</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/tf/" style="font-size: 15px;">tf</a> <a href="/tags/正则表达式/" style="font-size: 15px;">正则表达式</a> <a href="/tags/leetcode/" style="font-size: 15px;">leetcode</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/重装系统/" style="font-size: 15px;">重装系统</a> <a href="/tags/maven/" style="font-size: 15px;">maven</a> <a href="/tags/OJ/" style="font-size: 15px;">OJ</a> <a href="/tags/dfs/" style="font-size: 15px;">dfs</a> <a href="/tags/递归/" style="font-size: 15px;">递归</a> <a href="/tags/poj/" style="font-size: 15px;">poj</a> <a href="/tags/回文字符串/" style="font-size: 15px;">回文字符串</a> <a href="/tags/dp/" style="font-size: 15px;">dp</a> <a href="/tags/暴力/" style="font-size: 15px;">暴力</a> <a href="/tags/棋盘规则/" style="font-size: 15px;">棋盘规则</a> <a href="/tags/状态压缩/" style="font-size: 15px;">状态压缩</a> <a href="/tags/BFS/" style="font-size: 15px;">BFS</a> <a href="/tags/位运算/" style="font-size: 15px;">位运算</a> <a href="/tags/pytorch/" style="font-size: 15px;">pytorch</a> <a href="/tags/module/" style="font-size: 15px;">module</a> <a href="/tags/爬虫/" style="font-size: 15px;">爬虫</a> <a href="/tags/shell/" style="font-size: 15px;">shell</a> <a href="/tags/质数/" style="font-size: 15px;">质数</a> <a href="/tags/素数/" style="font-size: 15px;">素数</a> <a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/sklearn/" style="font-size: 15px;">sklearn</a> <a href="/tags/hole/" style="font-size: 15px;">hole</a> <a href="/tags/spark/" style="font-size: 15px;">spark</a> <a href="/tags/打散/" style="font-size: 15px;">打散</a> <a href="/tags/roc-auc-score/" style="font-size: 15px;">roc_auc_score</a> <a href="/tags/svm多类别分类/" style="font-size: 15px;">svm多类别分类</a> <a href="/tags/网格搜索/" style="font-size: 15px;">网格搜索</a> <a href="/tags/textFile/" style="font-size: 15px;">textFile</a> <a href="/tags/源码剖析/" style="font-size: 15px;">源码剖析</a> <a href="/tags/rdd计算/" style="font-size: 15px;">rdd计算</a> <a href="/tags/smoothing/" style="font-size: 15px;">smoothing</a> <a href="/tags/tensorboard/" style="font-size: 15px;">tensorboard</a> <a href="/tags/test-in-ubuntu/" style="font-size: 15px;">test in ubuntu</a> <a href="/tags/tf-nn/" style="font-size: 15px;">tf.nn</a> <a href="/tags/tensor/" style="font-size: 15px;">tensor</a> <a href="/tags/gather/" style="font-size: 15px;">gather</a> <a href="/tags/cnn/" style="font-size: 15px;">cnn</a> <a href="/tags/transformer/" style="font-size: 15px;">transformer</a> <a href="/tags/nlp/" style="font-size: 15px;">nlp</a> <a href="/tags/trie/" style="font-size: 15px;">trie</a> <a href="/tags/推荐，对比学习，冷启动/" style="font-size: 15px;">推荐，对比学习，冷启动</a> <a href="/tags/word2vec/" style="font-size: 15px;">word2vec</a> <a href="/tags/torch/" style="font-size: 15px;">torch</a> <a href="/tags/torch-geometric/" style="font-size: 15px;">torch-geometric</a> <a href="/tags/多任务学习/" style="font-size: 15px;">多任务学习</a> <a href="/tags/图网络/" style="font-size: 15px;">图网络</a> <a href="/tags/矩阵补全/" style="font-size: 15px;">矩阵补全</a> <a href="/tags/推荐/" style="font-size: 15px;">推荐</a> <a href="/tags/NAS/" style="font-size: 15px;">NAS</a> <a href="/tags/网络修剪/" style="font-size: 15px;">网络修剪</a> <a href="/tags/知识迁移/" style="font-size: 15px;">知识迁移</a> <a href="/tags/神经架构搜索/" style="font-size: 15px;">神经架构搜索</a> <a href="/tags/async/" style="font-size: 15px;">async</a> <a href="/tags/异步/" style="font-size: 15px;">异步</a> <a href="/tags/多进程/" style="font-size: 15px;">多进程</a> <a href="/tags/流数据/" style="font-size: 15px;">流数据</a> <a href="/tags/概念漂移/" style="font-size: 15px;">概念漂移</a> <a href="/tags/二分搜索/" style="font-size: 15px;">二分搜索</a> <a href="/tags/univesal-embedding/" style="font-size: 15px;">univesal embedding</a> <a href="/tags/机器学习工具/" style="font-size: 15px;">机器学习工具</a> <a href="/tags/universal-embedding/" style="font-size: 15px;">universal embedding</a> <a href="/tags/迁移学习/" style="font-size: 15px;">迁移学习</a> <a href="/tags/逻辑/" style="font-size: 15px;">逻辑</a> <a href="/tags/github-blog/" style="font-size: 15px;">github blog</a> <a href="/tags/例行化/" style="font-size: 15px;">例行化</a> <a href="/tags/协同过滤/" style="font-size: 15px;">协同过滤</a> <a href="/tags/GCN/" style="font-size: 15px;">GCN</a> <a href="/tags/图卷积/" style="font-size: 15px;">图卷积</a> <a href="/tags/github/" style="font-size: 15px;">github</a> <a href="/tags/在线学习/" style="font-size: 15px;">在线学习</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> 归档</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/03/">三月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/09/">九月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/08/">八月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/07/">七月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/01/">一月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/12/">十二月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">十一月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/10/">十月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/09/">九月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/08/">八月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/02/">二月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/12/">十二月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/11/">十一月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/10/">十月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">九月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">七月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">六月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">四月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">三月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">二月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">十一月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">十月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">八月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">七月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">五月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">十二月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">十一月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">十月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">七月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">四月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">十一月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">八月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">四月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">十二月 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">十一月 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">十月 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/05/">五月 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/04/">四月 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/12/">十二月 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/11/">十一月 2014</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-you"> 友情链接</i></div><ul></ul><a href="https://petr-mitrichev.blogspot.com/" title="petr" target="_blank">petr</a><ul></ul><a href="http://blog.pluskid.org/" title="Free Mind" target="_blank">Free Mind</a><ul></ul><a href="http://www.flickering.cn/" title="火光摇曳" target="_blank">火光摇曳</a><ul></ul><a href="https://recsys.acm.org/" title="recsys" target="_blank">recsys</a><ul></ul><a href="https://sites.google.com/site/xreborner/" title="Xreborner" target="_blank">Xreborner</a><ul></ul><a href="http://blog.watashi.ws/" title="watashi" target="_blank">watashi</a><ul></ul><a href="https://toc.csail.mit.edu/user/306" title="WJMZBMR" target="_blank">WJMZBMR</a><ul></ul><a href="http://dongxicheng.org/" title="dongxicheng" target="_blank">dongxicheng</a><ul></ul><a href="https://www.byvoid.com/zht/" title="byvoid" target="_blank">byvoid</a></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p><a href="/baidusitemap.xml">Baidu Site Haritası</a> |  <a href="/atom.xml">订阅</a> |  <a href="/about/">关于</a></p><p><span> Copyright &copy;<a href="/." rel="nofollow">TiuVe.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/chaooo/hexo-theme-BlueLake"> BlueLake.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script type="text/javascript" src="/js/search.json.js?v=2.0.1"></script><!-- 页面点击小红心，在末尾添加，避免找不到 -->
<script type="text/javascript" src="/js/love.js"></script>
<!-- 背景彩带, true打开，false关闭 --><script type="text/javascript" src="/js/toctotop.js?v=2.0.1" async></script><script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":["mshare","weixin","tsina","qzone","linkedin","fbook","twi","print","renren","sqq","evernotecn","bdysc","tqq","tqf","bdxc","kaixin001","tieba","douban","bdhome","thx","ibaidu","meilishuo","mogujie","diandian","huaban","duitang","hx","fx","youdao","sdo","qingbiji","people","xinhua","mail","isohu","yaolan","wealink","ty","iguba","h163","copy"],"bdPic":"","bdStyle":"1","bdSize":"16"},"share":{},"image":{"viewList":["tsina","qzone","weixin","fbook","twi","linkedin","youdao","evernotecn","mshare"],"viewText":"分享到：","viewSize":"16"},"selectShare":{"bdContainerClass":null,"bdSelectMiniList":["tsina","qzone","weixin","fbook","twi","linkedin","youdao","evernotecn","mshare"]}};with(document)0[(getElementsByTagName('head')[0]||head).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
</script><script>(function(d, s) {
  var j, e = d.getElementsByTagName('body')[0];
  if (typeof LivereTower === 'function') { return; }
  j = d.createElement(s);
  j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
  j.async = true;
  e.appendChild(j);
})(document, 'script');
</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/Epsilon2.1.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>