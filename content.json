[{"title":"《ACM MM2021 Contrastive Learning for Cold-Start Recommendation》阅读笔记","date":"2023-03-29T10:53:18.000Z","path":"2023/03/29/《Contrastive-Learning-for-Cold-Start-Recommendation》阅读笔记/","text":"本论文发表于ACM MM2021，针对推荐系统的冷启动问题进行了研究。论文设计了基于图结构的user-item的相关性框架得到user embedding和item embeding，但是对于冷启动item则无能为力，为此又设计了基于内容的item表征和基于图结构的item表征的对比学习任务。其实这个思维框架和Google的《Self-supervised Learning for Large-scale Item Recommendations》很像，也是解决长尾冷启动问题的。 具体来说，论文提出了基于对比学习的冷启动推荐框架CLCRec，其由三部分组成：Contrastive Pair Organization，Contrastive Embedding Network和Contrasitve Optimization modules。 论文的一个亮点在于从理论的角度推导了对比学习任务的目标函数，这里就不做过多介绍了，详细可以读原文，接下来介绍下CLCRec是什么，以及两个对比学习任务分别是如何设计的。 1. CLCRec是什么CLCRec其实就是把基于图结构的user-item的相关性框架和item对比学习的任务进行融合，其融合公式如下： 上式第一部分是item的对比学习任务，第二部分是基于图结构的user-item的相关性框架。第三部分是假设所有参数服从高斯先验分布。 2. user-item的相关性框架 2.1 样本设计$\\lbrace (u,i), (u,j_1),(u,j_2)..,(u,j_K) \\rbrace$ (u,i)是正样本，u表示用户，i表示用户交互过的item；$(u,j_K)$是负样本，$j_K$表示用户u没有交互过的item，K是随机采样的item个数。 2.2 相关性设计简单来说就是，用户交互过的item集合来表征user，购买过item的用户集合来表征item，最后计算二者的相关性。这样的话对于冷启动的item则无能为力，所以又设计了item的对比学习任务。 3 item对比学习任务 3.1 样本设计$\\lbrace (i,i), (i,j_1),(i,j_2)..,(i,j_K) \\rbrace$ $(i,i)$ 是正样本，$(i,j_K)$是负样本。$i$和$j_K$都是item。 3.2 对比学习设计item的对比学习任务做了两个数据增强。1是基于user-item的相关性框架得到的item表征，2是基于item的内容信息通过一个特征提取器得到的item表征，特征提取器是一个简单的MLP。 在得到上述两个item表征之后，最后计算二者的相似性。 4. 目标函数更详细的目标函数如下： 5. 实验对比 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} });","tags":[{"name":"推荐，对比学习，冷启动","slug":"推荐，对比学习，冷启动","permalink":"http://aeyoo.net/tags/推荐，对比学习，冷启动/"}]},{"title":"《KDD2018 Perceive Your Users in Depth Learning Universal User Representations from Multiple E-commerce Tasks》阅读笔记","date":"2022-09-07T01:36:36.000Z","path":"2022/09/07/《KDD2018-Perceive-Your-Users-in-Depth-Learning-Universal-User-Representations-from-Multiple-E-commerce-Tasks》阅读笔记/","text":"DUPN（深度用户感知网络）是阿里在KDD2018发表的一篇文章。 参考 推荐系统的多目标优化(3)-DUPN - weber’s Blog MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} });","tags":[{"name":"univesal embedding","slug":"univesal-embedding","permalink":"http://aeyoo.net/tags/univesal-embedding/"}]},{"title":"《Parameter-Efficient Transfer from Sequential Behaviors for User Modeling and Recommendation》论文阅读","date":"2022-08-10T01:25:52.000Z","path":"2022/08/10/《Parameter-Efficient-Transfer-from-Sequential-Behaviors-for-User-Modeling-and-Recommendation》论文阅读/","text":"归纳迁移学习对计算机视觉和 NLP 领域产生了重大影响，但尚未用于推荐系统领域。虽然已经有大量基于建模user-item交互序列做推荐任务的研究，但很少有人尝试表征和迁移这些模型到仅存在有限数据的下游任务。本文深入研究了如何有效地学习单个用户表征，并将该表征应用于各种任务，从跨域推荐到用户属性预测。微调大型预训练网络并使其适应下游任务是解决此类任务的有效方法。但是考虑到每个新任务都需要重新训练整个模型，微调的参数效率很低。为了克服这个问题，论文提出了一种参数有效的迁移学习架构，称为 PeterRec，它可以动态配置到各种下游任务。具体来说，PeterRec 通过注入一系列重新学习的神经网络，允许预训练的参数在微调期间保持不变，这些神经网络虽小但与学习整个网络一样具有表现力。论文通过一系列消融实验展示了用户表征在五个下游任务中的有效性。此外，作者证明了 PeterRec在多个领域迁移学习的有效性，与微调整个模型参数相比，PeterRec实现了相当或更好的性能。代码和数据集可在 https://github.com/fajieyuan/sigir2020_peterrec 获得。 1 介绍在过去10年的工作中，社交平台产生了各种各样丰富的item序列，然而大部分工作集中在同平台&#x2F;领域的序列推荐任务，很少有工作利用这些数据学习用户的通用表征，用于其它下游任务，例如不同推荐平台的用户冷启动和用户属性预测等。 作者希望通过学习用户的通用表征用于下游各种任务。具体地，作者尝试使用神经网络，从具有丰富user-item交互序列的源域出发，以无监督（自监督）的方式进行预训练得到用户的embedding，用于目标域的各种任务（目标域的用户是新&#x2F;冷的）。为此需要解决以下问题： 构造一个高效通用的预训练模型，可以在无监督情况下建模非常长的user-item交互序列； 开发一个微调架构，可以将预训练的用户表征用于下游任务； 引入一种自适应方法，使得微调架构在所有下游任务中共享大部分参数。目的是在昂贵的计算代价和效果之间做折中。 为了解决第三个问题，两种迁移技术被广泛使用： 微调额外的输出层将知识从源于迁移到目标域； 微调最后一个或几个隐藏层和输出层 事实上，仅对输出层进行微调通常在推荐场景中效果不佳，适当微调最后几层有时效果会更好，但是这需要大量手动工作，因为要调整的层数取决于预训练和模型和目标任务。在实践中，层数的选择往往依赖于低效的超参数搜索，另外这也并没有实现共享预训练模型大多数参数的目标。 为了实现前两个目标，作者提出了两阶段的训练过程。 基于顺序神经网络nextItnet对用户的点击序列做序列推荐任务（next item）； 使用监督目标让预训练模型适应下游任务。 为了实现第三个目标，即实现微调模型在不同域之间的高度参数共享，作者借鉴了learn-to-learn方法（参考文献【Learning feed-forward one-shot learners】），learn-to-learn的思想是神经网络的参数可以从另一个神经网络预测得到。此外，【Predicting parameters in deep learning】证明了给定神经网络一个层中5%的参数，剩下95%的参数可以预测得到。作者将这个思路用到了推荐系统的迁移学习任务。具体地，作者提出了一个嫁接神经网络（也被叫做模型补丁），使预训练模型中每个卷积层的参数适应目标任务。每个模型补丁由原始卷积层不到10%的参数组成。通过将这些模型补丁插入到预训练模型中，微调网络不需要改变预训练参数，就可以成功应用到下游任务而不降低性能。作者将提出的模型命名为PeterRec。 本文的主要贡献如下： 提出了一种通用的用户表征架构，自称是第一个将得到的用户表征用于用户基础信息的预测（性别年龄等）； 提出了一个简单但有效的嫁接网络，允许微调网络不改变预训练参数就可以应用于下游任务； 提出了两种将模型补丁嵌入到预训练模型中的方法：串行插入和并行插入。 微调时对五中不同任务做了广泛的消融分析； 发布了用于迁移学习的高质量数据集。这是第一个用于迁移和多领域学习的大规模推荐数据集。 2 相关工作2.1 序列推荐模型序列推荐（SR）模型是将用户对物品的交互序列作为输入，预测用户喜欢的下一个物品。在对用户的序列动作建模时，相比于传统的基于内容的推荐方法，SR被证明有明显的准确率提升；SR的另一个优点是不需要用户的基础信息。对于SR问题，研究人员主要关注三个方面的工作： 基于RNN的建模。训练过程中严重依赖于顺序，无法充分利用并行计算架构GPU，而基于CNN和基于attention的推荐方法在训练过程中可以观察到整个序列，所以不存在这个问题。 基于CNN的建模。kernel较小导致感受野有限，无法成为强序列模型。膨胀卷积解决了这个问题，可以在kernel大小不变的情况下指数级增加感受野大小。 基于attention机制的建模。可能存在时间复杂度和内存问题，其随序列长度呈现二次方增长。 综上，作者选择了基于CNN（膨胀卷积）的方式建模。具体地，选择了因果卷积（nextItNet）和非因果卷积（GRec的双向编码器）构建预训练模型。 2.2 迁移学习和域适应迁移学习（TL）是从源域中获取知识，去解决不同但相关的目标域问题，而目标域中只有少量的标记数据（监督信号）。和早期专注于浅层分类器的工作不同（例如矩阵分解），现在的TL研究转向DNN作为分类器，这产生了更好的准确率。然而也带来了一些挑战： 如何在有限的资源下进行高效的迁移学习； 在目标域的监督信号稀疏情况下，如何避免过拟合问题。 上述研究尚未进行有效探索，甚至不确定是否可以仅通过用户的行为来学习到有效的用户表征，以及是否可以迁移这些表征以改进下游任务。最近的一个相关工作是代表深度用户感知网络的 DUPN 模型。 DUPN 通过多任务学习用户的通用表征，这造成一个局限，就是需要依靠许多附加特征进行预训练；另外对于迁移学习问题，DUPN只考虑了微调所有预训练参数和最终分类层，成本较高。相比之下，PeterRec 通过单loss进行预训练用于下游多个任务，且PeterRec只微调了一小部分注入参数，但与微调所有参数相比，获得了相当或更好的结果。。为此，我们将本文中的任务定义为多域学习问题，这与 DUPN 中的多任务学习不同。CoNet [16] 是另一个使用神经网络作为基础模型的跨域推荐模型。为了实现知识迁移，CoNet联合训练了两个目标函数，其中一个代表源网络，另一个代表目标网络。 CoNet 的作者得出的一个有趣结论是，根据经验观察，他们论文中的预训练和微调范式效果不佳。事实上，CoNet 和 DUPN 都没有提供证据表明使用预训练网络进行微调比从头开始微调效果更好，这无疑是推荐系统中 TL 的基本假设。本文证明了PeterRec相对于从头开始训练并对预训练模型微调的方式，显着提高了下游推荐任务的准确性。 3 PeterRec3.1 定义 源域：$S$，由用户id和用户交互的序列$x^u&#x3D;\\lbrace x^u_1,…,x^u_n \\rbrace$组成； 目标域：$T$，由用户id和监督标签y组成。 下面介绍下peterRec的模型设计。如下图所示，左边是预训练模型，右边是微调模型。在预训练模型中，$\\tilde{\\Theta}$包括embedding和卷积层的参数，$H(\\tilde{\\Theta})$是预训练网络，$w(\\hat{\\Theta})$是是预训练网络的分类层。$\\tilde{H}(\\tilde{\\Theta}; \\vartheta)$是微调网络，微调网络中的$\\tilde{\\Theta}$指的是预训练好的embedding和卷积层的参数，$\\vartheta$是模型补丁。$H(\\tilde{\\Theta})$和$\\tilde{H}(\\tilde{\\Theta}; \\vartheta)$共享相同的预训练网络参数，但模型补丁的参数不共享。[TCL]是一个特殊的token作为分类标记，具体可以参考下文介绍的nextItNet网络结构。 3.2 预训练的用户表征1 预训练目标 和NextItNet类似，peterRec的预训练目标是根据用户的交互序列预测下一个用户感兴趣的item。其概率表示如下： $\\Theta$是预训练模型参数，包括预训练网络参数和分类层参数。如公式所示，相比于DUPN简单将用户交互序列当做特征，这种方式更能充分建模用户的交互序列。论文提到，PeterRec是推荐系统领域的第一个基于无监督自回归的迁移学习模型。 另外，有研究表明，用户的交互序列在表达用户兴趣偏好时并不需要是严格有序的，例如用户点击序列a,b,c和c,a,b其实表达的信息量是等同的。为了缓解严格有序的问题，作者随机mask掉的一些item。 论文没有提出一种新的预训练目标函数，而是介绍了用户表征领域的一些预训练目标函数。 2 预训练网络架构 预训练网络架构是由空洞卷积（DC）层堆叠而成的。每两个DC层由残差模块组成，而每个DC层后面有一个LN层和非线性激活层ReLU（如图3a所示）。 另外，预训练网络通过因果CNN和非因果CNN两种方式被构建，公式如下： 下面是预训练方式。 3.3 用户表征迁移PeterRec迁移架构包括三部分： 预训练模型（分类层除外） 作用于下游任务的分类层 模型补丁 1 微调架构 首先介绍下预训练模型的架构。以因果CNN为例（图2a）。对于每个样本(X，Y)，增加一个[TCL]标识到序列X的末尾，即$x^u&#x3D;\\lbrace x_1^u,..,x_n^u,[TCL] \\rbrace$，然后对$x^u$做一系列卷积操作，得到token对应的embedding矩阵，然后在[TCL]对应的embedding $h_n$后面增加一个分类层，得到各个label的score。 非因果CNN也类似，区别在于非因果CNN是在$x^u$的首尾都增加了[TCL]标识。 另外值得一提的是，论文对不同的下游任务使用了不同的loss。对于topN推荐任务使用了BPR损失，对于用户属性预测任务使用了交叉熵损失。 2 模型补丁 模型补丁其实也是一个神经网络，其目的是使预训练的DC残差块适应下游任务。最近一个learn-to-learn的研究表明，可以根据模型5%的参数预测剩下95%的参数。作者希望不微调所有参数，二是通过微调部分参数在下游任务中实现更好的性能。模型补丁的结构如图3f所示，由两个卷积层（kernel 1×1，维度k，通道d），一个Relu激活层和一个残差结构组成。这里使用其它的模型补丁也是可以的。 3 插入方法 作者介绍了两种插入方法，串行和并行，如图3bcde所示。 对于串行插入，插入位置非常灵活，因此可以在层标准化之前或之后注入嫁接补丁，如（b）和（c）所示。 对于串行插入，每个 DC 残差块的补丁数量非常灵活，可以注入一个或两个补丁。 如果 (c) 中的 k 是 (b) 中的 k 的两倍，它会给出几乎相同的结果。 对于平行插入，PeterRec 对插入位置很敏感，如 (d) 和 (e) 所示。 具体来说，在层归一化之前注入的模型补丁（即（d））比层归一化和激活函数之间的模型补丁表现更好，后者的性能大大优于激活函数之后的模型补丁（即（e））。 对于并行插入，在 DC 块中插入两个补丁的 PeterRec 通常比只插入一个补丁的效果略好 最终需要微调的参数减少到1.7%。 4 实验实验环节，作者重点论述了四个问题： 自监督学习用户表示真的对下游任务有帮助吗？ 作为推荐系统领域迁移学习的基础研究问题，这在以前从未得到验证。 与微调最后一层和整个模型相比，PeterRec 提出的模型补丁的效果如何？ PeterRec 可以估计哪些用户属性？ 当用户在目标域中是冷的或新用户时，PeterRec 是否能正常工作。 是否能通过 PeterRec 的消融分析得出其它有趣的结论？ 以上问题的回答可以看下论文。 4.1 数据集数据集来自腾讯业务，源域数据是QQ浏览器的新闻推荐数据，目标域数据是QQ看点的新闻交互数据。源域数据比较丰富，人均50个标签；目标域数据比较稀疏，大概人均5个标签。 4.2 评估为了评估 PeterRec 在下游任务中的性能，作者将目标数据集随机分为训练集（70%）、验证集（3%）和测试集（27%），使用两个流行的 top-5 指标（MRR@5和 HR@5），用于冷启动推荐数据集（即 ColdRecs）；准确率指标用于其它三个数据集。 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} });","tags":[{"name":"universal embedding","slug":"universal-embedding","permalink":"http://aeyoo.net/tags/universal-embedding/"},{"name":"迁移学习","slug":"迁移学习","permalink":"http://aeyoo.net/tags/迁移学习/"}]},{"title":"《Towards Universal Sequence Representation Learning for Recommender Systems》论文阅读笔记","date":"2022-07-03T06:53:10.000Z","path":"2022/07/03/《Towards-Universal-Sequence-Representation-Learning-for-Recommender-Systems》论文阅读笔记/","text":"该论文是人大和阿里合作的一个序列表征相关的工作，发表于KDD2022。目前大多数序列表征工作基于itemid建模，导致其无法很好地迁移到其它场景中。该论文提出了一种通用的序列表征学习方法（UniSRec，Universal Sequence representation learning approach for Recommendation, named as UniSRec），首先通过item的描述文本学习到跨域的item表征，然后基于跨域的item表征学习到通用的序列表征。具体地，其提出了一种基于参数白化和混合专家增强适配器的item编码架构。为了使得学习到的序列表征更通用，论文通过多域负采样构造了两个对比学习任务。论文在使用Amazon数据集和英国在线零售平台的数据集进行了评测，并且开源了代码。 1 背景在推荐系统中，序列推荐是一项广泛研究的任务，旨在根据用户的历史交互记录向用户推荐合适的项目。已经提出了各种方法来提高顺序推荐的性能，从早期的矩阵分解（例如，FPMC [18]）到最近的序列神经网络（例如，GRU4Rec、Caser和 Transformer），这些方法在很大程度上提高了顺序推荐的性能标准。但是现有的工作多基于itemid，这导致其很难迁移到新场景。论文提出了一种叫UniSRec的编码架构，给定用户在多个域的历史行为序列，学习到item和序列的universal表征，并将其用于新场景中。 2 方法首先给出uniSRec框架的示意图： 简单来说，论文以一种预训练的方式（uniSRec）学习universal表征，然后将其用于其它业务场景中。uniSRec将用户的交互序列作为input。论文中对input做了形式化说明（关于序列推荐问题的形式化问题论文中没有提及，这里也不累述了。）。 给定一个用户序列$s&#x3D;{i_1,i_2,…,i_n}$，$i$表示item i（item i关联了itemid和描述文本），item i的描述文本$t_i&#x3D;{w_1,…,w_c}$，$w_j$表示来自共享词典中的一个词，c是截断阈值。 论文认为，不同域的用户序列存在较大的语义gap，所以对于同一个用户在不同域的序列，将其当做不同序列。另外需要强调的一点是，input提到的itemid仅仅用于形式化说明，论文核心是基于item文本生成和itemid无关的序列表征。 为了学习到跨域的序列表征，论文抽象了两个关键问题，分别学习item和序列的universal表征（因为item和序列是基本的数据格式）。 对于学习item表征，论文提出了一种基于参数白化和混合专家增强适配器的域融合机制； 对于学习序列表征，论文提出了两个对比学习任务，即基于多域负采样的序列-item对比任务和序列-序列的对比任务，用于更好地融合不同域的语义信息。 基于上述介绍，UniSRec主要分为三部分： Universal Textual Item Representation Universal Sequence Representation Parameter-Efficient Fine-tuning（介绍如何迁移到下游任务） 2.1 Universal Textual Item Representation序列表征建模的第一步是将不同域的item表征映射到统一的语义空间。借鉴NLP中的一些工作，这里引入预训练语言模型学习item文本的embedding。 2.1.1 基于预训练的item文本编码简单来说就是将item的文本送入bert，得到item的embedding表征。 2.1.2 基于参数白化的语义迁移通过bert可以得到多个域的item表征，但是如果将其简单融合的话会存在较大的语义鸿沟，一些研究表明bert为普通文本引入了非平滑的各向异性语义空间（出自On the Sentence Embeddings from Pre-trained Language Models. In EMNLP2020）。为了解决上述问题，这里引入了参数白化，构造了一个简单的线性变换对bert得到的item表征进行变换。和别的预设均值和方差的白化方法不同，这里的参数白化引入了可学习的参数增强其泛化能力。 2.1.3 基于混合专家增强适配器的域融合机制通过参数白化可以学习到向同性的item表征，接下来要考虑的是如何融合多个域的item表征，因为在不同域之间存在较大的语义鸿沟。一种简单的做法是，将不同域的item映射到相同的共享语义空间，但是这样做会限制其表达能力，无法捕获不同域的差异。这里作者使用了MoE结构融合多个域的item表征。 2.2 Universal Sequence Representation因为不同域反映了用户不同的行为模式，所以简单融合多个域的序列是不可取的，这可能会导致跷跷板现象。所以引入了两个对比学习任务，进一步强化不同域item表征的融合。 2.2.1 自注意力序列编码作者希望基于item通用语义编码，构造一个序列模式。这里使用了transformer机制，将学习到的文本表征（等式3）和位置编码作为输入，输入和更新机制如下： 最终得到序列的初始表征$F^{l+1}$。 2.2.2 多域序列表征为了获取统一语义空间的序列编码，并在预训练阶段捕捉不同域的语义相关性，作者构造了两个对比学习任务。 1 Sequence-item对比任务 这样做的目的是捕获上下文序列和next item的相关性。和之前next item的预测任务不同，这里使用可跨域的item作为负样本，这样做有助于不同域的语义融合，学到更通用的表征。 2 Sequence-sequence对比任务 sequence-sequence对比任务和sequence-item非常类似，这里不再累述。值得注意的是，这里使用了drop（item drop和word drop）方式增强泛化能力。 3 多任务融合 就是融合连个对比学习任务的loss。 2.3 下游任务微调分为归纳式和直推式两种。 3 实验2.1 数据集 论文使用的数据集分为三部分，预训练数据集（Amazon），跨域数据集（Amazon），跨平台数据集（英国在线零售平台）。 2.2 评估 4 个人总结总的来说，工作是围绕着建设通用化序列表征开展的，idea也比较好。去年我们团队也尝试过类似的思路，用于广告业务，但是效果不是特别明显。当然这其中的原因很多，某些域的数据非常稀疏，这可能最主要的原因。我个人认为这个思路还是值得尝试的，但是在工程中可能需要做必要的简化以应对庞大的数据（个人感觉6个月及以上的数据是必要的，不然数据太稀疏了）。 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} });","tags":[{"name":"universal embedding","slug":"universal-embedding","permalink":"http://aeyoo.net/tags/universal-embedding/"}]},{"title":"NLP相关资料整理","date":"2022-01-06T16:22:04.000Z","path":"2022/01/07/NLP相关资料整理/","text":"本帖整理下NLP的相关资料，有空的时候学习下。 COMS W4705: Natural Language Processing (Spring 2019) 哥伦比亚大学NLP slides","tags":[{"name":"NLP","slug":"NLP","permalink":"http://aeyoo.net/tags/NLP/"}]},{"title":"hexo博客链接在微信被屏蔽的解决办法","date":"2022-01-05T14:47:06.000Z","path":"2022/01/05/hexo博客链接在微信被屏蔽的解决办法/","text":"众所周知，微信对于外链管理是出了名的严格，动不动就屏蔽，但是hexo博客被屏蔽就难以理解了，提示说涉及色情。。朋友说可能是dom里面涉及到sex等关键词触发了相应规则，不知真假，不过还真有代码centerx: mousex - screen.width / 2命中了sex关键字。奇奇怪怪，还是说下怎么解决吧。 被微信屏蔽的外链被拦截分为两种情况，第一种情况是被微信拦截，这种情况下根据提示进行网站链接申诉就可以了。第二种情况是被手机管家拦截，如果第一种方式根据提示无法解除屏蔽，那么就需要考虑第二种情况，可以去https://urlsec.qq.com/complain.html 确认网址是否被拦截，如果确认被手机管家被拦截，直接申诉就好了，大概十几分钟的样子，挺快。 参考 网站拦截申诉站长认证失败为什么？ | 微信开放社区","tags":[{"name":"hexo，微信屏蔽","slug":"hexo，微信屏蔽","permalink":"http://aeyoo.net/tags/hexo，微信屏蔽/"}]},{"title":"TensorFlow的自动求导具体是在哪部分代码里实现的？","date":"2022-01-05T11:56:18.000Z","path":"2022/01/05/TensorFlow的自动求导具体是在哪部分代码里实现的？/","text":"最近在构建nn的时候，发现使用内积导致了输出全0，所以研究下tf的自动求导机制。题目来自于知乎的一个问题《(34 封私信 &#x2F; 77 条消息) TensorFlow的自动求导具体是在哪部分代码里实现的？ - 知乎》，这个答案讲的很好，但是对其中log函数求导先求复共轭的逻辑有点疑惑，所以研究下复数求导相关机制。先从实数域的多元函数导数讲起，再讲复数域的多元函数导数机制。 tf梯度-&gt;方向导数存在的前提-&gt;多元可微 实数多源求导 1 实数域下多元函数的可微性微分和导数是两个不同的概念。 对于一元函数，可微和可导完全等价。 对于多元函数，可微指的是可全微分。如果在偏导数存在且连续，那么可微 1.1 一元函数的可微性，可导，连续性如果$y&#x3D;f(x)$在点x可导，那么函数在该点必连续。反之，一个函数在某点连续但不一定在该点可导，例如函数$f(x)&#x3D;\\sqrt[3]{x}$在实数域内连续，但是在点x&#x3D;0处不可导。对于一元函数，可微和可导完全等价。 1.2 多元函数的可微性，可导，连续性雅可比矩阵： 1 复数与复平面复数，为实数的延伸，它使任一多项式方程都有根。复数当中有个虚数单位，它是-1的一个平方根，即$i^2&#x3D;-1$。任一复数都可表达为$x + yi$，其中x及y皆为实数，分别称为复数之“实部”和“虚部”。复数的发现源于三次方程的根的表达式。数学上，“复”字表明所讨论的数域为复数，如复矩阵，复变函数等。 复平面（英语：Complex plane）是用水平的实轴与垂直的虚轴建立起来的复数的几何表示。 2 全纯函数全纯函数（英语：Holomorphic function）是复分析研究的中心对象；它们是定义在复平面上的，在复平面$C$中取值的，在每点上皆复可微的函数。全纯函数有时称为正则函数。在整个复平面上都全纯的函数称为整函数。在一点a全纯，不仅意味着a可微，而且表示在某个中心为a的复平面上的开邻域上可微。 2.1 定义若$U$为$C$的开子集，且$f: U-&gt;C$为一个函数。 我们称$f$是在$U$中一点$z_0$是复可微的（complex differentiable）或全纯的，当且仅当该极限存在： $$f^{‘}(z_0)&#x3D;\\lim_{z \\to z_0} \\frac{f(z)-f(z_0)}{z-z_0} \\quad$$ 若$f$在$U$上任取一点均全纯，则称f在$u$上全纯。 特别地，若函数在整个复平面全纯，我们称这个函数为整函数。 关于全纯函数还有一个等价的定义：一个复函数全纯当且仅当它满足柯西-黎曼方程。 3 复变函数可微性4 Wirtinger导数参考 (34 封私信 &#x2F; 77 条消息) TensorFlow的自动求导具体是在哪部分代码里实现的？ - 知乎 NMT Tutorial 3扩展b. 自动微分 | Tingxun’s Blog Python callable() 函数 | 菜鸟教程 TensorFlow—计算梯度与控制梯度 : tf.gradients和compute_gradients和apply_gradients和clip_by_global_norm控制梯度_xinjieyuan的博客-CSDN博客 神经网络中复数函数求导 | zdaiot 全纯函数 - 维基百科，自由的百科全书 复数 (数学) - 维基百科，自由的百科全书 实值复变函数求导 ——（Wirtinger derivatives）_slsl97的博客-CSDN博客_实值复变函数求导 (34 封私信 &#x2F; 78 条消息) 复变函数如何理解（或学习）？ - 知乎 (34 封私信 &#x2F; 78 条消息) 正则和全纯有什么区别？ - 知乎 微分 - 维基百科，自由的百科全书 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} });","tags":[{"name":"tensorflow","slug":"tensorflow","permalink":"http://aeyoo.net/tags/tensorflow/"},{"name":"自动求导，自动微分","slug":"自动求导，自动微分","permalink":"http://aeyoo.net/tags/自动求导，自动微分/"}]},{"title":"tf中如何修改tensor的值","date":"2022-01-05T08:47:29.000Z","path":"2022/01/05/tf中如何修改tensor的值/","text":"在搞深度学习的工作时，经常遇到修改tensor值的需求。除此之外，之前还发现tf1.x中使用tf.scatter_update()更新tensor的值会报错，疑似不能反向传播。基于这些原因，本帖旨在整理一些修改tensor值的技巧，持续更新。 tf更新tensor&#x2F;自定义层 - 侯凯 - 博客园","tags":[{"name":"tensorflow","slug":"tensorflow","permalink":"http://aeyoo.net/tags/tensorflow/"},{"name":"tensor","slug":"tensor","permalink":"http://aeyoo.net/tags/tensor/"}]},{"title":"解决tf1.15中tf.scatter_update()函数没有定义梯度的问题","date":"2022-01-04T13:40:01.000Z","path":"2022/01/04/解决tf1-15中tf-scatter-update-函数没有定义梯度的问题/","text":"在本地使用了tf.compat.v1.scatter_update()更新tensor的值，测试OK放到服务器上跑一直失败，报错LookupError: No gradient defined for operation &#39;ScatterUpdate&#39; (op type: ScatterUpdate)，最后发现疑似tf1.15的tf.scatter_update()没有实现反向求导逻辑，挺奇怪的。 因为本地和服务器的代码是相同的，只有服务器端报错，所以首先判断是环境的问题。在本地开发使用的tf版本是tf2.2+python3.6，服务器使用的是tf1.15+python3.6。所以首先考虑将本地环境切换至tf1.15+python3.6，复现该问题。切换了环境后果然复现了该问题。网上Google了下该问题，知乎用户smallsunsun说是没有实现反向传播的逻辑，竟然会发生这种事情？？？看来应该看下tf反向求导的代码逻辑。 因为时间紧张，所以打算先绕过这个问题，既然tf1.15的tf.scatter_update()没有实现反向求导逻辑，那么一个合理的思路是用别的函数实现tf.scatter_update()的逻辑。stackoverflow用户Dmytro Prylipko给出了代码，如下所示。 12345678def scatter_update_tensor(x, indices, updates): ''' Utility function similar to `tf.scatter_update`, but performing on Tensor ''' x_shape = tf.shape(x) patch = tf.scatter_nd(indices, updates, x_shape) mask = tf.greater(tf.scatter_nd(indices, tf.ones_like(updates), x_shape), 0) return tf.where(mask, patch, x) 尝试了下是OK的（可以反向传播）。但是要注意，tf.scatter_nd()第一个参数的shape维度必须&gt;&#x3D;2，下面给出tf.scatter_nd()的函数声明和使用示例。 1234567891011121314151617181920212223tf.scatter_nd( indices, updates, shape, name=None)indices = tf.constant([[4], [3], [1], [7]]) # 是二维的updates = tf.constant([9, 10, 11, 12])shape = tf.constant([8])scatter = tf.scatter_nd(indices, updates, shape)print(scatter)# [0, 11, 0, 10, 9, 0, 0, 12]indices = tf.constant([[0], [2]])updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]], [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]]])shape = tf.constant([4, 4, 4])scatter = tf.scatter_nd(indices, updates, shape)print(scatter)# [[[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],# [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]],# [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],# [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]] 下面代码测试了函数scatter_update_tensor()和函数tf.scatter_update()的功能，结果是相同的。 12345678910111213141516171819202122232425262728def scatter_update_tensor(x, indices, updates): ''' Utility function similar to `tf.scatter_update`, but performing on Tensor ''' x_shape = tf.shape(x) patch = tf.scatter_nd(indices, updates, x_shape) mask = tf.greater(tf.scatter_nd(indices, tf.ones_like(updates), x_shape), 0) return tf.where(mask, patch, x)with tf.compat.v1.Session() as sess: x = tf.Variable(tf.ones(shape=[4,2])) indices = tf.constant([0, 1, 2, 3], dtype=tf.int32) updates = tf.reshape(tf.range(8, dtype=tf.float32), [4,2]) sess.run(tf.global_variables_initializer()) print(\"scatter_update_tensor:\") print(sess.run(scatter_update_tensor(x, tf.reshape(indices, [-1,1]), updates))) print(\"tf.scatter_update:\") print(sess.run(tf.scatter_update(x, indices, updates))) # scatter_update_tensor: # [[0. 1.] # [2. 3.] # [4. 5.] # [6. 7.]] # tf.scatter_update: # [[0. 1.] # [2. 3.] # [4. 5.] # [6. 7.]] 参考 (34 封私信 &#x2F; 76 条消息) Tensorflow No gradient defined for operation 怎么解决？ - 知乎 python - TensorFlow: An alternative to tf.scatter_update - Stack Overflow tf.scatter_nd | TensorFlow Core v1.15.0","tags":[{"name":"tensorflow","slug":"tensorflow","permalink":"http://aeyoo.net/tags/tensorflow/"},{"name":"scatter_update","slug":"scatter-update","permalink":"http://aeyoo.net/tags/scatter-update/"}]},{"title":"解决hexo博客代码在IOS下字体过大的问题","date":"2021-12-31T11:56:02.000Z","path":"2021/12/31/解决hexo博客代码在IOS下字体过大的问题/","text":"今天花了一个半小时对hexo博客进行格式美化，web端正常显示，但是在iPhone下，无论是Safari还是chrome，代码字体都特别大，疑似和ios下的渲染有关系，解决办法也很简单，设置webkit-text-size-ajust=none即可，但是注意该参数不要定义为全局的，因为设置为none的意思是禁止字体缩放。 代码设置如下： 123456789101112131415161718192021222324/* syntax highlight*/pre width: 100% position: relative border: none padding: 0 margin: 0 code display block box-sizing: border-box overflow-x: auto font-family: Monaco, monospace, Menlo, Source Code Pro, Consolas -webkit-text-size-adjust: none margin: 1.2em 0 padding 15px 15px 10px 15px line-height: 1.2em width: 100% border-radius: 5px /* box-shadow: 1px 1px 2px rgba(0, 0, 0, 0.125) */ font-size: 13px // color: #333 color: #ffffff // background: #f7f8f8 background: #282c34 参考 Chrome 调试工具与 iOS 上样式展示不同的问题 - V2EX Markdown code block font size is very large on the phone. · Issue #22 · probberechts&#x2F;hexo-theme-cactus","tags":[{"name":"hexo","slug":"hexo","permalink":"http://aeyoo.net/tags/hexo/"},{"name":"markdown","slug":"markdown","permalink":"http://aeyoo.net/tags/markdown/"}]},{"title":"记一次悲催的tf报错","date":"2021-12-30T07:56:48.000Z","path":"2021/12/30/记一次悲催的tf报错/","text":"昨天下午写tf代码的时候遇到一个报错tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[0] = 24 is not in [0, 24)，怀疑是矩阵变换哪里出了问题，但是check了很久的逻辑没有发现任何问题，甚至将相关逻辑抽取出来做了单元测试，依然没有任何发现。今天决定check下数据是否有问题，虽然之前已经check没有问题，但由于没有头绪，还是决定再次check下数据。打印了找了一个part的数据（tfrecord格式）重新打印成明文，根据batch数据的值找到对应的源数据，发现已经到达数据的末尾，突然意识到了什么…貌似是最后的数据量 &lt; batch_size导致了报错，竟然没有想到。。。 具体是为什么报错呢？之前的代码如下： 12345mask = tf.compat.v1.sparse_to_dense(sparse_indices=mask_line_id, output_shape=[self.batch_size, ], default_value=1, sparse_values=0,) 这里生成了mask矩阵，用于在下游对input和label进行mask，mask的方式是使用tf.gather()函数。由于mask的大小是batch_size，而input和label的大小&lt;batch_size，这时候使用tf.gather(input, mask)则报错tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[0] = 24 is not in [0, 24)。 针对上述问题，一个简单的办法就是，动态获取input的大小，代码如下： 12345mask = tf.compat.v1.sparse_to_dense(sparse_indices=mask_line_id, output_shape=[tf.shape(indices)[0], ], default_value=1, sparse_values=0,) 期间还遇到一个报错InvalidArgumentError: indices[0] = [0] is out of bounds: need 0 &lt;= index &lt; [0]，这是因为tf.compat.v1.sparse_to_dense的前两个参数的size不同。","tags":[{"name":"tensorflow","slug":"tensorflow","permalink":"http://aeyoo.net/tags/tensorflow/"}]},{"title":"tensorboard中的Smoothing","date":"2021-12-17T11:11:08.000Z","path":"2021/12/17/tensorboard中的Smoothing/","text":"tensorboard是Google提出的一个机器学习可视化的工具，它的界面上有一个smoothing的参数，通过调整smoothing可以控制指标曲线的平滑程度。那么它背后的原理是什么呢？ tensorboard可以对机器学习任务中的各种指标进行可视化呈现，指标有loss，auc等，可视化方式有折线，直方图等。在很多情况下，如果样本比较少的情况下，各种指标的值就会变化很大，可视化出来之后就会变得很震荡。这时候就需要对曲线进行平滑，这时候smoothing参数就派上用场了。 简单来说，smoothing参数实现了一个指数平滑（Exponential smoothing）的逻辑，使用历史数据对当前值进行指数平滑。越久远的数据，对当前值的影响力越小，其影响力指数级衰减。指数平滑的公式如下：$$\\begin{aligned}&amp; s_0&#x3D;x_0 \\\\&amp; s_t&#x3D;\\alpha x_t + (1-\\alpha)s_{t-1}, t&gt;0 \\\\&amp; \\alpha \\ is \\ smoothing\\ factor，0&lt;\\alpha&lt;1\\end{aligned}$$看到这里可能有所疑问，指数体现在哪里呢？？ 其实上面的只是一个状态转移方程，描述了t时刻和t-1时刻的关系。我们可以举个例子： 假设$s_0&#x3D;0$，$\\alpha&#x3D;0.1$，那么 $s_1&#x3D;x_1 + 0.9s_0$​​ $s_2&#x3D;0.1x_2 + 0.9s_1$​​ $s_3&#x3D;0.1x_3 + 0.9s_2$​ 将$s_1$和$s_2$带入$s_3$​，则$$\\begin{aligned}s_3&amp;&#x3D;0.1x_3+0.9(0.1x_2 + 0.9(0.1x_1 + 0.9s_0)) \\\\ &amp; &#x3D;0.1(x_3+0.9x_2+0.9^2x_1) \\\\ &amp; &#x3D; \\alpha (x_3+(1-\\alpha)x_2 + (1-\\alpha)^2x_1)\\end{aligned}$$也就是$$s_t&#x3D;\\alpha (x_t+(1-\\alpha)x_{t-1} + (1-\\alpha)^2x_{t-2} + … + (1-\\alpha)^{t-1}x_1)$$ 可以看到， 越靠近时刻t&#x3D;1（越久远），$x$对$s$影响力以指数级下降。 $\\alpha$越接近1，$s_t$越接近当前时刻的值$x_t$。 在tensorboard的smoothing实现中，上述逻辑正好反过来了，$\\alpha$​变成了$(1-\\alpha)$​，这点需要注意。实现源码如下： 1234567891011121314151617181920212223242526272829303132333435private resmoothDataset(dataset: Plottable.Dataset) &#123; let data = dataset.data(); const smoothingWeight = this.smoothingWeight; // 1st-order IIR low-pass filter to attenuate the higher- // frequency components of the time-series. let last = data.length &gt; 0 ? 0 : NaN; let numAccum = 0; const yValues = data.map((d, i) =&gt; this.yValueAccessor(d, i, dataset)); // See #786. const isConstant = yValues.every((v) =&gt; v == yValues[0]); data.forEach((d, i) =&gt; &#123; const nextVal = yValues[i]; if (isConstant || !Number.isFinite(nextVal)) &#123; d.smoothed = nextVal; &#125; else &#123; last = last * smoothingWeight + (1 - smoothingWeight) * nextVal; //关键逻辑 numAccum++; // The uncorrected moving average is biased towards the initial value. // For example, if initialized with `0`, with smoothingWeight `s`, where // every data point is `c`, after `t` steps the moving average is // // EMA = 0*s^(t) + c*(1 - s)*s^(t-1) + c*(1 - s)*s^(t-2) + ... // = c*(1 - s^t) // // If initialized with `0`, dividing by (1 - s^t) is enough to debias // the moving average. We count the number of finite data points and // divide appropriately before storing the data. let debiasWeight = 1; if (smoothingWeight !== 1) &#123; debiasWeight = 1 - Math.pow(smoothingWeight, numAccum); &#125; d.smoothed = last / debiasWeight; //没看懂debias的逻辑 &#125; &#125;); &#125; 参考： 指数加权平均EWA_ltochange的博客-CSDN博客 (23 封私信 &#x2F; 72 条消息) EMA（指数平均数指标）到底是什么？ - 知乎 tensorflow - What is the mathematics behind the “smoothing” parameter in TensorBoard’s scalar graphs? - Stack Overflow MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} });","tags":[{"name":"smoothing","slug":"smoothing","permalink":"http://aeyoo.net/tags/smoothing/"},{"name":"tensorboard","slug":"tensorboard","permalink":"http://aeyoo.net/tags/tensorboard/"}]},{"title":"如何打包maven项目中的配置文件和依赖","date":"2021-11-25T11:53:52.000Z","path":"2021/11/25/如何打包maven项目中的配置文件和依赖/","text":"今天在开发spark项目中，发现用maven打包spark项目有一定的概率无法把json配置文件打包到jar中，有点疑惑。问了下同事，才知道配置相关文件要放到resources目录下，在打包过程中，maven会把resources下的资源放到jar包的根目录，在项目中就可以按照/xx.json的方式引入文件。 另外，如果maven要打包依赖的话，必须指定scope&#x3D;compile。由于服务器会存在基础的依赖包，所以只需要设置没有的依赖scope&#x3D;compile即可，这也可以极大减小jar包的大小。具体地可以设置基础依赖共用一个scope，其它依赖共用一个scope。","tags":[{"name":"maven","slug":"maven","permalink":"http://aeyoo.net/tags/maven/"},{"name":"打包","slug":"打包","permalink":"http://aeyoo.net/tags/打包/"}]},{"title":"maven深入浅出","date":"2021-11-12T08:12:38.000Z","path":"2021/11/12/maven深入浅出/","text":"","tags":[{"name":"maven","slug":"maven","permalink":"http://aeyoo.net/tags/maven/"}]},{"title":"spark实现随机打散","date":"2021-11-11T08:56:52.000Z","path":"2021/11/11/spark实现随机打散/","text":"在做机器学习研究时，我们通常使用spark生成正负样本，如果是自己通过随机采样的方式生成负样本时，会有一个正负样本union的过程，这时候如果正负样本无法随机打散的话，可能会导致正负样本扎堆，在模型遇到正样本或者负样本之前就已经收敛了，这并不是我们所期望的，所以用spark将样本随机打散是一个非常必要的过程。 repartition是一个重分区的算子，将数据随机打散到各个分区上。repartition通常被用来实现数据的随机打散，但是它并不总是能够完全打散，这和repartition打散逻辑有关。repartition是将数据顺序均匀放在各个Partition当中，与(K,V)对的K无关。而partitionby是根据key进行打散，将key相同的数据放到同一个partition。所以可以使用partitionby将数据打散。实现如下： 1val tfData = tfDataTmp.map(f=&gt;(Random.nextInt(21474830), f)).partitionBy(new HashPartitioner(2000)).map(f=&gt;f._2) 应该看下源码的，记录下。 参考： [spark] repartition与partitionBy的区别_da_kao_la的博客-CSDN博客","tags":[{"name":"spark","slug":"spark","permalink":"http://aeyoo.net/tags/spark/"},{"name":"打散","slug":"打散","permalink":"http://aeyoo.net/tags/打散/"}]},{"title":"《Adversarial Mixture Of Experts with Category Hierarchy Soft Constraint》论文阅读","date":"2021-10-29T12:30:42.000Z","path":"2021/10/29/《Adversarial-Mixture-Of-Experts-with-Category-Hierarchy-Soft-Constraint》论文阅读/","text":"","tags":[{"name":"多任务学习","slug":"多任务学习","permalink":"http://aeyoo.net/tags/多任务学习/"}]},{"title":"在windows无法显示github上的图片","date":"2021-10-28T13:53:48.000Z","path":"2021/10/28/在windows无法显示github上的图片/","text":"github仓库上传了一些图片但是在windows下用各种浏览器都无法查看，报错Failed to load resource: net::ERR_NAME_NOT_RESOLVED，上网查了下好像是github图片服务器被dns污染了，所以查不到，可以通过配置本机hosts文件的方式访问github图片服务器。 打开hosts文件， 1vi C:\\Windows\\System32\\drivers\\etc\\hosts 添加如下内容， 12345678910111213141516171819# GitHub Start 192.30.253.112 Build software better, together 192.30.253.119 gist.github.com151.101.184.133 assets-cdn.github.com151.101.184.133 raw.githubusercontent.com151.101.184.133 gist.githubusercontent.com151.101.184.133 cloud.githubusercontent.com151.101.184.133 camo.githubusercontent.com151.101.184.133 avatars0.githubusercontent.com151.101.184.133 avatars1.githubusercontent.com151.101.184.133 avatars2.githubusercontent.com151.101.184.133 avatars3.githubusercontent.com151.101.184.133 avatars4.githubusercontent.com151.101.184.133 avatars5.githubusercontent.com151.101.184.133 avatars6.githubusercontent.com151.101.184.133 avatars7.githubusercontent.com151.101.184.133 avatars8.githubusercontent.com # GitHub End 参考： 解决浏览器浏览github无法查看图片的问题_菜鸟的救赎之旅的博客-CSDN博客 解决Github网页上图片显示失败的问题 - SegmentFault 思否","tags":[{"name":"github","slug":"github","permalink":"http://aeyoo.net/tags/github/"}]},{"title":"多任务学习系列之PLE","date":"2021-09-06T07:19:42.000Z","path":"2021/09/06/多任务学习系列之PLE/","text":"多任务学习的典型工作有多独立塔DNN，多头DNN，MOE，MMOE等工作，今天介绍的是腾讯的PLE(Progressive Layered Extraction)模型，PLE重点解决了多任务学习中存在的跷跷板现象（seesaw phenomenon）。多任务学习（MTL）并被证明可以通过任务之间的信息共享来提高学习效率。 然而，多个任务经常是松散相关甚至是相互冲突的，这可能导致性能恶化，这种情况称为负迁移 。 在论文中提到，通过在真实世界的大规模视频推荐系统和公共基准数据集上的大量实验，发现现有的 MTL 模型经常以牺牲其他任务的性能为代价来改进某些任务，当任务相关性很复杂并且有时依赖于样本时，即与相应的单任务模型相比，多个任务无法同时改进，论文中称之为跷跷板现象。 为了解决跷跷板和负迁移的现象，论文提出了一种共享结构设计的渐进式分层提取（PLE）模型。其包含两部分， 一部分是一种显式区分共享专家塔和特定任务专家塔的门控 (CGC) 模型，另一部分是由单层CGC结构扩展到多层的PLE模型。 1 Customized Gate Control (CGC) Model为了实现和单任务相似的性能，论文显式分离了任务共享专家部分和任务独享专家部分，并提出了CGC（如下图所示）。顶部是一些和任务相关的多层塔网络，底部是一些专家模块，每个专家模块由多个专家网络组成。专家模块分为两类，一类是任务共享的专家模块，负责学习任务的共享模式，一类是任务独享的专家模块，负责学习任务的独享模式。每个塔网络从所有专家模块（共享专家模块和独享专家模块）学习知识。 在CGC中，所有专家模块的输出通过一个门控网络融合。门控网络是一个单层前馈网络，使用softmax作为激活函数。input作为选择器（selector）计算所有选择向量（the selected vectors）的加权和（ input as the selector to calculate the weighted sum of the selected vectors），这句话有点绕，其实就是基于input生成选择概率，然后基于选择概率融合所有专家模块的输出，所以input被称作selector；selected vectors就是专家模块的输出，它们基于选择概率被选择了。任务k的门控网络形式化如下： 上面的公式其实很简单，$w^k(x)$​就是门控网络的参数矩阵，$S^k(x)$​是所有专家模块的输出，$g^k(x)$是门控网络的输出，任务k的输出就是$y^k(x)&#x3D;t^k(g^k(x))$​，$t^k(x)$是任务k的塔网络。 **和MMOE相比，CGC增加了任务的独享专家网络，使其更聚焦于学习任务的独享模式**。 2 Progressive Layered ExtractionPLE将单层CGC结构扩展到了多层，用于学习越来越深的语义表示。那么在多层CGC中，独享专家模块和共享专家模块怎么融合上一层网络的输出是一个需要考虑的问题。为此，论文提出了多级提取网络，其结构类似于CGC，但是定义了各个专家模块更新的逻辑。多级提取网络的结构如下图所示。 在多级提取网络中，**任务k的独享专家模块融合了上一层网络中任务k的独享专家模块和共享专家模块，而共享专家模块则融合了上一层所有的专家模块**。所以在多级提取网络中有两个门控，for独享专家模块和 for共享专家模块。所以在PLE中，不同任务的参数并不是像CGC中完全分离的，而是在顶层网络中分离的。在高层提取网络中的门控网络将低层提取网络中门控的融合结果作为选择器，而不是input。论文给出的理由是it may provide better information for selecting abstract knowledge extracted in higher-level experts。 PLE中权重函数、选择矩阵和门控网络的计算与CGC中的相同。 具体来说，PLE的第j个提取网络中任务k的门控网络的公式为： **和MMOE相比，PLE增加了不同的Expert之间交互**。 3 loss设计loss好像没有什么特别的地方。 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} });","tags":[{"name":"多任务学习","slug":"多任务学习","permalink":"http://aeyoo.net/tags/多任务学习/"},{"name":"PLE","slug":"PLE","permalink":"http://aeyoo.net/tags/PLE/"}]},{"title":"多标签分类问题的评估","date":"2021-09-02T08:50:07.000Z","path":"2021/09/02/多标签分类问题的评估/","text":"机器学习中有一类问题叫做多标签分类(multi-label)，其和多分类(multi-class)问题不同。多分类问题是将一个样本x分到某一个类别$y_i$，而多标签分类问题是将一个样本x分到某些类别$y_i$, .., $y_j$等，也就是说多分类问题的类别之间是互斥的，所有类别的概率和为1。而多标签分类问题的类别之间不互斥，所有类别的概率和不为1，多标签分类问题可以理解为n个二分类问题。 最近在做一个多标签分类问题的工作，涉及到多标签分类问题如何评估效果，这里进行一些总结。 首先看下**多分类问题的评估**，知乎用户王晋东不在家已经讲的非常好了。 对于**多标签分类的评估**，上文已经说到，其可以看做是n个二分类问题，那么我们可以通过计算每个类别下的auc，综合起来对模型进行评估，这个其实很容易理解。但是在实现的时候需要注意几个问题： tf2已经提供了多标签分类计算auc的函数，但是其综合了所有类别的auc，计算得到一个平均auc。如下所示，只需要指定multi_label&#x3D;True就可以计算多标签分类的平均auc了。 123456tf.keras.metrics.AUC( num_thresholds=200, curve='ROC', summation_method='interpolation', name=None, dtype=None, thresholds=None, multi_label=False, num_labels=None, label_weights=None, from_logits=False) 虽然tf2提供了多标签分类计算auc的函数，但是其计算的是平均auc，更多情况下我们希望看下每个类别的auc情况。所以还需要自己实现下。思路就是分别拎出各个类别的样本计算auc，计算某个类别auc的时候需要剔除其它类别的样本。同时因为tf提供的auc计算函数计算的是累积auc(就是计算auc的中间变量：真正例&#x2F;假正例&#x2F;真负例&#x2F;假负例等本地变量值会累积)，所以需要对每个类别的auc确定一个变量作用域，eg with tf.compat.v1.variable_scope(&#39;class_&#39; + str(class_id)):，避免计算出的各个类别auc之间相互干扰。分析源码得知，tf在计算真正例&#x2F;假正例&#x2F;真负例&#x2F;假负例时，是通过metric_variable()函数定义了变量真正例，同时metric_variable()的实现也是依赖于variable_scope.variable，所以通过tf.compat.v1.variable_scope()可以避免各个类别的auc相互干扰。 1234567891011def metric_variable(shape, dtype, validate_shape=True, name=None): return variable_scope.variable( lambda: array_ops.zeros(shape, dtype), trainable=False, collections=[ ops.GraphKeys.LOCAL_VARIABLES, ops.GraphKeys.METRIC_VARIABLES ], validate_shape=validate_shape, synchronization=variable_scope.VariableSynchronization.ON_READ, aggregation=variable_scope.VariableAggregation.SUM, name=name) 上面也说了tf计算的是累积auc，所以需要区分自己想要的是batch auc还是累积auc。一个建议是，可以考虑在训练的时候计算batch_auc，观察auc的实时变化情况；预测的时候计算累积auc，观察整体效果。这个可以通过tf.control_dependencies()控制。代码如下： 123456789if is_training: tf.compat.v1.add_to_collection( tf.compat.v1.GraphKeys.UPDATE_OPS, tf.compat.v1.local_variables_initializer())update_ops = tf.compat.v1.get_collection( tf.compat.v1.GraphKeys.UPDATE_OPS)with tf.control_dependencies(update_ops), tf.compat.v1.variable_scope( \"train\", reuse=tf.compat.v1.AUTO_REUSE): train_op = optimizer.minimize(self.losses, global_step=global_step) tf.compat.v1.metrics.auc()函数的返回值有两个auc_value, update_op。需要先执行update_op，再执行auc_value。因为auc_value依赖于update_op先执行才会被更新。参见代码计算混淆矩阵的实现： 12345678910111213141516171819def _confusion_matrix_at_thresholds(labels, predictions, thresholds, weights=None, includes=None): ... if 'fp' in includes: false_p = metric_variable( [num_thresholds], dtypes.float32, name='false_positives') is_false_positive = math_ops.cast( math_ops.logical_and(label_is_neg, pred_is_pos), dtypes.float32) if weights_tiled is not None: is_false_positive *= weights_tiled update_ops['fp'] = state_ops.assign_add(false_p, math_ops.reduce_sum( is_false_positive, 1)) values['fp'] = false_p return values, update_ops 可以看到上述代码中，只有update_ops[&#39;fp&#39;]先被执行，false_p才会被更新。其实也可以直接拿update_ops的值作为当前数据更新之后的auc。 参考： 对多分类数据的模型比较选择，应该参考什么指标？ MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} });","tags":[{"name":"auc","slug":"auc","permalink":"http://aeyoo.net/tags/auc/"},{"name":"评估指标","slug":"评估指标","permalink":"http://aeyoo.net/tags/评估指标/"},{"name":"多标签分类","slug":"多标签分类","permalink":"http://aeyoo.net/tags/多标签分类/"}]},{"title":"keras.metrics.AUC源码详解","date":"2021-08-07T06:23:51.000Z","path":"2021/08/07/keras-metrics-AUC源码详解/","text":"TF2提供了多标签分类问题的auc计算方法，但是计算结果和预期不同，所以剖析下源码。 发现多标签分类有点问题。 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} });","tags":[{"name":"auc","slug":"auc","permalink":"http://aeyoo.net/tags/auc/"},{"name":"tf","slug":"tf","permalink":"http://aeyoo.net/tags/tf/"}]},{"title":"windows下如何安装torch-geometric","date":"2021-02-23T06:32:05.000Z","path":"2021/02/23/windows下如何安装torch-geometric/","text":"最近要看下IGMC的源码，发现代码中引用了torch-geometric库，所以需要安装下pytorch环境和对应的库。有点点坑，记录下。环境配置需要和作者保持一致，不然会有一些问题，作者的环境是 Python 3.8.1 + PyTorch 1.4.0 + PyTorch_Geometric 1.4.2。 1 创建虚拟环境windows下安装各种深度学习环境通常是通过anaconda实现的，可以先下载个anaconda安装，我下载的是anaconda3。 安装好之后，使用conda命令创建一个虚拟环境，我们之后所有pytorch相关操作都在这个虚拟环境进行，这样可以防止对现有环境造成破坏。conda这个命令和virtualenv命令是类似的。 创建python3.6的虚拟环境（环境路径：anaconda安装目录的envs目录下）： 1conda create --name python36 python=3.6 激活上述环境： 1activate python36 激活环境后就可以进行其它操作了。 查看现在的所有环境： 1conda info --env # 前面有‘*’星号的是当前环境 删除环境： 12conda deactivate # 先退出环境conda remove --name [env_name] --all #再删除环境 这样携带python3.6的虚拟环境就做好了。 2 安装pytorchpytorch-geometric的官方安装教程说需要安装至少pytorch1.4.0之上的版本，所以这里我们安装pytorch1.5，选择的cuda版本是10.2（有些版本在安装pytorch-geometric必要包的时候会报错，例如torch-scatter==latest+cu98会报错，因为没有cuda9.8这个版本）。在Windows下，使用conda安装pytorch1.5命令如下（pytorch和cuda版本对应关系列表）： 12# CUDA 10.2conda install pytorch==1.5.0 torchvision==0.6.0 cudatoolkit=10.2 -c pytorch 安装完成后，可以使用命令查看下pytorch是否安装成功。 12345python -c \"import torch; print(torch.__version__)\"&gt;&gt;&gt; 1.5.0python -c \"import torch; print(torch.version.cuda)\"&gt;&gt;&gt; 10.2 如果出现对应版本号则说明安装成功。 3 安装pytorch-geometric根据pytorch-geometric的官方安装教程安装是无法成功的，会提出找不到满足要求的包，网上找到一种方法（参考用户duanyuchen的【踩坑】Linux下配置torch-geometric），命令如下： 12345pip install torch-scatter==latest+$&#123;CUDA&#125; -f https://pytorch-geometric.com/whl/torch-$&#123;PyTorch&#125;.htmlpip install torch-sparse==latest+$&#123;CUDA&#125; -f https://pytorch-geometric.com/whl/torch-$&#123;PyTorch&#125;.htmlpip install torch-cluster==latest+$&#123;CUDA&#125; -f https://pytorch-geometric.com/whl/torch-$&#123;PyTorch&#125;.htmlpip install torch-spline-conv==latest+$&#123;CUDA&#125; -f https://pytorch-geometric.com/whl/torch-$&#123;PyTorch&#125;.htmlpip install torch-geometric 将上面命令中的${CUDA}和${PyTorch}替换成对应的版本号就好了，例如我们的${CUDA}值是cu102，${PyTorch}值是1.5.0。命令如下： 12345pip install torch-scatter==latest+cu102 -f https://pytorch-geometric.com/whl/torch-1.5.0.htmlpip install torch-sparse==latest+cu102 -f https://pytorch-geometric.com/whl/torch-1.5.0.htmlpip install torch-cluster==latest+cu102 -f https://pytorch-geometric.com/whl/torch-1.5.0.htmlpip install torch-spline-conv==latest+cu102 -f https://pytorch-geometric.com/whl/torch-1.5.0.htmlpip install torch-geometric==1.4.2 #这里必须指定是1.4.2版本 执行上述命令可能报错版本号无效的错误,，例如Invalid version: &#39;latest+cu102，这是因为pip的版本太高了，回退到19.3.0就可以了[2]。pip版本回退命令： 1python -m pip install pip==版本（如19.3.0) 这样pytorch-geometric安装完成了，最后在pycharm中设置python环境为新建的虚拟环境就可以了。 4 注意 torch-geometric的版本必须是1.4.2，更高版本可能会报错：torch.nn.modules.module.ModuleAttributeError: &#39;RGCNConv&#39; object has no attribute &#39;att&#39;，因为GCNConv是引用其它的包，这个包在1.4.2有att属性，更高版本删除了。 参考文章[1] 【踩坑】Linux下配置torch-geometric [2] Error installing dependency PyTorch Scatter from wheel","tags":[{"name":"torch","slug":"torch","permalink":"http://aeyoo.net/tags/torch/"},{"name":"torch-geometric","slug":"torch-geometric","permalink":"http://aeyoo.net/tags/torch-geometric/"}]},{"title":"《Inductive Matrix Conpletion Based On Graph Neural Network》论文阅读","date":"2021-02-14T08:52:16.000Z","path":"2021/02/14/《Inductive-Matrix-Conpletion-Based-On-Graph-Neural-Networks》论文阅读/","text":"论文提出了一种不使用辅助信息的归纳(inductive)矩阵补全模型。通过将评分矩阵分解为行（用户）和列（物品）的低维隐向量的乘积，现有的大多数矩阵补全方法都是可转导(transductive)的，因为学习的向量无法泛化为看不见的行&#x2F;列或新矩阵。为了使矩阵补全具有归纳性，之前大多数的工作都使用内容（辅助信息）进行预测，例如用户的年龄或电影类型。但是，内容并不总是高质量的，并且可能难以提取。在极端的情况下，除了要补全的矩阵之外没有其他辅助信息可用，这时我们就无法学习归纳矩阵补全模型。本文提出了一种基于归纳图的矩阵补全（IGMC）模型来解决此问题。 IGMC基于一跳子图训练图神经网络（GNN），并将这些子图映射到其对应的评分，一跳子图基于评分矩阵生成的用户-物品pair对生成。IGMC相比于最新的transductive基线实现了更好的性能。此外，IGMC是归纳性的，它可以推广到训练时未看到的用户&#x2F;物品（假设二者存在相互作用），甚至可以推广到新任务上。我们的迁移学习实验表明，从MovieLens数据集中训练出的模型可以直接用于预测豆瓣电影收视率，并且性能出奇地好。我们的工作表明：1）可以在不使用辅助信息的情况下训练归纳矩阵补全模型，同时获得与最新的transductive方法相似或更好的性能； 2）用户-物品pair对周围的局部图模式是该用户对该物品评分的有效预测指标；和3）建模推荐系统时可能不需要长期依赖。 先说下inductive学习和transductive学习的区别 ： inductive学习，指的是训练数据和测试数据互斥的学习。模型从训练数据学习规律，然后在测试数据预测，训练数据和测试数据互斥。这样训练得到的模型泛化能力更强。 transductive学习，指的是训练数据和测试数据有重叠的学习。模型训练时会基于训练数据和测试数据的部分信息（不包括label信息）进行联合建模，然后在测试数据上预测label，例如在聚类学习中，分析X的分布然后预测Y，这点可以参考知乎用户望尼玛的回答《如何理解 inductive learning 与 transductive learning?》。 1 构造二部图定义图G为无向二部图，其来源于评分矩阵R。在图G中，节点代表用户（u表示，代表评分矩阵中的一行）或者物品（v表示，代表评分矩阵中的一列），用户和物品之间存在边，但是用户之间和物品之间不能存在边。每条边的值r&#x3D;$R_{u,v}$代表该用户对该物品的评分，定义$R$代表评分值的集合，例如在MovieLenszhong ,R&#x3D;{1，2，3，4，5}。定义$N_{r(u)}$为节点u的以r类型的边连接的邻居。 2 提取子图IGMC的第一部分是提取封闭子图。对于每个观测到的评分值$R_{u,v}$，从G中提取一个从u到v的h跳封闭子图，算法1描述了提取h跳封闭子图的BFS算法。然后把这些子图喂到GNN中，然后回归其评分。对于测试集中的每个(u-v) pair对，同样从G中提取h跳封闭子图，然后使用训练得到的GNN模型预测其评分。需要注意的是，在提取了(u,v)的训练封闭子图之后，需要将(u,v)的边移除，因为目标是预测。 3 节点学习IGMC第二部分是节点标记。因为封闭子图提取出来之后要喂给GNN，GNN无法区分不同的节点，所以需要对节点进行标记，1是要区分目标节点和上下文节点（目标节点指的是我们将要预测的用户对物品的评分）；2是要区分用户节点和物品节点。为此论文提出了一种节点标记方法：首先定义目标用户和目标物品的标签为0和1，对i跳的上下文用户标记为2i，对i跳的上下文物品标记为2i+1。然后将这些标记转化为one-hot向量，将其节点的初始特征输入GNN。这里同时也区分了不同阶的节点，因为不同阶的节点对目标节点的贡献程度不同。 需要注意的是，虽然我们已经证明了上述方法具有很好的性能，但它并不是唯一的节点标记方法。这些节点标签的one-hot编码将被用于子图节点特征的初始化，然后喂给GNN。节点标签完全依赖于封闭子图，和全局二部图无关。给定一个封闭子图，即使它的节点来自于不同的二部图，我们也可以预测其评分，因为IGMC完全依赖于局部封闭子图的图模式，而没有利用任何二部图的全局信息。节点标签也不同于在GC-MC中使用全局节点ID，Using one-hot encoding of global IDs is essentially transforming the first message passing layer’s parameters into latent node embedding associated with each particular ID (equivalent to an embedding lookup table). Such a model cannot generalize to nodes whose IDs are out of range, thus is transductive. 4 图神经网络架构IGMC的第三部分是训练图神经网络模型预测封闭子图的评分。在以前基于节点的方法中，例如GC-MC，一个节点级的GNN应用于整个二部图以提取节点向量。然后，节点u和v的向量被输入到内积或者双线性算子中（bilinear operator），以重建(u,v)评分。而IGMC是将图级别的GNN应用于(u, v)的封闭子图，并将子图映射到评分。因此，IGMC的GNN有两个组件：（1）消息传递层，为子图中的每个节点提取一个特征向量；（2）一个池化层，抽象这些节点特征的子图表达。 为了从不同的边类型中学习丰富的图模式，这里采用了R-GCN(relational graph convolutional operator)算子作为GNN的消息传递层，形式如下： 其中$X^l_i$表示节点i在$l$层的特征向量，$W_0^l$和 $W_r^l|r \\in R$是可学习的参数矩阵。由于连接邻居j到节点i的边r是由不同的参数矩阵$W^l_r$，我们可以从边类型中学习丰富的图模式，例如目标用户对物品的平均评分，目标物品得到的平均分，两个目标节点通过哪条路径连接，等等。 这里我们简要介绍下RGCN。RGCN的目的是解决GCN忽略不同边关系对节点的影响的问题，其主要形式如下： $N_i^r$表示节点i的关系为r的邻居节点集合，$c_{i,r}$是一个正则化常量， 其中$c_{i,r}$的取值是$|N_i^r|$。$W_r^{(l)}$是线性转化函数，将同类型边的邻居节点，使用用一个参数矩阵$W_r^{(l)}$进行转化。此公式和GCN不同的是，不同边类型所连接的邻居节点，进行一个线性转化，$W_r^{(l)}$的个数也就是边类型的个数，论文中称为relation-specific。这里还可以设置更加灵活的函数，例如多层神经网络[1]。 我们在两个层之间堆叠具有tanh激活的L个消息传递层。（follow Zhang等人，2018； Xu等人，2018的工作），来自不同层的节点i的特征向量被拼接起来作为其最终表达形式$h_i$： 接下来，我们对节点表达进行池化得到一个图级别的特征向量。池化方式有多种，例如求和，均值，SortPooling（Zhang et al., 2018），DiffPooling (Ying et al., 2018b)。在论文中使用了一个和上述不同的池化层，其拼接目标用户和物品的最终表达作为图表达。 $h_u$表示目标用户的最终表达，$h_v$是目标物品的最终表达。之所以要这么做（拼接目标用户和物品的最终表达作为图表达），是因为与其它上下文相比，这两个节点更重要，尽管这样做很简单，但是我们验证了在矩阵补全任务中，这种方式的性能明显优于其它池化层。 在得到最终的图表达之后，使用MLP输出预测评分： W和w是MLP的参数，$\\hat{r}$是标量评分，$\\sigma$是激活函数，论文中使用了ReLU。 5 模型训练损失函数，最小化预测得分和真实得分的均方误差(MSE): $R_{u,v}$表示真实得分，$\\hat{R}_{u,v}$是预测得分。$\\Omega$是0&#x2F;1掩码矩阵，表示评分矩阵R中的可观测条目。 相邻评分正则化，GNN中使用的R-GCN层，（1）对于不同的评级类型具有不同的参数$W_r$。 一个缺点是它没有考虑到评分值的大小。 例如，MovieLens中的4级和5级都表示用户喜欢该电影，而1级则表明用户不喜欢该电影。 理想情况下，我们希望我们的模型意识到这样一个事实，即4评分比1更接近5。 但是，在R-GCN中，评分值1，4和5仅被视为三种独立的边缘类型，评分值的大小和顺序信息完全丢失。 为了解决这个问题，论文提出了一种相邻的评分正则化（ARR）技术，该技术使得相近的评分具有相似的参数矩阵。 假设R中的评分具有$r_1$，$r_2$，…$r|R|$的顺序， 这表明用户对商品的偏好越来越高。 然后，ARR正则化器为： 其中${\\lVert \\cdot \\lVert}_F$表示矩阵的Frobenius范数。 上述正则化器可抑制相近评分参数矩阵之间的差异过大，这不仅考虑了评分顺序，而且还通过迁移相近评分的知识来帮助优化那些不经常使用的评分。 最终损失函数由下式给出： $\\lambda$权衡了MSE损失和ARR调整器的重要性。 还有很多方法可以对评分值的大小和顺序进行建模，这些方法留待以后的工作。 参考文献[1] [论文笔记] RGCN ：GCN 在多边类型的应用 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} });","tags":[{"name":"图网络","slug":"图网络","permalink":"http://aeyoo.net/tags/图网络/"},{"name":"矩阵补全","slug":"矩阵补全","permalink":"http://aeyoo.net/tags/矩阵补全/"},{"name":"推荐","slug":"推荐","permalink":"http://aeyoo.net/tags/推荐/"}]},{"title":"协同过滤","date":"2021-02-11T10:00:18.000Z","path":"2021/02/11/协同过滤/","text":"协同过滤（collaborative filtering）是一种在推荐系统中广泛使用的技术。该技术通过分析用户或者物品之间的相似性（”协同”），来预测用户可能感兴趣的物品并推荐给用户[1]。所以，协同过滤本质上是一类技术的统称。在大多数资料中，协同过滤技术分为两类：基于存量（Memory - based）的协同过滤和基于模型（Model- based）的协同过滤。 1 协同过滤的分类一个推荐问题可以分为评分预测和TopN推荐[2]。评分预测就是预测用户和物品之间的偏好度，TopN推荐就是基于偏好度对物品数量进行截断然后推荐给用户。评分预测问题可以用下图[3]来描述。 在上图中，纵轴代表用户，横轴代表物品，每个格子代表了该用户对该物品的偏好度。上图中的问号表示该用户对该物品没有行为。在推荐系统中，用户对物品的行为通常是非常稀疏的，稀疏度几乎可以达到90%。所以，评分预测问题可以理解为一个矩阵补全问题，即预测问号处的实际分数。而协同过滤技术也是围绕该问题衍生而来的，协同过滤技术的分类如下： 基于存量（Memory - based）的协同过滤 基于用户（User-based）的协同过滤 基于物品（Item-based）的协同过滤 基于模型（Model - based）的协同过滤 个人理解，Memory - based和Model - based的区别是记忆和泛化的区别。Memory - based侧重于从历史行为中捕获一些关联规则或规律进行推荐，其存在的问题是用户对物品的行为比较稀疏；Model- based解决数据稀疏问题，其通过模型的方式对用户-物品的评分矩阵补全未知的评分，典型的有MF、隐语义模型、贝叶斯网络等。 User-based基于一个假设，兴趣相似的用户其偏好的物品也是相似的。当一个用户a需要个性化推荐的时候，找到和这个用户a相似的用户群体，看看他们喜欢什么商品，然后将这些商品推荐给a，这就是User-based。Item-based是基于用户行为挖掘出具有强相关性的商品对(a, b)，然后基于用户的历史行为(a)和商品对做推荐（推荐b）。 2 基于模型（Model - based）的协同过滤个人觉得MF是最能代表Model - based的模型。MF的思路很简单，知乎用户推荐系统玩家介绍的很好了，这里就直接贴过来了。 参考文献[1] 协同过滤 维基百科 [2] 推荐系统之矩阵分解家族 [3] 推荐系统玩家 之 推荐系统入门——推荐系统的发展历程（上）","tags":[{"name":"协同过滤","slug":"协同过滤","permalink":"http://aeyoo.net/tags/协同过滤/"}]},{"title":"2020年回忆录","date":"2020-12-25T12:40:53.000Z","path":"2020/12/25/2020年回忆录/","text":"2020年只剩下6天了，刚刚晚上和组长交流完工作后，继续开始搞可视化项目，分心之余想起来了大学喜欢看的一个短视频《80后在路上》，于是又打开边听边工作，&#x3D;&#x3D;。虽然早已没有了当年的激情，但是仍然希望做出一些有意义的事情来。 最近磊哥的一席话让我感触挺深。 领导力； 事事毕； 思考； 不要心浮气躁； 逻辑思维。 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} });","tags":[{"name":"思考","slug":"思考","permalink":"http://aeyoo.net/tags/思考/"}]},{"title":"leetcode 10 正则表达式匹配","date":"2020-11-26T13:19:21.000Z","path":"2020/11/26/leetcode-10-正则表达式匹配/","text":"给你一个字符串 s 和一个字符规律 p，请你来实现一个支持 ‘.’ 和 ‘*’ 的正则表达式匹配。 ‘.’ 匹配任意单个字符‘*’ 匹配零个或多个前面的那一个元素所谓匹配，是要涵盖 整个 字符串 s的，而不是部分字符串。 示例 1： 123输入：s = \"aa\" p = \"a\"输出：false解释：\"a\" 无法匹配 \"aa\" 整个字符串。 示例 2: 123输入：s = \"aa\" p = \"a*\"输出：true解释：因为 '*' 代表可以匹配零个或多个前面的那一个元素, 在这里前面的元素就是 'a'。因此，字符串 \"aa\" 可被视为 'a' 重复了一次。 示例 3： 123输入：s = \"ab\" p = \".*\"输出：true解释：\".*\" 表示可匹配零个或多个（'*'）任意字符（'.'）。 示例 4： 123输入：s = \"aab\" p = \"c*a*b\"输出：true解释：因为 '*' 表示零个或多个，这里 'c' 为 0 个, 'a' 被重复一次。因此可以匹配字符串 \"aab\"。 示例 5： 12输入：s = \"mississippi\" p = \"mis*is*p*.\"输出：false 提示： 123450 &lt;= s.length &lt;= 200 &lt;= p.length &lt;= 30s 可能为空，且只包含从 a-z 的小写字母。p 可能为空，且只包含从 a-z 的小写字母，以及字符 . 和 *。保证每次出现字符 * 时，前面都匹配到有效的字符 这道理挺有意思。一开始的思路其实和解法相近，但是有一个地方想错了，就是 .*的*是可以匹配任意多个’.‘，而不是匹配一个常量字符。脑回路蠢的可以。下面说下思路： 首先判断s[i]和p[j]是否相等。如果相等的话，判断p的下一个字符是否是星号。如果是星号，那么s第i个位之前的字符已经匹配成功，那么就判断s[i+1]和p是否匹配，这里为啥是p[j:]而不是p[j+1:]呢，因为*可以匹配前面0个字符呀，所以p[j+1:]用于递归才是合理的。如果不是星号，那么就判断s[i+1]和p[j+1]是否匹配； 如果s[i]和p[j]不相等的话，那么判断p[j+1]是否是星号，如果是星号，那么判断s[i]和p[j+2]是否匹配；如果不是星号，那么就肯定不匹配了。 判断递归终止条件，这往往是最难的一步，可以根据逻辑推导下； 注意substr的时候不要越界。 此外还需要注意的是，下面代码中的s.substr(1)是不会错的！所以不用考虑越界问题。 代码： 1234567891011121314151617181920#include&lt;iostream&gt;using namespace std;bool match(string s, string p)&#123; if(s.length()==0) return p.length()==0; auto isEq =s.length()&gt;0 &amp;&amp; (s[0]==p[0] || p[0]=='.'); if(p.length()&gt;=2 &amp;&amp; p[1]=='*')&#123; return (isEq &amp;&amp; match(s.substr(1),p) || match(s,p.substr(2))); &#125;else&#123; return isEq &amp;&amp; match(s.substr(1),p.substr(1)); &#125;&#125;int main()&#123; cout&lt;&lt;match(\"a\",\".\")&lt;&lt;endl; string s = \"a\"; cout&lt;&lt;s.substr(1)&lt;&lt;endl; return 0;&#125; 参考： allen在该题下的题解，Allen主页。","tags":[{"name":"正则表达式","slug":"正则表达式","permalink":"http://aeyoo.net/tags/正则表达式/"}]},{"title":"transformer是什么","date":"2020-11-17T11:27:58.000Z","path":"2020/11/17/transformer是什么/","text":"transformer是近些年在NLP领域火起来的一个语言模型，google bert的出现更是将其推到了顶峰。所谓语言模型就是预测每个句子在语言中出现的概率。简单地说，transformer是基于attention和encode-decode的产物。transformer出自2017年的一篇论文《Attention Is All You Need》，最初是用来提高机器翻译的效率，后来逐渐演化为各类预训练模型（bert）的基础。基于transformser可以构建各种各样的NLP任务，只需要修改下训练样本，并进行微调就可以了。 transformer的细节可以参考李理的博客《Transformer图解》，讲的非常细致。transformer的模型结构如下： 如上图所示，其实transformer也是在encode-decode框架下做的，与此前不同的是，transformer提出了一种self-attention机制（自注意力机制），怎么理解呢？就是说之前的attention大多使用在seq2seq任务中，例如在机器翻译中，attention作用在源句子token（token就指的是单词或词语）和目标句子token之间，但是transformer的self-attention作用在源句子的token之间。 attention第一次提出在2014年的一篇论文《Neural Machine Translation by Jointly Learning to Align and Translate》，个人感觉这篇工作做的特别棒。这篇论文的核心如下： 意思就是基础的encode-decode框架使用一个固定长度的向量表达源句子的所有语义信息，这种做法造成了encode-decode框架的性能瓶颈，因为源句子中前面的词容易被后面词的信息覆盖，另外单一个固定长度的向量也无法充分表达一个句子的语义。论文提出了一种attention机制，自动找到在源句子中和预测目标词相关的词，基于这些词对目标词进行预测。论文很简单，不过如果看英文吃力的话也有中文版的：Microstrong的博客《深度学习中的注意力机制》。attention的逻辑如下所示（博客中的图4就是下图2）： 那么transformer做了哪些核心工作呢？个人总结有如下几点： 提出了self-attention机制，使得效果提升易于并行。在transformer中有两个注意力，一个是self-attention，在encoder和decoder中都有使用；一个是普通的attention，只在decoder中被使用，用来在每个decoder中self-attention的输出和encoder最后一层输出建立联系。 引入了位置编码； encode和decode具有不同的结构，decode多了一个普通的attention，使得encode的最后一层输出可以作用于decode的各个层，同1； 提出了层归一化的概念，本质上也是为了加速梯度求解吧，我觉得层归一化没有什么物理含义。 需要注意的是： 使用mask。因为使用transformer进行预测的时候，decoder是串行地一个时间步一个时间步进行预测的，不能使用未来信息，所以在训练decoder的时候也要避免使用未来信息，这时候就需要使用mask。【参考 变压器解码器掩模篇】不过在transformer有两种mask，一种是为了解决上述问题的，叫做Sequence mask；另一种是为了解决句子长短不一的问题的，叫做padding mask。具体可以参考《Transformer各层网络结构详解！面试必备！(附代码实现)》 decoder的第一个时间步的输入是一个特殊的token，这个token主要目的是占位。目标序列开始的token(如)，也可能是源序列结尾的token(如)，也可能是其它视任务而定的输入。等等，不同源码中可能有微小的差异，其目标则是预测下一个位置的单词(token)是什么，对应到time step为1时，则是预测目标序列的第一个单词(token)是什么，以此类推。 在decoder中有一个普通的attention，即上图中的Multi-Head Attention，这个attention是将encoder的最后一层输出和当前decoder的第一个子模块（即上图中的Masked Multi-Head Attention）进行关联，Q就是encoder的最后一层输出，K，V就是Masked Multi-Head Attention的输出，使得当前的decoder对源序列的不同部分给予不同权重的注意力。","tags":[{"name":"transformer","slug":"transformer","permalink":"http://aeyoo.net/tags/transformer/"},{"name":"nlp","slug":"nlp","permalink":"http://aeyoo.net/tags/nlp/"}]},{"title":"leetcode 9 回文数","date":"2020-10-27T01:35:45.000Z","path":"2020/10/27/leetcode-9-回文数/","text":"题目有点水，先得到要求商求余的除数就很简单了。但是没判定&lt;0，wa；求余wa。 判断一个整数是否是回文数。回文数是指正序（从左向右）和倒序（从右向左）读都是一样的整数。 1234567891011121314示例 1:输入: 121输出: true示例 2:输入: -121输出: false解释: 从左向右读, 为 -121 。 从右向左读, 为 121- 。因此它不是一个回文数。示例 3:输入: 10输出: false解释: 从右向左读, 为 01 。因此它不是一个回文数。 代码： 123456789101112131415161718192021bool isPalindrome(int x) &#123; if(x&lt;0) return false; int len = 1; int tmp =x; while((tmp=tmp/10)&gt;0)&#123; len = len*10; &#125; while(x)&#123; int left = x/len; int right = x%10; if(left!=right)&#123; return false; &#125; x = x%len; x = x/10; len = len/100; &#125; return true;&#125;","tags":[]},{"title":"leetcode 8 字符串转换整数 (atoi)","date":"2020-10-26T16:38:48.000Z","path":"2020/10/27/leetcode-8-字符串转换整数-atoi/","text":"这道题是一道水题，但是没有注意到一个细节：假如第一个非空格字符不是一个有效整数字符的话是无效转换返回0，所以wa了一发，mmp。 请你来实现一个 atoi 函数，使其能将字符串转换成整数。 首先，该函数会根据需要丢弃无用的开头空格字符，直到寻找到第一个非空格的字符为止。接下来的转化规则如下： 如果第一个非空字符为正或者负号时，则将该符号与之后面尽可能多的连续数字字符组合起来，形成一个有符号整数。假如第一个非空字符是数字，则直接将其与之后连续的数字字符组合起来，形成一个整数。该字符串在有效的整数部分之后也可能会存在多余的字符，那么这些字符可以被忽略，它们对函数不应该造成影响。注意：假如该字符串中的第一个非空格字符不是一个有效整数字符、字符串为空或字符串仅包含空白字符时，则你的函数不需要进行转换，即无法进行有效转换。 在任何情况下，若函数不能进行有效的转换时，请返回 0 。 提示： 本题中的空白字符只包括空格字符 ‘ ‘ 。假设我们的环境只能存储 32 位大小的有符号整数，那么其数值范围为 [−231, 231 − 1]。如果数值超过这个范围，请返回 INT_MAX (231 − 1) 或 INT_MIN (−231) 。 123456789101112131415161718192021222324252627示例 1:输入: \"42\"输出: 42示例 2:输入: \" -42\"输出: -42解释: 第一个非空白字符为 '-', 它是一个负号。 我们尽可能将负号与后面所有连续出现的数字组合起来，最后得到 -42 。示例 3:输入: \"4193 with words\"输出: 4193解释: 转换截止于数字 '3' ，因为它的下一个字符不为数字。示例 4:输入: \"words and 987\"输出: 0解释: 第一个非空字符是 'w', 但它不是数字或正、负号。 因此无法执行有效的转换。示例 5:输入: \"-91283472332\"输出: -2147483648解释: 数字 \"-91283472332\" 超过 32 位有符号整数范围。 因此返回 INT_MIN (−231) 。 代码： 123456789101112131415161718192021222324252627long res=0;if(s.length()==0)&#123; return res;&#125;int i=0;while(s[i]==' ') i++;int factor = 1;if(s[i]=='+' || s[i]=='-')&#123; if(s[i]=='-') factor = -1; i++;&#125;for(;i&lt;s.length();i++)&#123; if(s[i]&gt;='0' &amp;&amp; s[i]&lt;='9') &#123; res = res*10 + (s[i]-'0')*factor; if(res&lt;INT_MIN || res&gt;INT_MAX)&#123; res = factor &gt; 0 ? INT_MAX : INT_MIN; break; &#125; &#125;else&#123; break; &#125;&#125;return res;&#125;","tags":[]},{"title":"leetcode 6 Z 字形变换","date":"2020-10-24T15:39:50.000Z","path":"2020/10/24/leetcode-6-Z-字形变换/","text":"这是一道思考题，比较简单，但是我没有想明白为啥程序输出和预期一致判定为wa… 将一个给定字符串根据给定的行数，以从上往下、从左到右进行 Z 字形排列。 比如输入字符串为 “LEETCODEISHIRING” 行数为 3 时，排列如下： L C I RE T O E S I I GE D H N之后，你的输出需要从左往右逐行读取，产生出一个新的字符串，比如：”LCIRETOESIIGEDHN”。 请你实现这个将字符串进行指定行数变换的函数： string convert(string s, int numRows); 1234567891011121314示例 1:输入: s = \"LEETCODEISHIRING\", numRows = 3输出: \"LCIRETOESIIGEDHN\"示例 2:输入: s = \"LEETCODEISHIRING\", numRows = 4输出: \"LDREOEIIECIHNTSG\"解释:L D RE O E I IE C I H NT S G 代码： 12345678910111213141516171819202122string convert(string s, int numRows) &#123; if(numRows&lt;=1)&#123; return s; &#125; int cycle = 2+(numRows-2)*2; string res=\"\"; for(int i=0;i&lt;numRows;i++)&#123; for(int c=0;c&lt;=s.length()/cycle;c++)&#123; for(int j=i;j&lt;cycle &amp;&amp; c*cycle+j&lt;s.length();)&#123; res+=s[c*cycle+j]; if(i!=0 &amp;&amp; i!=numRows-1)&#123; j+=cycle-i*2; res+=s[c*cycle+j]; //// 需要在这里赋值res然后break，不然的话j可能存在重复叠加的情况，但是一个周期内每行最多只有两个字符。 break; &#125;else&#123; break; &#125; &#125; &#125; &#125; return res;&#125; 但是wa了，神奇。。","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://aeyoo.net/tags/leetcode/"}]},{"title":"leetcode 5 最长回文子串","date":"2020-10-24T14:41:44.000Z","path":"2020/10/24/leetcode-5-最长回文子串/","text":"这道题是一道经典的dp，给定一个字符串 s，找到 s 中最长的回文子串。用dp[i][j]表示字符串s从i位到j位是回文子串。然后当每次赋值dp[i][j]&#x3D;1的时候，记录回文子串的最大长度以及index。 给定一个字符串 s，找到 s 中最长的回文子串。你可以假设 s 的最大长度为 1000。 123456789示例 1：输入: \"babad\"输出: \"bab\"注意: \"aba\" 也是一个有效答案。示例 2：输入: \"cbbd\"输出: \"bb\" 代码： 1234567891011121314151617string longestPalindrome(string s) &#123; int len = s.length(), maxLen=0,left=0,right=s.length(); int dp[1000+5][1000+5]=&#123;&#123;0,&#125;,&#125;; for(int i=len-1;i&gt;=0;i--)&#123; for(int j=i;j&lt;len;j++)&#123; if(s[i]==s[j] &amp;&amp; (j-i&lt;=2 || dp[i+1][j-1]))&#123; dp[i][j]=1; if(maxLen&lt;j-i+1)&#123; maxLen=j-i+1; left=i; right=j; &#125; &#125; &#125; &#125; return s.substr(left,maxLen);&#125;","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://aeyoo.net/tags/leetcode/"}]},{"title":"leetcode 4 寻找两个正序数组的中位数","date":"2020-10-24T10:04:13.000Z","path":"2020/10/24/leetcode-4-寻找两个正序数组的中位数/","text":"这道题很有意思，题目是给定两个大小为 m 和 n 的正序（从小到大）数组 nums1 和 nums2。请你找出并返回这两个正序数组的中位数，要求设计一个时间复杂度为 O(log (m+n)) 的算法。常规做法就是先合并两个数组，然后排序取中位数即可，但是这样的时间复杂度是O(nlog (m+n))。 O(log (m+n)) 很明显是二分的思路，如果可以想到对k进行二分的话题目就变简单了，可惜第一次思考的时候局限在对数组进行二分。在考虑到对k进行二分之后，还需要注意很多的边界条件。 题目： 给定两个大小为 m 和 n 的正序（从小到大）数组 nums1 和 nums2。请你找出并返回这两个正序数组的中位数。 进阶：你能设计一个时间复杂度为 O(log (m+n)) 的算法解决此问题吗？ 1234567891011121314151617181920212223242526272829303132示例 1：输入：nums1 = [1,3], nums2 = [2]输出：2.00000解释：合并数组 = [1,2,3] ，中位数 2示例 2：输入：nums1 = [1,2], nums2 = [3,4]输出：2.50000解释：合并数组 = [1,2,3,4] ，中位数 (2 + 3) / 2 = 2.5示例 3：输入：nums1 = [0,0], nums2 = [0,0]输出：0.00000示例 4：输入：nums1 = [], nums2 = [1]输出：1.00000示例 5：输入：nums1 = [2], nums2 = []输出：2.00000提示：nums1.length == mnums2.length == n0 &lt;= m &lt;= 10000 &lt;= n &lt;= 10001 &lt;= m + n &lt;= 2000-106 &lt;= nums1[i], nums2[i] &lt;= 106 代码： 123456789101112131415161718192021222324252627282930313233343536373839#include&lt;iostream&gt;#include&lt;vector&gt;#include&lt;string&gt;using namespace std;double kth(vector&lt;int&gt;&amp; nums1, int left1, int right1, vector&lt;int&gt;&amp; nums2,int left2, int right2, int k)&#123; if(right1-left1 &gt; right2-left2)&#123; //将size小的数组放在前面，便于判断数组为空 return kth(nums2,left2,right2,nums1, left1,right1,k); &#125; if(left1&gt;right1) //判断数组为空 return nums2[left2+k-1]; //要加left偏移 if(k==1)&#123; return min(nums1[left1], nums2[left2]); &#125; int mid1=min(k/2, static_cast&lt;int&gt;(nums1.size()))-1, mid2=min(k/2,static_cast&lt;int&gt;(nums2.size()))-1; int res; if(nums1[left1+mid1]&lt;nums2[left2+mid2])&#123; //要加left偏移 res=kth(nums1, left1+mid1+1,right1,nums2,left2,right2,k-(mid1+1)); &#125;else &#123; res=kth(nums1, left1,right1,nums2,left2+mid2+1,right2,k-(mid2+1)); &#125; return res;&#125;double findMedianSortedArrays(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) &#123; int len = nums1.size() + nums2.size(); if(len%2==0) return (kth(nums1, 0, nums1.size()-1,nums2,0,nums2.size()-1,len/2) + kth(nums1, 0, nums1.size()-1,nums2,0,nums2.size()-1,len/2+1))/(double)2; else return kth(nums1, 0, nums1.size()-1,nums2,0,nums2.size()-1,(len+1)/2);&#125;int main()&#123; vector&lt;int&gt; nums1=&#123;1&#125;; vector&lt;int&gt; nums2=&#123;2,3,4,5,6&#125;; cout&lt;&lt;findMedianSortedArrays(nums1, nums2)&lt;&lt;endl; return 0;&#125; 参考 https://zhuanlan.zhihu.com/p/142548675","tags":[]},{"title":"poj1019 Number Sequence数字序列","date":"2020-10-13T13:33:37.000Z","path":"2020/10/13/poj1019-Number-Sequence数字序列/","text":"这道题其实不难，就是有些绕。题目给了一个数字序列的规律，要求输出数字序列第i位数字。第一次没注意输出了第i个数字wa了。eg: …12345678910…，第10位数字是1。解题过程就两点：1是找到第i位对应的子串，2是找到子串中对应的数字并输出。 Description: A single positive integer i is given. Write a program to find the digit located in the position i in the sequence of number groups S1S2…Sk. Each group Sk consists of a sequence of positive integer numbers ranging from 1 to k, written one after another.For example, the first 80 digits of the sequence are as follows:11212312341234512345612345671234567812345678912345678910123456789101112345678910 Input The first line of the input file contains a single integer t (1 ≤ t ≤ 10), the number of test cases, followed by one line for each test case. The line for a test case contains the single integer i (1 ≤ i ≤ 2147483647) Output There should be one output line per test case containing the digit located in the position i. Sample Input 123283 Sample Output 1222 题目还需要明白如下知识点： 如何计算某一个子串的长度，(int)(log10((double)i)+1)； 假设第i位数字位于第m个子串的第n位，那么问题就可以简化为找到长度&gt;n的子串$S_k$，求它的第n位。我们可以找到长度&gt;n的最小子串$S_k$，假设$S_k$的长度是len，那么$k&#x2F;(10^{len-n})$就是所求。为啥呢？因为可以明确一点，当我们找到了长度&gt;n的最小子串$S_k$之后，所求的位数数字肯定是k的某一位，因为如果是k-1的某一位，那么长度&gt;n的最小子串就是$S_{k-1}$了。 代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041#include&lt;iostream&gt;#include&lt;cmath&gt;using namespace std;const int N=31270;long a[N];long sum[N];void makeT()&#123; a[1]=1; sum[1]=1; for(int i=2;i&lt;N;i++)&#123; a[i]=a[i-1]+(int)(log10((double)i)+1); sum[i]=sum[i-1]+a[i]; &#125;&#125;int pow_10(int x, int d)&#123; while (d--) x /= 10; return x % 10;&#125;int main()&#123; makeT(); int n,str_idx; long k,idx,len,cnt,j; while(cin&gt;&gt;n)&#123; for(int i=0;i&lt;n;i++)&#123; cin&gt;&gt;k; str_idx=0; while (sum[str_idx] &gt;= 0 &amp;&amp; sum[str_idx] &lt; k) str_idx++; len=k-sum[str_idx-1]; j = 0; while (a[j] &lt; len) j++; cout&lt;&lt;pow_10(j,a[j]-len)&lt;&lt;endl; &#125; &#125; return 0;&#125; 参考： POJ 1019 Number Sequence POJ1019 ZOJ1410 UVA10706 Number Sequence【数学】 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} });","tags":[{"name":"poj","slug":"poj","permalink":"http://aeyoo.net/tags/poj/"}]},{"title":"poj1013 Counterfeit Dollar假币","date":"2020-10-10T15:35:56.000Z","path":"2020/10/10/poj1013-Counterfeit-Dollar假币/","text":"这是一道枚举题，第一次思考的时候一直陷在如何在三次称量之内找到假币，但是这道题已经明确了三次称量必定找到假币，所以呢，只需要枚举就可以了。假设一枚硬币是假的或轻或重，然后判断是否符合三个条件。需要注意的是，最后输出的是第几枚硬币是轻的还是重的，刚开始没有注意到这个细节wa了好几次。下面看下详细题目。 Description: Sally Jones has a dozen Voyageur silver dollars. However, only eleven of the coins are true silver dollars; one coin is counterfeit even though its color and size make it indistinguishable from the real silver dollars. The counterfeit coin has a different weight from the other coins but Sally does not know if it is heavier or lighter than the real coins.Happily, Sally has a friend who loans her a very accurate balance scale. The friend will permit Sally three weighings to find the counterfeit coin. For instance, if Sally weighs two coins against each other and the scales balance then she knows these two coins are true. Now if Sally weighsone of the true coins against a third coin and the scales do not balance then Sally knows the third coin is counterfeit and she can tell whether it is light or heavy depending on whether the balance on which it is placed goes up or down, respectively.By choosing her weighings carefully, Sally is able to ensure that she will find the counterfeit coin with exactly three weighings. Input The first line of input is an integer n (n &gt; 0) specifying the number of cases to follow. Each case consists of three lines of input, one for each weighing. Sally has identified each of the coins with the letters A–L. Information on a weighing will be given by two strings of letters and then one of the words up&#39;&#39;, down’’, or &#96;&#96;even’’. The first string of letters will represent the coins on the left balance; the second string, the coins on the right balance. (Sally will always place the same number of coins on the right balance as on the left balance.) The word in the third position will tell whether the right side of the balance goes up, down, or remains even. Output For each case, the output will identify the counterfeit coin by its letter and tell whether it is heavy or light. The solution will always be uniquely determined. Sample Input 12341 ABCD EFGH even ABCI EFJK up ABIJ EFGH even Sample Output 1K is the counterfeit coin and it is light. 贴代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#include&lt;iostream&gt;#include&lt;string.h&gt;#include&lt;vector&gt;#include&lt;string&gt;using namespace std;int main()&#123; int n; string str; int weight[12]=&#123;0&#125;; vector&lt;vector&lt;string&gt;&gt; input; while(cin&gt;&gt;n)&#123; for(int f=0;f&lt;n;f++)&#123; input.clear(); for(int t=0;t&lt;3;t++)&#123; vector&lt;string&gt; vec; for(int i=0;i&lt;3;i++)&#123; cin&gt;&gt;str; vec.push_back(str); &#125; input.push_back(vec); &#125; bool isI = true; string left,right; for(int i=0;i&lt;12;i++)&#123; for(int v=-1;v&lt;=1;v++)&#123; if(v==0) continue; isI = true; memset(weight,0,sizeof(weight)); weight[i]=v; for(int j=0;j&lt;3;j++)&#123; left=input[j][0]; right=input[j][1]; int left_w=0, right_w=0; for(int k=0;k&lt;left.size();k++)&#123; left_w += weight[left[k]-65]; right_w += weight[right[k]-65]; &#125; if(!((left_w &gt; right_w &amp;&amp; input[j][2]==\"up\") || (left_w &lt; right_w &amp;&amp; input[j][2]==\"down\") || (left_w == right_w &amp;&amp; input[j][2]==\"even\")))&#123; isI=false; break; &#125; &#125; if(isI &amp;&amp; v==-1)&#123; cout&lt;&lt;(char)('A'+i)&lt;&lt;\" is the counterfeit coin and it is light.\"&lt;&lt;endl; break; &#125;else if(isI &amp;&amp; v==1) &#123; cout&lt;&lt;(char)('A'+i)&lt;&lt;\" is the counterfeit coin and it is heavy.\"&lt;&lt;endl; break; &#125; &#125; if(isI==true) break; &#125; &#125; &#125; return 0;&#125;","tags":[{"name":"poj","slug":"poj","permalink":"http://aeyoo.net/tags/poj/"}]},{"title":"poj1050 To the Max求最大矩形和","date":"2020-10-05T08:22:51.000Z","path":"2020/10/05/poj1050-To-the-Max求最大矩形和/","text":"Description: Given a two-dimensional array of positive and negative integers, a sub-rectangle is any contiguous sub-array of size 1*1 or greater located within the whole array. The sum of a rectangle is the sum of all the elements in that rectangle. In this problem the sub-rectangle with the largest sum is referred to as the maximal sub-rectangle.As an example, the maximal sub-rectangle of the array: 12340 -2 -7 09 2 -6 2-4 1 -4 1-1 8 0 -2 is in the lower left corner: 1239 2-4 1-1 8 and has a sum of 15. Input The input consists of an N * N array of integers. The input begins with a single positive integer N on a line by itself, indicating the size of the square two-dimensional array. This is followed by N^2 integers separated by whitespace (spaces and newlines). These are the N^2 integers of the array, presented in row-major order. That is, all numbers in the first row, left to right, then all numbers in the second row, left to right, etc. N may be as large as 100. The numbers in the array will be in the range [-127,127]. Output Output the sum of the maximal sub-rectangle. Sample Input 1234540 -2 -7 0 9 2 -6 2-4 1 -4 1 -18 0 -2 Sample Output 115 题解： 刚看到这道题思路有点乱，感觉是一道二维dp，于是沉迷于推导状态转移方程；但是又感觉和求最大子数组的和有点类似。想了半天思路不清晰看了题解，原来求矩形面积就是把相邻行逐列求和，当做一维数组当成最大子数组的和问题来处理。而求最大子数组和的问题相当在该问题中，输入是一个行为1的矩阵。 此外还需要注意的以下几点： poj不支持int[n]的声明，但是在devc++中该声明可以编译通过。所以遇到这样的声明，直接写成n的实际最大值； 进行数组压缩的时候是一个组合问题，千万别遗漏； memset在头文件string.h中； 虽然题目中的样例输入很奇怪，但是cin本身就可以截断空格，所以确定了要输入多少个元素之后，逐个遍历输入就行。刚开始的我竟然想到用getline。。。 12345678910111213141516171819202122232425262728293031323334353637383940414243#include&lt;iostream&gt;#include&lt;string.h&gt;using namespace std;long dp[100+1]=&#123;0&#125;;int input[100+1][100+1];int comp_ary[100+1]=&#123;0&#125;; long max_seq_sum(int* seq,int n)&#123; dp[0]=seq[0]; long max_sum=dp[0]; for(int i=1;i&lt;n;i++)&#123; dp[i] = dp[i-1]&gt;0? dp[i-1]+seq[i] : seq[i]; if(dp[i]&gt;max_sum) max_sum=dp[i]; &#125; return max_sum; &#125; int main()&#123; int n; while(cin&gt;&gt;n)&#123; for(int i=0;i&lt;n;i++)&#123; for(int j=0;j&lt;n;j++)&#123; cin&gt;&gt;input[i][j]; &#125; &#125; long max_sum=INT_MIN; long sum=0; for(int i=0;i&lt;n;i++)&#123; memset(comp_ary,0,sizeof(comp_ary)); for(int j=i;j&lt;n;j++)&#123; for(int k=0;k&lt;n;k++)&#123; //这里注意 comp_ary[k]+=input[j][k]; &#125; sum=max_seq_sum(comp_ary, n); if(sum&gt;max_sum) max_sum=sum; &#125; &#125; cout&lt;&lt;max_sum&lt;&lt;endl; &#125; return 0;&#125;","tags":[]},{"title":"poj1656 Counting Black数黑色","date":"2020-10-04T11:42:19.000Z","path":"2020/10/04/poj1656-Counting-Black数黑色/","text":"Description：There is a board with 100 * 100 grids as shown below. The left-top gird is denoted as (1, 1) and the right-bottom grid is (100, 100). We may apply three commands to the board: 123456789101. WHITE x, y, L // Paint a white square on the board, // the square is defined by left-top grid (x, y) // and right-bottom grid (x+L-1, y+L-1)2. BLACK x, y, L // Paint a black square on the board, // the square is defined by left-top grid (x, y) // and right-bottom grid (x+L-1, y+L-1)3. TEST x, y, L // Ask for the number of black grids // in the square (x, y)- (x+L-1, y+L-1) In the beginning, all the grids on the board are white. We apply a series of commands to the board. Your task is to write a program to give the numbers of black grids within a required region when a TEST command is applied. Input The first line of the input is an integer t (1 &lt;&#x3D; t &lt;&#x3D; 100), representing the number of commands. In each of the following lines, there is a command. Assume all the commands are legal which means that they won’t try to paint&#x2F;test the grids outside the board. Output For each TEST command, print a line with the number of black grids in the required region. Sample Input 1234565BLACK 1 1 2BLACK 2 2 2TEST 1 1 3WHITE 2 1 1TEST 1 1 3 Sample Output 1276 这道题乍一看有点复杂，但是模拟一下就很简单了。棋盘初始全白，然后根据规则涂黑或者涂白。最后计算涂黑的个数就好了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#include&lt;iostream&gt;#include&lt;sstream&gt;#include&lt;vector&gt;using namespace std;int visits[101][101]=&#123;0&#125;;const int N=100;int cnt=0;void split(const string&amp; s, vector&lt;string&gt;&amp; sv,const char sep=' ') &#123; sv.clear(); istringstream iss(s); string tmp; while(getline(iss, tmp,sep)) &#123; sv.push_back(tmp); &#125; return;&#125;void coloring(string line) &#123; if(line.size()==0) return ; vector&lt;string&gt; vec; split(line, vec,' '); string action=vec[0]; int x=atoi(vec[1].c_str()); int y=atoi(vec[2].c_str()); int step=atoi(vec[3].c_str()); if(action==\"TEST\")&#123; cnt=0; for(int i=x;i&lt;=x+step-1;i++)&#123; for(int j=y;j&lt;=y+step-1;j++)&#123; if(visits[i][j]==1) cnt+=1; &#125; &#125; cout&lt;&lt;cnt&lt;&lt;endl; &#125; for(int i=x;i&lt;=x+step-1;i++) &#123; for(int j=y;j&lt;=y+step-1;j++)&#123; if(action==\"BLACK\")&#123; if(visits[i][j]==0)&#123; visits[i][j]=1; &#125; &#125;else if(action==\"WHITE\")&#123; if(visits[i][j]==1)&#123; visits[i][j]=0; &#125; &#125; &#125; &#125;&#125;int main()&#123; int n; while(cin&gt;&gt;n) &#123; string line; getline(cin, line); // 这行是为了读取cin&gt;&gt;n的结束符 for(int i=0;i&lt;n;i++)&#123; getline(cin, line); coloring(line); &#125; &#125; return 0;&#125;","tags":[{"name":"暴力","slug":"暴力","permalink":"http://aeyoo.net/tags/暴力/"},{"name":"棋盘规则","slug":"棋盘规则","permalink":"http://aeyoo.net/tags/棋盘规则/"}]},{"title":"poj2909 Goldbach's Conjecture哥德巴赫猜想","date":"2020-10-04T09:22:48.000Z","path":"2020/10/04/poj2909-Goldbach-s-Conjecture哥德巴赫猜想/","text":"Description： For any even number n greater than or equal to 4, there exists at least one pair of prime numbers p1 and p2 such that n &#x3D; p1 + p2 This conjecture has not been proved nor refused yet. No one is sure whether this conjecture actually holds. However, one can find such a pair of prime numbers, if any, for a given even number. The problem here is to write a program that reports the number of all the pairs of prime numbers satisfying the condition in the conjecture for a given even number. A sequence of even numbers is given as input. There can be many such numbers. Corresponding to each number, the program should output the number of pairs mentioned above. Notice that we are interested in the number of essentially different pairs and therefore you should not count (p1, p2) and (p2, p1) separately as two different pairs. Input An integer is given in each input line. You may assume that each integer is even, and is greater than or equal to 4 and less than 215. The end of the input is indicated by a number 0. Output Each output line should contain an integer number. No other characters should appear in the output. Sample Input 1234610120 Sample Output 123121 这道题是一道暴力题， 但是有一个优化的地方就是将已经计算过的素数记录下来，这样应该不会超时。另一个需要注意的地方就是如何判断一个数是素数。这里用的是试除法。 **试除法**：测试n是否为素数的最基本方法为试除法。此一程序将n除以每个大于1且小于等于n的平方根之整数m。若存在一个相除为整数的结果，则n不是素数；反之则是个素数。 代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include&lt;iostream&gt;#include&lt;cmath&gt;using namespace std;int prime_ary[65535+5]=&#123;0&#125;; // 记录素数bool is_prime_number(int n) &#123; if(n==0 || n==1) return false; bool flag=true; for(int i=2;i&lt;=sqrt((double)n);i++) &#123; if(n%i==0) flag=false; &#125; return flag;&#125;int calc_pair_num(int n)&#123; int cnt=0; // 这里要预先计算到n的素数 for(int i=n;prime_ary[i]==0 &amp;&amp; i&gt;=0;i--)&#123; if(is_prime_number(i)) prime_ary[i]=2; //2表示i是素数 else prime_ary[i]=1; //1表示i不是素数，0表示没有判断过i是否是素数 &#125; int last=n/2+1; //用于避免重复计算,因为1+2和2+1算作一种情况 for(int i=2;i&lt;last;i++)&#123; if(prime_ary[i]==2 &amp;&amp; prime_ary[n-i]==2)&#123; cnt+=1; last=n-i; &#125; &#125; return cnt;&#125;int main()&#123; int n; while(cin&gt;&gt;n) &#123; if(n==0) break; cout&lt;&lt;calc_pair_num(n)&lt;&lt;endl; &#125; return 0;&#125; 参考文献： 维基百科-素数","tags":[{"name":"暴力","slug":"暴力","permalink":"http://aeyoo.net/tags/暴力/"},{"name":"质数","slug":"质数","permalink":"http://aeyoo.net/tags/质数/"},{"name":"素数","slug":"素数","permalink":"http://aeyoo.net/tags/素数/"}]},{"title":"poj1003 Hangover","date":"2020-10-04T07:40:45.000Z","path":"2020/10/04/poj1003-Hangover/","text":"Hangover： How far can you make a stack of cards overhang a table? If you have one card, you can create a maximum overhang of half a card length. (We’re assuming that the cards must be perpendicular to the table.) With two cards you can make the top card overhang the bottom one by half a card length, and the bottom one overhang the table by a third of a card length, for a total maximum overhang of 1&#x2F;2 + 1&#x2F;3 = 5&#x2F;6 card lengths. In general you can make n cards overhang by 1&#x2F;2 + 1&#x2F;3 + 1&#x2F;4 + … + 1&#x2F;(n + 1) card lengths, where the top card overhangs the second by 1&#x2F;2, the second overhangs tha third by 1&#x2F;3, the third overhangs the fourth by 1&#x2F;4, etc., and the bottom card overhangs the table by 1&#x2F;(n + 1). This is illustrated in the figure below. Input The input consists of one or more test cases, followed by a line containing the number 0.00 that signals the end of the input. Each test case is a single line containing a positive floating-point number c whose value is at least 0.01 and at most 5.20; c will contain exactly three digits. Output For each test case, output the minimum number of cards necessary to achieve an overhang of at least c card lengths. Use the exact output format shown in the examples. Sample Input 123451.003.710.045.190.00 Sample Output 12343 card(s)61 card(s)1 card(s)273 card(s) 这是一道水题，代码如下： 1234567891011121314151617181920#include&lt;iostream&gt;using namespace std;int main()&#123; double n; while(cin&gt;&gt;n) &#123; if(n==0) &#123; break; &#125; double i=0.0; double sum=0; while(sum&lt;n)&#123; i+=1; sum+=1/(i+1); &#125; cout&lt;&lt;i&lt;&lt;\" card(s)\"&lt;&lt;endl; &#125; return 0;&#125;","tags":[{"name":"OJ","slug":"OJ","permalink":"http://aeyoo.net/tags/OJ/"}]},{"title":"cross特征总结","date":"2020-10-03T08:50:36.000Z","path":"2020/10/03/cross特征总结/","text":"cross特征是机器学习中一类非常有用的特征，例如在推荐系统领域，用户和商品的交叉特征往往可以给模型带来极大的增益，例如&lt;性别女, 口红&gt;的交叉特征，当一个用户是女性且商品是口红时，点击的概率就会很高；反之&lt;男，口红&gt;点击的概率就很低了。下面总结一些cross特征相关的工作，比较典型有FM, FFM, 各类NN模型等。DNN模型不在文本讨论之列，DNN的全连接层带交叉特征的能力，但是有些情况下我们需要构造一些更加直接的cross特征。 1 人工构造二阶交叉特征FM是人工构造二阶交叉特征的代表。FM诞生之初是为了解决稀疏数据下的特征组合问题。多项式模型是包含特征组合最直观的模型，在多项式模型中，特征$x_i$和$x_j$的组合采用$x_ix_j$表示，即当$x_i$和$x_j$都非零时，组合特征$x_ix_j$才有意义。以二阶多项式模型为例，其表达式如下： $$y(x)&#x3D;w_0 + \\sum^n_{i&#x3D;1}w_ix_i + \\sum^n_{i&#x3D;1}\\sum^n_{j&#x3D;i+1}w_{ij}x_ix_j$$在数据普遍稀疏的情况下，二次项参数$w_{ij}$训练时很困难的。基于模型的协同过滤中，一个评分矩阵通常被分解为user矩阵和item矩阵的积（MF），每个user向量和每个item向量的点积就表示了这个user对这个item的评分。 借鉴于上述思路，同时也是对称矩阵的二次项参数$w_{ij}$可以分解为两个矩阵的乘积，即$W&#x3D;V^TV$，$V$的第 $j$ 列表示第 $j$ 维特征的隐向量。因此二阶cross特征的FM模型方程为：$$y(x)&#x3D;w_0 + \\sum^n_{i&#x3D;1}w_ix_i + \\sum^n_{i&#x3D;1}\\sum^n_{j&#x3D;i+1}v_iv_j^Tx_ix_j$$ 2 自动构造有限高阶的交叉特征论文《Deep &amp; Cross Network for Ad Click Predictions》是斯坦福和Google合作的一篇论文，论文中提出了一种自动构造有限高阶交叉特征的方法，并且使构造交叉特征的层拟合残差。网络结构如下： 模型的输入有稀疏特征和稠密特征，稀疏特征embedding之后和归一化后的稠密特征concat，一起作为cross网络和deep网络的输入。deep网络就是简单的全连接层，cross网络拟合了残差 $x_{i+1}-x_i$，目的是使得网络更深；并且可以注意到cross网络的输入和输出的维度是相同的。可以看下cross是如何进行的：$$x_1&#x3D;x_0x_0^Tw_{c,0} + b_{c,0} + x_0$$下面的图就非常直观地展示了cross机制： 关于这个模型的总结，知乎已经有大佬总结的很到位了《揭秘 Deep &amp; Cross : 如何自动构造高阶交叉特征》。 参考文献 深入FFM原理与实践 揭秘 Deep &amp; Cross : 如何自动构造高阶交叉特征 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} });","tags":[]},{"title":"关于思维逻辑的几点思考","date":"2020-10-01T16:35:08.000Z","path":"2020/10/02/关于思维逻辑的几点思考/","text":"今天中秋，刚刚晚上下班回来后就22:30了，然后处理了下工作上的事情，然后放松了会洗了个澡，然后就现在00:43了。总是说生活要有一些仪式感的，哎，时间所迫生活已然不易。 今天在忙实验放量50%的事情，中午起来感觉浑身难受就去用冷水洗了个头，组长一个电话打过来我有点懵，然后就开启了被diss的过程，话说被组长diss表达有问题也不是第一次了，没有第一次那样郁闷，其实我讲的时候连我自己都觉得对方听不明白…就很奇怪，挂了电话之后仿佛才灵魂附体，我刚刚讲了啥？？ 晚上回来的时候想了想，这是第四次被diss表达能力有问题了，但是我高中语文一直很好伐。如果一次两次是偶然的话，四次就决然不是了。一项自诩逻辑思维还比较强的我，到现在依然不觉得是我的逻辑思维能力起了决定性作用。认真想了想，两次表达混乱的情况是对背景知识不熟悉，一次是我以为别人有先验知识，一次是别人写的代码有些抽象，再加上一直没想明白怎么给别人介绍代码，于是卒… 直接说结论吧，我觉得上面的都是表象，真正影响表达能力的原因，是交流心态和总结能力的问题。突然发现除了做课程作业，竟然很少对一些工作做总结，这就导致了一方面没有建立起知识的立体结构，另一方面缺少在特殊情况下冷静思考的能力。还记得之前头条和网易面试的时候，因为紧张导致一些不太难的算法问题没有做出来。所以现在看来，每周的周报还是很必要的，可以锻炼自己的总结能力。关于上面的两个问题的解决思路： 每天及时总结工作，零散的知识进行记录和必要的整理，一个项目必须写总结文档； 针对突然出现的问题必须进行及时的思考；领域知识必须及时回顾； 刷OJ，锻炼规定时间内解决问题的能力； 先理论AC，再实现； 建立立体知识体系。 前两天因为自己的失误，导致一个现网逻辑没有在国庆期间生效，汗… 感觉事情多的时候就容易出问题，本质还是自己的专注力不够，做事情的时候总是想别的事情。这个事情就通过刷OJ解决吧，严谨的思维，希望可以早日相对petr一样优秀。 TiuVe, to be best. 其实写上面这些内容的时候也是想到哪里写到哪里…这病得治。","tags":[{"name":"逻辑","slug":"逻辑","permalink":"http://aeyoo.net/tags/逻辑/"}]},{"title":"COLD Towards the Next Generation of Pre Ranking System","date":"2020-09-16T15:27:02.000Z","path":"2020/09/16/COLD-Towards-the-Next-Generation-of-Pre-Ranking-System/","text":"目前主流的以双塔结构为基础的粗排系统被定义为第三代粗排系统，其离线计算得到用户和广告的向量，同时以向量内积的方式在线计算得到用户和广告的分数进行排序过滤。该架构的优点在于性能开销小，但是也有如下缺点： 模型表达能力受限； 离线计算用户和广告向量的时间久，较难捕捉到数据分布漂移； 模型更新频率受限，即很难保证用户和广告的索引同时切换，而这是非常重要的，不同步会损害模型的性能。 基于以上问题，论文提出了一种新的粗排系统，在模型表达能力和算力消耗两方面进行了优化（也就是重新考虑模型设计和系统设计），使得可以上线较复杂的模型。优化点主要有3个： COLD模型是一个七层的全连接网络，其使用SE进行了特征选择，受益于SE，算力消耗可控。且加入了交叉特征； 使用了一些优化技巧降低算力消耗，包括并行计算，半精度计算进行推理加速； COLD模型以在线学习的方式运行，解决数据分布漂移的问题； 如图3所示，COLD实现了模型表达能力和更新频率之间的平衡。目前COLD被广泛应用于阿里巴巴业务线，并实现了6%的RPM提升。 下面来谈谈COLD的细节： 设计灵活的模型结构降低平衡模型性能和算力成本。论文使用GwEN作为base model，这是在线模型的早期版本。GwEN分组的目的是借鉴cnn局部感受野的思想，降低参数量级。此外要保证模型尽量轻，且保证模型的表达能力。使模型变轻有很多方法，例如剪枝，特征选择，NAS等，论文选择了一种叫做SE的特征选择方法。SE最开始被应用于CV。 工程优化tricks，推理加速。工程优化指的是在线推断环节，其分为两个部分：交叉特征计算和稠密网络计算。在阿里定向广告系统中，粗排的线上打分主要包含两部分：特征计算和网络计算。特征计算部分主要负责从索引中拉取用户和广告的特征并且进行交叉特征的相关计算。而网络计算部分，会将特征转成embedding向量，并将它们拼接进行网络计算[1]。特征计算环节加速的trick有多线程加速，列计算转换；稠密网络计算环节加速的trick有GPU加速（混合精度加速）。 在线服务架构方面，我个人理解没有过多的创新。如图7所示。 关于实验结果可以参考文献[1]，值得注意的是论文使用了GAUC指标评测模型。 参考[1] 阿里定向广告最新突破：面向下一代的粗排排序系统COLD certain metrics 某些指标；vector-product 向量内积；Shortcomings 缺点；suboptimal performance 欠佳；lightweight 轻量级；","tags":[{"name":"cold","slug":"cold","permalink":"http://aeyoo.net/tags/cold/"},{"name":"gwen","slug":"gwen","permalink":"http://aeyoo.net/tags/gwen/"}]},{"title":"cpx,ocpx那些事儿","date":"2020-07-09T09:19:26.000Z","path":"2020/07/09/cpx-ocpx那些事儿/","text":"在计算广告领域，通常会遇到cpm, ocpm, ecpm等指标，那么这些指标是用来做什么的以及有什么区别呢？本文将做一个全面梳理。首先来讲一下这些指标的定义。 1 CPM, eCPM, oCPM的定义为描述方便，下文将广告主称为需求方，广告平台称为供给方。 eCPM（effective cost per mile）是衡量广告收益的一个指标，即** 每一千次展示可以获得的广告收入**。 CPM（Cost Per Mille）是一种结算方式，即按照千次展示付费。除了CPM，还有CPC, CPA, CPT等。 CPC（Cost Per Click）按照点击结算； CPA（Cost Per Action）按照转化结算，CPS, ROI和CPA一样，都是按照转化付费的一个变种； CPT（Cost Per Time）按照独占时间结算。严格来说，CPT是一种销售方式而非结算方式，因为价格是双方事先约定的。 oCPM（Optimized Cost Per Mille）也是由Facebook主推的一种新结算方式，指的是优化转化的CPM结算。什么意思呢？就是优化目标是转化，结算方式是CPM。虽然结算方式是CPM，但是供给方会承担点击率和点击价值估计的任务。具体来说就是，广告主设置一个目标转化价格，然后广告系统基于该转化价格，预估PCTR&#x2F;PCVR等信息计算出一个价格进行竞价。除了oCPM，同样有oCPC, oCPA。oCPC指的是优化转化的CPC结算，oCPA是优化转化的CPA结算，不过在有些地方，oCPA和oCPM等价。 下表对比了几种常见的结算方式。 2 eCPM计算公式首先给出eCPM的计算公式： $$\\begin{aligned} eCPM &amp;&#x3D; CPM \\times 1000 &#x3D; 消耗&#x2F;曝光 \\times 1000 \\\\ &amp;&#x3D; (CPC \\times 点击数）&#x2F;（点击数&#x2F;点击率）\\times 1000 \\\\ &amp;&#x3D; CPC \\times 点击数 &#x2F; 点击数 \\times 点击率 \\times 1000 \\\\ &amp;&#x3D; CPC \\times CTR \\times 1000 \\\\ &amp;&#x3D; CPA \\times CVR \\times CTR \\times 1000 \\\\ &amp;\\approx CPA \\times pCVR \\times pCTR \\times 1000 \\\\\\end{aligned}$$上式中，CPA就是广告主设置的目标转化价格，$CPM&#x3D;CPA\\ast CVR \\ast CTR$，这个公式告诉我们，当广告主设定了CPA时，如果要按照CPM扣费应该如何计算CPM。这里的CTR&#x2F;CVR是用户对广告的真实CTR&#x2F;CVR，这两个值很难获取，所以通常会对这两个值进行预估，即pCTR&#x2F;pCVR。然后根据pCTR，pCVR近似计算CPM。，当pCVR 和pCTR预测绝对准确时，按照CPM收费，实际转化价格等于广告主的目标转化价格。 这里需要强调一点，CPM和oCPM有非常大的不同。CPM是供给方和需求方约定好千次展示的计费标准，至于这些展示是否能带来相应的收益，由需求方估计和控制风险；而oCPM是需求方设置目标转化价格，供给方根据需求方设置的目标转化价格进行优化，按照千次展示收费，这里的千次展示收费是基于广告主设置的目标转化价格的，所以容易控制广告主的转化成本。 RTB根据广告的eCPM进行竞价，最终按照第二名的出价进行收费。通常来说，参与竞价的各个广告的pctr&#x2F;pcvr差别不会太大，但是广告主的出价(CPA)可能会差别很大，所以CPA高的广告会因为ecpm高而赢得竞价，但是最终按照第二名的出价收费，所以，广告平台收费会略低于广告主的目标出价。 这里再稍微提一点，计算广告中有一个指标叫GMV（腾讯定义，在字节叫做广告主价值），单个广告的GMV&#x3D;CPA*转化数，可以看出，GMV是广告主带来的真实价值，而消耗只是从广告主账户实际扣费得到的收入。对于一个广告来说，当它曝光时只有转化或者不转化两种情况，当曝光1次时，其$GMV期望&#x3D;CPA\\ast 1\\ast CTR\\ast CVR+CPA\\ast 1\\ast 0$（0表示不转化）。所以当它曝光n次时，其$GMV的期望&#x3D;CPA\\ast n\\ast CTR\\ast CVR&#x3D;CPM\\ast n$，即$单个广告的GMV期望&#x3D;CPM\\ast n&#x3D;单个广告的消耗$。当pCTR&#x2F;pCVR预估绝对准确时，GMV&#x3D;消耗。但是消耗的提升和广告的CTR&#x2F;CVR高低没有直接关系，而是和广告主的预算有关。当你的广告系统能够给广告主带来收益（转化），同时广告主也提高预算时，那么消耗自然就涨了。 3 oCPM 深入分析oCPM的好处就是统一了广告主和广告平台的利益。对于广告主来说，使用oCPM结算更容易控制成本，其次在转化成本不变的前提下，广告主可以通过提高素材的质量提升PCTR&#x2F;PCVR，从而提升自己的广告在竞价能力。对于广告平台来说，通过不断优化PCTR&#x2F;PCVR，可以使得转化率高的用户看到广告，转化率低的用户看不到广告，从而使得流量具有区分性，最大化流量的使用，从而提升广告平台的收益。 参考1 oCPM功能以及原理简述 2 oCPA、oCPM竞价的本质是什么？ 3《计算广告》第二版 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} });","tags":[{"name":"cpm","slug":"cpm","permalink":"http://aeyoo.net/tags/cpm/"},{"name":"opcm","slug":"opcm","permalink":"http://aeyoo.net/tags/opcm/"},{"name":"ecpm","slug":"ecpm","permalink":"http://aeyoo.net/tags/ecpm/"}]},{"title":"fine","date":"2020-06-24T14:35:43.000Z","path":"2020/06/24/fine/","text":"灰色石头","tags":[]},{"title":"一个异步多进程python包aiomultiprocess","date":"2020-06-01T01:50:23.000Z","path":"2020/06/01/一个python异步多进程包aiomultiprocess/","text":"aiomultiprocess是一个异步多进程的python库，其依赖于aiohttp和asyncio两个库。aiohttp是一个基于asyncio的异步http客户端和服务器。asyncio 是用来编写 并发 代码的库，使用 async&#x2F;await 语法。asyncio 被用作多个提供高性能 Python 异步框架的基础，包括网络和网站服务，数据库连接库，分布式任务队列等等。 On their own, AsyncIO and multiprocessing are useful, but limited: AsyncIO still can’t exceed the speed of GIL, and multiprocessing only works on one task at a time. But together, they can fully realize their true potential. aiomultiprocess presents a simple interface, while running a full AsyncIO event loop on each child process, enabling levels of concurrency never before seen in a Python application. Each child process can execute multiple coroutines(协程) at once, limited only by the workload and number of cores available. 举个例子： 1234567891011121314151617181920212223242526272829#coding:utf8import asynciofrom aiohttp import requestfrom aiomultiprocess import Poolurl = \"https://github.com\"async def request_one(json_req): try: print(json_req) async with request(method='GET', url=url) as rsp: return await rsp.text(\"utf-8\"), json_req[\"uid\"] #这里获取uid是为了区分返回的结果 except Exception: print(\"error\")def request_batch(list_req): async def run_all(): async with Pool(10) as pool: #list传入请求列表，request_one单次请求函数 return await pool.map(request_one, list_req) return asyncio.run(run_all()) #py3.7 asyncio.run() 函数用来运行最高层级的入口点 \"main()\" 函数 # loop = asyncio.get_event_loop() # return loop.run_until_complete(run_all())if __name__==\"__main__\": out = request_batch([&#123;\"uid\":\"2\"&#125;, &#123;\"uid\":\"4\"&#125;]) print(len(out)) for o in out: print(o) asyncio.run is a Python 3.7 addition. In 3.5-3.6, your example is roughly equivalent to: 12345import asynciofutures = [...]loop = asyncio.get_event_loop()loop.run_until_complete(asyncio.wait(futures)) 参考 https://pypi.org/project/aiomultiprocess/ https://docs.aiohttp.org/en/stable/ https://www.cnblogs.com/alummox/p/12364498.html https://stackoverflow.com/questions/52796630/python3-6-attributeerror-module-asyncio-has-no-attribute-run asyncio — 异步 I&#x2F;O Asyncio并发编程","tags":[{"name":"async","slug":"async","permalink":"http://aeyoo.net/tags/async/"},{"name":"异步","slug":"异步","permalink":"http://aeyoo.net/tags/异步/"},{"name":"多进程","slug":"多进程","permalink":"http://aeyoo.net/tags/多进程/"}]},{"title":"心灵之旅一","date":"2020-04-22T13:44:52.000Z","path":"2020/04/22/心灵之旅一/","text":"最近状态一直不好，可能潜意识中被莫名其妙的事情影响着。我想是心态有点崩和毫无工作计划。这让我想起来了《李小龙传奇》中徐迪雅和李小龙说的一段话：“美国是个大动物园，适者生存。这是我这么多年在美国打拼，尝遍酸甜苦辣之后得出的结论。不管遇到任何困难，都不要迷失自己，不要丧失自信”。我想对于现在的我也同样适用吧。想清楚自己想要的是什么，好好干。","tags":[{"name":"心灵之旅","slug":"心灵之旅","permalink":"http://aeyoo.net/tags/心灵之旅/"}]},{"title":"tf.nn函数概览","date":"2020-04-21T08:11:13.000Z","path":"2020/04/21/tf-nn函数概览/","text":"最近遇到一个问题，几天没有思路，结果被同事一语道破，发现还是对api不熟，所以这里立个flag，最近把所有的tf.nn下的api全部看一遍。下次有问题直接先把api撸一遍再说。 下述内容全部来自于w2cschool，侵删。不过过两天就删除了哈哈。。 all_candidate_sampler(…)：生成所有可能的类集合？看不懂先放放，官方描述如下： Deterministically generates and returns the set of all possible classes. For testing purposes. There is no need to use this, since you might as well use full softmax or full logistic regression. atrous_conv2d(value,filters,rate,padding,name&#x3D;None)：实现atrous卷积（空洞卷积）。 atrous_conv2d_transpose(…)：atrous_conv2d的转置。 tf.nn.avg_pool(value, ksize, strides, padding, data_format&#x3D;’NHWC’, name&#x3D;None, input&#x3D;None)：对输入执行平均池化。 avg_pool1d(input,ksize,strides,padding,data_format&#x3D;’NWC’,name&#x3D;None) 在输入上执行1D平均池化 avg_pool3d(input,ksize,strides,padding,data_format&#x3D;’NDHWC’,name&#x3D;None)：在输入上执行3D平均池化。 batch_norm_with_global_normalization(…)：批量标准化，这个是旧版本被废弃，建议使用batch_normalization()。 batch_normalization(x,mean,variance,offset,scale,variance_epsilon,name&#x3D;None)：批量归一化。 bias_add(…)：将bias向量添加到value矩阵上。注意是bias与矩阵的每一行进行相加，value的shape不变。 bidirectional_dynamic_rnn(…)：创建双向递归神经网络的动态版本。 collapse_repeated(labels, seq_length, name&#x3D;None)：Merge repeated labels into single labels. compute_accidental_hits(true_classes,sampled_candidates,num_true,seed&#x3D;None,name&#x3D;None)： 猜也是mask的一种？官方描述如下： In Candidate Sampling, this operation facilitates virtually removing sampled classes which happen to match target classes. This is done in Sampled Softmax and Sampled Logistic. compute_average_loss(…): Scales per-example losses with sample_weights and computes their average. conv1d(value&#x3D;None,filters&#x3D;None,stride&#x3D;None,padding&#x3D;None,use_cudnn_on_gpu&#x3D;None,data_format&#x3D;None, name&#x3D;None,input&#x3D;None,dilations&#x3D;None)：一维卷积，input是3d。 conv1d_transpose(…)： conv2d(…)：同上。 conv2d_backprop_filter(…)：计算滤波器的卷积梯度。 conv2d_backprop_input(…)：计算输入的卷积梯度。 conv2d_transpose(…)：conv2d的转置. conv3d(…)：计算给定5-D输入和滤波器张量的3-D卷积. conv3d_backprop_filter(…)：计算滤波器的3d卷积梯度。 conv3d_transpose(…)：conv3d的转置。 convolution(…)：计算n维卷积的总和。 conv_transpose(…)：convolution的转置。 crelu(…)：Computes Concatenated ReLU。 —–4.22中午总结到此。 ctc_beam_search_decoder(…)：对输入中给出的logits执行波束搜索解码. ctc_greedy_decoder(…)：对输入(最佳路径)中给出的logits执行贪婪解码. ctc_loss(…)：计算CTC(连接器时间分类)loss. depthwise_conv2d(…)：深度2-D卷积. depthwise_conv2d_native(…)：计算给定4-D输入和滤波器张量的2-D深度卷积. depthwise_conv2d_native_backprop_filter(…)：计算相对于滤波器的深度卷积的梯度. depthwise_conv2d_native_backprop_input(…)：计算相对于输入的深度卷积的梯度. dilation2d(…)：计算4-D输入和3-D滤波器张量的灰度扩张. dropout(…)：计算丢失. dynamic_rnn(…)：创建由RNNCell cell指定的递归神经网络. elu(…)：计算指数线性：exp(features) - 1,如果&lt;0,则为features. embedding_lookup(…)：在嵌入式张量列表中查找ids. embedding_lookup_sparse(…)：计算给定ID和权重的嵌入. erosion2d(…)：计算4-D value和3-D kernel张量的灰度侵蚀. fixed_unigram_candidate_sampler(…)：使用提供的(固定)基本分布对一组类进行采样. fractional_avg_pool(…)：对输入执行小数平均池. fractional_max_pool(…)：对输入执行小数最大池. fused_batch_norm(…)：批量标准化. in_top_k(…)：说目标是否在最高K预测中. l2_loss(…)：L2 loss. l2_normalize(…)：使用L2范数沿维度axis规范化.(不赞成的参数) leaky_relu(…)：计算Leaky ReLU激活功能. learned_unigram_candidate_sampler(…)：从培训期间学习的分布中抽取一组类进行采样. local_response_normalization(…)：本地响应规范化. log_poisson_loss(…)：计算给定log_input的对数Poisson loss. log_softmax(…)：计算log softmax激活.(不赞成的参数) log_uniform_candidate_sampler(…)：使用对数统一(Zipfian)基本分布对一组类进行采样. lrn(…)：本地响应规范化. max_pool(…)：对输入执行最大池化. max_pool3d(…)：在输入上执行3D最大池化. max_pool_with_argmax(…)：对输入执行最大池化并输出最大值和索引. moments(…)：计算x的平均值和方差. nce_loss(…)：计算并返回噪声对比估计训练loss. normalize_moments(…)：根据足够的统计数据计算均值和方差. pool(…)：执行ND池操作. quantized_avg_pool(…)：为量化类型生成输入张量的平均池. quantized_conv2d(…)：计算给定量化4D输入和滤波器张量的2D卷积. quantized_max_pool(…)：为量化类型生成输入张量的最大池. quantized_relu_x(…)：计算量化整流线性X： min(max(features, 0), max_value) raw_rnn(…)：创建由RNNCell cell和循环函数loop_fn指定的RNN. relu(…)：计算Rectified线性：max(features, 0). relu6(…)：计算Rectified线性6 : min(max(features, 0), 6). relu_layer(…)：计算Relu(x * weight + biases). sampled_softmax_loss(…)：计算并返回采样的softmax训练损失. selu(…)：计算缩放指数线性：scale * alpha * (exp(features) - 1) separable_conv2d(…)：带可分离滤波器的2-D卷积. sigmoid(…)：计算x元素方式的sigmoid . sigmoid_cross_entropy_with_logits(…)：计算给出的sigmoid cross entropy logits. softmax(…)：计算softmax激活.(不赞成的参数) softmax_cross_entropy_with_logits(…)：计算logits和labels之间的softmax交叉熵.(废弃) softmax_cross_entropy_with_logits_v2(…)：计算logits和labels之间的softmax交叉熵. softplus(…)：计算softplus : log(exp(features) + 1). softsign(…)：计算softsign : features &#x2F; (abs(features) + 1). sparse_softmax_cross_entropy_with_logits(…)：计算logits和labels之间的稀疏softmax交叉熵. static_bidirectional_rnn(…)：创建双向递归神经网络. static_rnn(…)：创建由RNNCell cell指定的递归神经网络. static_state_saving_rnn(…)：RNN接受状态保护程序进行时间截断的RNN计算. sufficient_statistics(…)：计算x的平均值和方差的足够统计量. tanh(…)：计算x元素的双曲正切值. top_k(…)：查找最后一个维度的k最大条目的值和索引. uniform_candidate_sampler(…)：使用统一的基本分布对一组类进行采样. weighted_cross_entropy_with_logits(…)：计算加权交叉熵. weighted_moments(…)：返回x的频率加权平均值和方差. with_space_to_batch(…)：对input的space-to-batch执行op. xw_plus_b(…)：计算matmul(x, weights) + biases. zero_fraction(…)：返回value中的零的分数.","tags":[{"name":"tf.nn","slug":"tf-nn","permalink":"http://aeyoo.net/tags/tf-nn/"}]},{"title":"tf 实现torch.gather()函数","date":"2020-04-16T02:51:04.000Z","path":"2020/04/16/tf实现torch-gather-函数/","text":"在tensorflow和pytorch中都有一个gather函数，其作用相似但是用法不同。关于tf.gather的用法可以参考知乎作者Towser的文章《TF 中的 indexing 和 slicing》。torch.gather函数的用法也很简单，就是给定indices获取tensor对应元素。给个例子就明白了。 123456tensor = torch.Tensor([[1,2,3],[4,5,6]])indexs = torch.LongTensor([[0,1],[1,2]]) #就是获取tensor中的[1,0],[1,1],[2,1],[2,2]对应位置的元素print(torch.gather(tensor, 1, indexs))#tensor([[1., 2.],# [5., 6.]]) 下面直接给出torch.gather的tf实现。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748def torch_gather_2d(input, indices): len_1d, len_2d = tf.shape(input)[0], tf.shape(input)[1] idx_matrix = tf.tile(tf.expand_dims(tf.range(0, len_2d), 0), [len_1d,1]) indices_t = tf.transpose(indices) len = indices_t.get_shape()[0] for i in range(len): coln = tf.nn.embedding_lookup(indices_t, [i]) idx_mask_new = tf.equal(idx_matrix, tf.transpose(coln)) if i == 0: idx_mask = idx_mask_new idx_mask = tf.logical_or(idx_mask_new, idx_mask) input = tf.reshape(tf.boolean_mask(input, idx_mask), tf.shape(indices)) return inputwith tf.Session() as sess: x = tf.reshape(tf.range(1,49), [6,8]) y = tf.constant([[0,1], [1,2], [2,3,], [3,4], [4,5], [5,6]]) out = torch_gather_2d(x, y) print(\"x:\\n\", sess.run(x)) print(\"y:\\n\", sess.run(y)) print(\"out:\\n\", sess.run(out)) # x:# [[ 1 2 3 4 5 6 7 8]# [ 9 10 11 12 13 14 15 16]# [17 18 19 20 21 22 23 24]# [25 26 27 28 29 30 31 32]# [33 34 35 36 37 38 39 40]# [41 42 43 44 45 46 47 48]]# y:# [[0 1]# [1 2]# [2 3]# [3 4]# [4 5]# [5 6]]# out:# [[ 1 2]# [10 11]# [19 20]# [28 29]# [37 38]# [46 47]] 就酱。还是写tf太少了，不过mask真的是一种很有用的技巧。","tags":[{"name":"gather","slug":"gather","permalink":"http://aeyoo.net/tags/gather/"}]},{"title":"sklearn roc_auc_score源码解读","date":"2020-03-26T03:39:59.000Z","path":"2020/03/26/sklearn-roc-auc-score源码解读/","text":"在sklearn中使用roc_auc_score()函数计算auc，其计算方式和tf.metrics.auc()计算方式基本一致，也是通过极限逼近思想，计算roc曲线下面积的小梯形之和得到auc的。二者主要区别在于计算小梯形面积（计算小梯形面积时需要设置阈值计算tp,tn,fp,fn，进而计算tpr,fpr和小梯形面积）。第一，在tf.metrics.auc()中可以指定阈值个数，默认是200个阈值，一般设置该阈值为batch size比较合理。而在sklearn的roc_auc_score()函数实现中，直接指定了阈值个数为batch size。第二，阈值的产生方式也不同。tf.metrics.auc()是等距产生阈值的，roc_auc_score()直接以预测概率scores为阈值。 首先看roc_auc_score函数定义： 123456789101112131415161718192021222324def roc_auc_score(y_true, y_score, average=\"macro\", sample_weight=None): \"\"\"Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) Examples -------- &gt;&gt;&gt; import numpy as np &gt;&gt;&gt; from sklearn.metrics import roc_auc_score &gt;&gt;&gt; y_true = np.array([0, 0, 1, 1]) &gt;&gt;&gt; y_scores = np.array([0.1, 0.4, 0.35, 0.8]) &gt;&gt;&gt; roc_auc_score(y_true, y_scores) 0.75 \"\"\" def _binary_roc_auc_score(y_true, y_score, sample_weight=None): if len(np.unique(y_true)) != 2: raise ValueError(\"Only one class present in y_true. ROC AUC score \" \"is not defined in that case.\") fpr, tpr, tresholds = roc_curve(y_true, y_score, sample_weight=sample_weight) return auc(fpr, tpr, reorder=True) return _average_binary_score( _binary_roc_auc_score, y_true, y_score, average, sample_weight=sample_weight) 可以看到，传入参数主要有两个，y_true和 y_score。22行的_average_binary_score函数实际上调用了_binary_roc_auc_score(y_true, y_score)函数。在_binary_roc_auc_score()函数中，首先调用roc_curve()计算了fpr, tpr，然后调用了auc(fpr, tpr, reorder&#x3D;True)得到auc值。auc()函数的实现和tf.metrics.auc()的实现基本一致，不再累述。这里重点看下如何产生fpr, tpr的。 roc_curve()定义如下： 123456789101112131415161718192021222324252627282930313233343536373839def roc_curve(y_true, y_score, pos_label=None, sample_weight=None, drop_intermediate=True): \"\"\"Compute Receiver operating characteristic (ROC) \"\"\" fps, tps, thresholds = _binary_clf_curve( y_true, y_score, pos_label=pos_label, sample_weight=sample_weight) if drop_intermediate and len(fps) &gt; 2: optimal_idxs = np.where(np.r_[True, np.logical_or(np.diff(fps, 2), np.diff(tps, 2)), True])[0] fps = fps[optimal_idxs] tps = tps[optimal_idxs] thresholds = thresholds[optimal_idxs] if tps.size == 0 or fps[0] != 0: # Add an extra threshold position if necessary tps = np.r_[0, tps] fps = np.r_[0, fps] thresholds = np.r_[thresholds[0] + 1, thresholds] if fps[-1] &lt;= 0: warnings.warn(\"No negative samples in y_true, \" \"false positive value should be meaningless\", UndefinedMetricWarning) fpr = np.repeat(np.nan, fps.shape) else: fpr = fps / fps[-1] if tps[-1] &lt;= 0: warnings.warn(\"No positive samples in y_true, \" \"true positive value should be meaningless\", UndefinedMetricWarning) tpr = np.repeat(np.nan, tps.shape) else: tpr = tps / tps[-1] return fpr, tpr, thresholds roc_curve函数的核心在5-6行，如何计算tp,fp。当知道tp, fp之后，tpr, fpr就好计算了，因为tn, fp只要知道labels就可以计算出来。这里先说结论，第5-6行的fps, tps分别表示不同阈值下，fp和tp的值，它们是一个array。 再看_binary_clf_curve函数。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455def _binary_clf_curve(y_true, y_score, pos_label=None, sample_weight=None): \"\"\"Calculate true and false positives per binary classification threshold. \"\"\" # Check to make sure y_true is valid y_type = type_of_target(y_true) if not (y_type == \"binary\" or (y_type == \"multiclass\" and pos_label is not None)): raise ValueError(\"&#123;0&#125; format is not supported\".format(y_type)) check_consistent_length(y_true, y_score, sample_weight) y_true = column_or_1d(y_true) #column_or_1d 校验维度 y_score = column_or_1d(y_score) assert_all_finite(y_true) assert_all_finite(y_score) if sample_weight is not None: sample_weight = column_or_1d(sample_weight) # ensure binary classification if pos_label is not specified classes = np.unique(y_true) if (pos_label is None and not (np.array_equal(classes, [0, 1]) or np.array_equal(classes, [-1, 1]) or np.array_equal(classes, [0]) or np.array_equal(classes, [-1]) or np.array_equal(classes, [1]))): raise ValueError(\"Data is not binary and pos_label is not specified\") elif pos_label is None: pos_label = 1. # make y_true a boolean vector y_true = (y_true == pos_label) # sort scores and corresponding truth values desc_score_indices = np.argsort(y_score, kind=\"mergesort\")[::-1] #argsort升序排序得到索引, [::-1]是反转功能，这里就是降序 y_score = y_score[desc_score_indices] y_true = y_true[desc_score_indices] if sample_weight is not None: weight = sample_weight[desc_score_indices] else: weight = 1. # y_score typically has many tied values. Here we extract # the indices associated with the distinct values. We also # concatenate a value for the end of the curve. distinct_value_indices = np.where(np.diff(y_score))[0] threshold_idxs = np.r_[distinct_value_indices, y_true.size - 1] # np.r_按列concat # accumulate the true positives with decreasing threshold tps = stable_cumsum(y_true * weight)[threshold_idxs] if sample_weight is not None: fps = stable_cumsum(weight)[threshold_idxs] - tps else: fps = 1 + threshold_idxs - tps return fps, tps, y_score[threshold_idxs] 重点从35行开始，desc_score_indices得到了降序的y_score的索引。46行np.diff(y_score)得到了y_score的一阶差分，np.where(np.diff(y_score))[0]是获得一阶差分不为0的索引列表，[0]是因为np.where(np.diff(y_score))得到的是一个元组，元组的第一个元素才是索引列表。这里实际上就是对y_score做了一个去重操作，因为重复值作为阈值没有意义。36-37行得到了降序的y_score和y_true。第47行将索引值y_true.size - 1加入到了distinct_value_indices中，因为一阶差分之后少了一个值。 50行也是一个重点，stable_cumsum(y_true * weight)[threshold_idxs]首先对降序的y_true 进行了累加的操作，然后根据threshold_idxs获得了累加结果。因为正例是1，负例是0，所以这里实际上是获得了不同阈值下的真正例tp(tps)。而54行则获得了假正例fp(fps)。threshold_idxs的值不仅仅是索引，也代表了正负样例总和，所以1 + threshold_idxs - tps就是假正例。 综上，roc_auc_score实现方式和tf.metrics.auc基本一致，只是求小梯形面积时不一样，具体表现为：小梯形个数不一样(阈值个数不同)和小梯形面积不一样(阈值不同导致tp,fn,fp,fn不同，所以tpr,fpr不同进而导致小梯形面积不同）。综合roc_auc_score和tf.metrics.auc的实现，知道了两点： 关于阈值的个数，使用tf.metrics.auc时，参数num_thresholds最好设置为batch size； 关于阈值的取值，其实说不上哪种方式好。tf.metrics.auc时等距划分，roc_auc_score是直接取scores，仁者见仁智者见智吧。","tags":[{"name":"roc_auc_score","slug":"roc-auc-score","permalink":"http://aeyoo.net/tags/roc-auc-score/"}]},{"title":"tf.metrices.auc源码解读","date":"2020-03-25T11:44:48.000Z","path":"2020/03/25/tf-metrices-auc源码解读/","text":"auc是机器学习二分类问题的常用指标，其反映了分类器对正负样本的排序能力，换句话说，auc反映了模型对正负样本的区分能力。常用的auc计算方式有两种，一种是tensorflow的tf.metrics.auc函数，另一种是sklearn中的roc_auc_score()函数。二者都是通过极限逼近的思想，计算roc曲线下面积的一个个小梯形的面积和得到auc。不过有点奇怪的是，这两个函数计算出来的auc值并不总是相似的，有时会差别比较大，所以想分析下。本文先看下tf.metrics.auc的实现。 首先看下tf.metrics.auc的函数定义： 12345678910@tf_export('metrics.auc')def auc(labels, predictions, weights=None, num_thresholds=200, metrics_collections=None, updates_collections=None, curve='ROC', name=None, summation_method='trapezoidal') tf.metrics.auc的参数有三个比较重要。labels和predictions是必须参数，labels就是二分类问题的类别集合，一般就是0&#x2F;1的集合，predictions就是模型的预测得分集合，是一个0-1的浮点数的集合。num_thresholds参数也很重要，这个参数控制了划分成多少个梯形计算面积。默认是200，可以根据batch大小进行调整。 再看下tf.metrics.auc的具体实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798 @tf_export('metrics.auc')def auc(labels, predictions, weights=None, num_thresholds=200, metrics_collections=None, updates_collections=None, curve='ROC', name=None, summation_method='trapezoidal'): if context.executing_eagerly(): raise RuntimeError('tf.metrics.auc is not supported when eager execution ' 'is enabled.') with variable_scope.variable_scope(name, 'auc', (labels, predictions, weights)): if curve != 'ROC' and curve != 'PR': raise ValueError('curve must be either ROC or PR, %s unknown' % (curve)) kepsilon = 1e-7 # to account for floating point imprecisions thresholds = [ (i + 1) * 1.0 / (num_thresholds - 1) for i in range(num_thresholds - 2) ] # thresholds是在[0-1]中分num_thresholds个段，而首尾加一个微量值避免0和1. thresholds = [0.0 - kepsilon] + thresholds + [1.0 + kepsilon] values, update_ops = _confusion_matrix_at_thresholds( labels, predictions, thresholds, weights) # Add epsilons to avoid dividing by 0. epsilon = 1.0e-6 def interpolate_pr_auc(tp, fp, fn): dtp = tp[:num_thresholds - 1] - tp[1:] p = tp + fp prec_slope = _safe_div(dtp, p[:num_thresholds - 1] - p[1:], 'prec_slope') intercept = tp[1:] - math_ops.multiply(prec_slope, p[1:]) safe_p_ratio = array_ops.where( math_ops.logical_and(p[:num_thresholds - 1] &gt; 0, p[1:] &gt; 0), _safe_div(p[:num_thresholds - 1], p[1:], 'recall_relative_ratio'), array_ops.ones_like(p[1:])) return math_ops.reduce_sum( _safe_div( prec_slope * (dtp + intercept * math_ops.log(safe_p_ratio)), tp[1:] + fn[1:], name='pr_auc_increment'), name='interpolate_pr_auc') def compute_auc(tp, fn, tn, fp, name): \"\"\"Computes the roc-auc or pr-auc based on confusion counts.\"\"\" if curve == 'PR': if summation_method == 'trapezoidal': logging.warning( 'Trapezoidal rule is known to produce incorrect PR-AUCs; ' 'please switch to \"careful_interpolation\" instead.') elif summation_method == 'careful_interpolation': # This one is a bit tricky and is handled separately. return interpolate_pr_auc(tp, fp, fn) rec = math_ops.div(tp + epsilon, tp + fn + epsilon) # math_ops.div()除法 if curve == 'ROC': #auc是roc曲线的下面积 fp_rate = math_ops.div(fp, fp + tn + epsilon) x = fp_rate y = rec else: # curve == 'PR'. prec = math_ops.div(tp + epsilon, tp + fp + epsilon) x = rec y = prec if summation_method in ('trapezoidal', 'careful_interpolation'): #默认参数是trapezoidal # Note that the case ('PR', 'careful_interpolation') has been handled # above. return math_ops.reduce_sum( math_ops.multiply(x[:num_thresholds - 1] - x[1:], (y[:num_thresholds - 1] + y[1:]) / 2.), name=name) elif summation_method == 'minoring': return math_ops.reduce_sum( math_ops.multiply(x[:num_thresholds - 1] - x[1:], math_ops.minimum(y[:num_thresholds - 1], y[1:])), name=name) elif summation_method == 'majoring': return math_ops.reduce_sum( math_ops.multiply(x[:num_thresholds - 1] - x[1:], math_ops.maximum(y[:num_thresholds - 1], y[1:])), name=name) else: raise ValueError('Invalid summation_method: %s' % summation_method) # sum up the areas of all the trapeziums auc_value = compute_auc(values['tp'], values['fn'], values['tn'], values['fp'], 'value') update_op = compute_auc(update_ops['tp'], update_ops['fn'], update_ops['tn'], update_ops['fp'], 'update_op') if metrics_collections: ops.add_to_collections(metrics_collections, auc_value) if updates_collections: ops.add_to_collections(updates_collections, update_op) return auc_value, update_op tf.metrics.auc函数返回了两个值auc_value和update_op。auc_value就是我们需要的值，但是需要注意的是，只有必须先sess.run(update_op)之后才可以得到auc_value值。怎么理解呢？看下面代码就明白了。原因在后面介绍。 123auc_value, update_op = tf.metrics.auc(labels=target, predictions=predictions_score, name=\"auc_metric\", num_thresholds=512)_ = sess.run(update_op)auc = sess.run(auc_value) 看第87-90代码可知，auc_value和update_op是通过一个compute_auc()函数计算得到的，compute_auc()的传入参数貌似是混淆矩阵的四个值。 而在compute_auc函数中，57-61行中计算了真正例率rec和假正例率fp_rate，分别对应roc曲线的横坐标x和纵坐标y。66-72行计算了roc曲线下面积的小梯形之和。也就是说compute_auc()函数传入的是混淆矩阵的四个值，通过计算roc曲线下面积的小梯形之和得到auc返回。 再回过来看下97-90行，auc_value和update_op不同在于values和update_ops变量，update_op貌似是个op，而auc_value是标量值。values, update_ops的计算在25行的_confusion_matrix_at_thresholds()函数，其传入的参数是分别是labels, predictions, thresholds, weights(默认值None)。labels, predictions不多说，而thresholds是在[0-1]中分num_thresholds个段，而首尾加一个微量值避免0和1。可以猜想下，是根据num_thresholds个段作为分类阈值计算混淆矩阵的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120def _confusion_matrix_at_thresholds(labels, predictions, thresholds, weights=None, includes=None): all_includes = ('tp', 'fn', 'tn', 'fp') if includes is None: includes = all_includes else: for include in includes: if include not in all_includes: raise ValueError('Invalid key: %s.' % include) with ops.control_dependencies([ check_ops.assert_greater_equal( #断言，检查输入 predictions, math_ops.cast(0.0, dtype=predictions.dtype), message='predictions must be in [0, 1]'), check_ops.assert_less_equal( predictions, math_ops.cast(1.0, dtype=predictions.dtype), message='predictions must be in [0, 1]') ]): # 对predictions和labels进行类型规范 predictions, labels, weights = _remove_squeezable_dimensions( predictions=math_ops.to_float(predictions), labels=math_ops.cast(labels, dtype=dtypes.bool), weights=weights) num_thresholds = len(thresholds) # Reshape predictions and labels. predictions_2d = array_ops.reshape(predictions, [-1, 1]) labels_2d = array_ops.reshape( math_ops.cast(labels, dtype=dtypes.bool), [1, -1]) # Use static shape if known. num_predictions = predictions_2d.get_shape().as_list()[0] # Otherwise use dynamic shape. if num_predictions is None: num_predictions = array_ops.shape(predictions_2d)[0] thresh_tiled = array_ops.tile( # tile之后产生了num_thresholds*num_predictions的阈值矩阵 array_ops.expand_dims(array_ops.constant(thresholds), [1]), #expand_dims和reshape等价，但是palceloader无法使用reshape，这里产生了num_thresholds*1的阈值矩阵 array_ops.stack([1, num_predictions])) #stack之后产生了[1,num_predictions] # Tile the predictions after thresholding them across different thresholds. pred_is_pos = math_ops.greater( array_ops.tile(array_ops.transpose(predictions_2d), [num_thresholds, 1]), thresh_tiled) if ('fn' in includes) or ('tn' in includes): pred_is_neg = math_ops.logical_not(pred_is_pos) # Tile labels by number of thresholds label_is_pos = array_ops.tile(labels_2d, [num_thresholds, 1]) if ('fp' in includes) or ('tn' in includes): label_is_neg = math_ops.logical_not(label_is_pos) if weights is not None: weights = weights_broadcast_ops.broadcast_weights( math_ops.to_float(weights), predictions) weights_tiled = array_ops.tile( array_ops.reshape(weights, [1, -1]), [num_thresholds, 1]) thresh_tiled.get_shape().assert_is_compatible_with( weights_tiled.get_shape()) else: weights_tiled = None values = &#123;&#125; update_ops = &#123;&#125; if 'tp' in includes: true_p = metric_variable( [num_thresholds], dtypes.float32, name='true_positives') is_true_positive = math_ops.to_float( math_ops.logical_and(label_is_pos, pred_is_pos)) if weights_tiled is not None: is_true_positive *= weights_tiled update_ops['tp'] = state_ops.assign_add(true_p, math_ops.reduce_sum( is_true_positive, 1)) #1是维度 values['tp'] = true_p if 'fn' in includes: false_n = metric_variable( [num_thresholds], dtypes.float32, name='false_negatives') is_false_negative = math_ops.to_float( math_ops.logical_and(label_is_pos, pred_is_neg)) if weights_tiled is not None: is_false_negative *= weights_tiled update_ops['fn'] = state_ops.assign_add(false_n, math_ops.reduce_sum( is_false_negative, 1)) values['fn'] = false_n if 'tn' in includes: true_n = metric_variable( [num_thresholds], dtypes.float32, name='true_negatives') is_true_negative = math_ops.to_float( math_ops.logical_and(label_is_neg, pred_is_neg)) if weights_tiled is not None: is_true_negative *= weights_tiled update_ops['tn'] = state_ops.assign_add(true_n, math_ops.reduce_sum( is_true_negative, 1)) values['tn'] = true_n if 'fp' in includes: false_p = metric_variable( [num_thresholds], dtypes.float32, name='false_positives') is_false_positive = math_ops.to_float( math_ops.logical_and(label_is_neg, pred_is_pos)) if weights_tiled is not None: is_false_positive *= weights_tiled update_ops['fp'] = state_ops.assign_add(false_p, math_ops.reduce_sum( is_false_positive, 1)) values['fp'] = false_p return values, update_ops 以values[‘tp’]为例看下values是怎么得到的(72-82行)。可以看到values[&#39;tp&#39;] = true_p，而在73行true_p还没有赋值，仅仅是通过metric_variable()函数创建本地变量（Create variable in GraphKeys.(LOCAL|METRIC_VARIABLES) collections）。在第75行计算了真正例is_true_positive（真正例简称tp，即真实label是正例且预测也是正例），然后79行将tp和通过函数assign_add()加到了true_p上，然后返回op赋值给update_ops[‘tp’]。最后true_p赋值给了values[‘tp’]。**需要注意的是assign_add()返回的是op，所以如果想得到true_p的值必须先计算op(update_ops[‘tp’])**，这就解释了上文的问题。可以再看下assign_add()定义： 1234567891011121314151617181920212223@tf_export(\"assign_add\")def assign_add(ref, value, use_locking=None, name=None): \"\"\"Update 'ref' by adding 'value' to it. This operation outputs \"ref\" after the update is done.先更新才可以得到ref This makes it easier to chain operations that need to use the reset value. Args: ref: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int64`, `int32`, `uint8`, `uint16`, `int16`, `int8`, `complex64`, `complex128`, `qint8`, `quint8`, `qint32`, `half`. Should be from a `Variable` node. value: A `Tensor`. Must have the same type as `ref`. The value to be added to the variable. use_locking: An optional `bool`. Defaults to `False`. If True, the addition will be protected by a lock; otherwise the behavior is undefined, but may exhibit less contention. name: A name for the operation (optional). Returns: Same as \"ref\". Returned as a convenience for operations that want to use the new value after the variable has been updated. \"\"\" 然后看下怎么计算真正例is_true_positive的。math_ops.logical_and(label_is_pos, pred_is_pos)是对label_is_pos和pred_is_pos进行与操作。现在问题变成了分析label_is_pos和pred_is_pos是怎么来的。看58-59行。array_ops.tile(array_ops.transpose(predictions_2d), [num_thresholds, 1])得到的是num_thresholds*num_predictions的矩阵A，array_ops.transpose(predictions_2d)是1*n的矩阵，n对应batch大小为n的n个得分。使用tile沿着第0维复制num_thresholds次。thresh_tiled是num_thresholds*num_predictions的阈值矩阵。使用math_ops.greater()函数之后，如果predictions中元素大于阈值则返回True，否则False，最后得到了值为True&#x2F;False的list，也就是pred_is_pos（预测为正），其它同理。所以在76行通过logical_and得到了is_true_positive真正例。 emm，大概就这样。","tags":[{"name":"auc","slug":"auc","permalink":"http://aeyoo.net/tags/auc/"},{"name":"tf","slug":"tf","permalink":"http://aeyoo.net/tags/tf/"}]},{"title":"auc是什么","date":"2020-03-19T07:00:02.000Z","path":"2020/03/19/auc是什么/","text":"auc 是机器学习中二分类问题的常用评价指标，其反映了分类器对正负样本的排序能力。本文介绍一下 auc 指标，然后介绍下 tf.metrics.auc()函数。 性能度量1 错误率与精度错误率是分类错误的样本数占样本总数的比例，精度是分类正确的样本数占样本总数的比例。 2 查准率，查全率对于二分类问题，可以将样例根据其真实类别与学习器预测类别的组合分为真正例，假正例，真反例，假反例，令TP，FP，TN，FN分别表示其对应的样例数，则TP+FP+TN+FN&#x3D;样例总数。分类结果的混淆矩阵如下表所示： 真实情况 \\ 预测结果 正例(预测) 反例（预测） 正例(真实) TP（真正例） FN（假反例） 反例(真实) FP（假正例） TN（真反例） 查准率P与查全率R分别定义为：$$P&#x3D;\\frac{TP}{TP+FP}$$ $$R&#x3D;\\frac{TP}{TP+FN}$$ 简单来说，查准率就是在预测结果为正例的样本中，真实为正例的占比；查全率就是在真实为正例的样本中，预测结果为正例的占比。查准率和查全率是一对矛盾的度量。 在很多情况下，可以根据学习器的预测结果对样例进行排序，排在前面的是学习器认为最优可能是正例的样本，后面的最不可能为正例。按此顺序逐个将样本作为正例（例如在二分类神经网络中通过调整阈值控制正反例个数），则每次可以计算出当前的查全率，查准率。以查准率为纵轴，查全率为横轴作图，可以得到查准率-查全率曲线，简称“P-R曲线”，显示该曲线的图称为“P-R图”。如下图所示。 P-R曲线下面积越大，则表示该学习器性能越好。关于F1度量貌似不怎么用到，这里就不说了。 3 ROC与AUCAUC是机器学习中的一个重要二分类指标，其反映了模型对正负样本的排序能力，用通俗的话讲就是，用来评估模型对正负样本的区分能力。 和P-R曲线生成的过程类似，如果将计算查全率，查准率改为计算真正例率TPR，假正例率FPR，并以横轴为假正例率，纵轴为真正例率，可以得到ROC曲线（受试者工作特征），分别定义为：$$TPR&#x3D;\\frac{TP}{TP+FN}$$ $$FPR&#x3D;\\frac{FP}{TN+FP}$$ 真正例率TPR表示的是在真实为正例的样本中，预测为正例的占比；假正例率FPR表示的是真实为反例的样本中，预测为正例的占比。 显示ROC曲线的图称为ROC图，如下图所示。下图a给出了一个示意图，对角线对应于“随机猜测”模型。点(0,1)对应于将所有正例排在所有反例之前的理想模型。 同P-R图类似，如果ROC曲线下面积越大，则学习器更优。ROC曲线下面积的值也叫AUC（Area Under ROC Curve）。 从定义可知，AUC可通过对ROC曲线下各部分面积求和而得。假定ROC曲线由坐标为${(x_1,y_1), …, (x_m,y_m)}$的点按序连接而成，则AUC可估算为$$AUC&#x3D;\\frac{1}{2}\\sum_{i&#x3D;1}^{m-1}{(x_{i+1}-x_i)}\\cdot{(y_i+y_{i+1})}$$形式化看，AUC考虑的是样本预测的排序质量。 那么如何绘制roc曲线呢？很简单，机器学习一书中已经给了很明确的介绍。 根据有限个点画出roc曲线之后，会发现roc曲线下面积是由一个个小梯形组成。事实上，很多的计算auc的方法都是通过计算小梯形面积之和得到的。选择的分类阈值不同，那么得到auc的值也不同。 TF 实现在TF1.x 中实现了tf.metrics.auc()函数可以用来计算 AUC。 函数原型如下： 12345678910def auc(labels, predictions, weights=None, num_thresholds=200, metrics_collections=None, updates_collections=None, curve='ROC', name=None, summation_method='trapezoidal', thresholds=None) 可以看到，只有前两个参数是必须的，其它参数都有默认值。labels 是当前batch训练集的类别集合，predictions表示当前 batch 训练集的输出得分（0-1之前的浮点数）。需要注意的是，num_thresholds参数也是很重要的，它影响了 auc 计算的精度，一般设置num_thresholds&lt;&#x3D;batch size。 auc 函数的返回值有两个：auc_value, update_op。前者应该是单次 batch 的 auc，后者表示当前batch及之前 batch 的均值。文章《Tensorflow： AUC的错误&#x2F;问题与修正》也说明了这点，注意看评论。 另外在 TF1.x 中是通过先计算混淆矩阵，然后计算ROC 下面积的一个个小梯形之和得到 AUC 的。 12345678910111213141516171819202122232425def compute_auc(tp, fn, tn, fp, name): \"\"\"Computes the roc-auc or pr-auc based on confusion counts.\"\"\" if curve == 'PR': if summation_method == 'trapezoidal': logging.warning( 'Trapezoidal rule is known to produce incorrect PR-AUCs; ' 'please switch to \"careful_interpolation\" instead.') elif summation_method == 'careful_interpolation': # This one is a bit tricky and is handled separately. return interpolate_pr_auc(tp, fp, fn) rec = math_ops.div(tp + epsilon, tp + fn + epsilon) if curve == 'ROC': fp_rate = math_ops.div(fp, fp + tn + epsilon) x = fp_rate y = rec else: # curve == 'PR'. prec = math_ops.div(tp + epsilon, tp + fp + epsilon) x = rec y = prec if summation_method in ('trapezoidal', 'careful_interpolation'): # 一般传入的参数默认是trapezoidal return math_ops.reduce_sum( math_ops.multiply(x[:num_thresholds - 1] - x[1:], (y[:num_thresholds - 1] + y[1:]) / 2.), name=name) 参考文献周志华 机器学习。 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} });","tags":[{"name":"指标","slug":"指标","permalink":"http://aeyoo.net/tags/指标/"},{"name":"auc","slug":"auc","permalink":"http://aeyoo.net/tags/auc/"}]},{"title":"nextitnet源码解读","date":"2020-03-14T17:21:48.000Z","path":"2020/03/15/nextitnet源码解读/","text":"nextitnet的源码比较通俗易懂，十分有助于理解论文 idea。简单来说，输入是item 时间序列的集合（源数据的item 序列的长度是5），然后经过nextitnet_residual_block网络结构进行堆叠，网络结构的 channel是一个常量dilated_channels（100），该值同时也是item embedding 的长度。堆叠的nextitnet_residual_block网络最后一层的输出和输入的 shape 一致，都是[batch, seq_len, channel&#x2F;item embedding长度]，为了建立item seq和所有 item的联合概率分布，作者在nextitnet_residual_block网络的最后一层加了一个卷积层，卷积核 shape 为[1,1,dilated_channels, items_size]，所以最终的输出的 shape 是[batch, seq_len, items_size]（**原来我总感觉这里有点强转了，但是后来想了想，经典cnn结构不也是将三维打平然后映射到 n 个类别吗？**）。 发完牢骚再来一发代码解读吧，写博客真的一定要坚持下来啊啊！看似浪费时间，实则有益无害。最近因为科研了解了下 nextitnet网络，看论文的话有点抽象但是阅读完作者代码之后感觉还行，看一遍代码可能不够。 未完待续。","tags":[]},{"title":"静夜思","date":"2020-03-14T16:54:32.000Z","path":"2020/03/15/静夜思/","text":"晚上打完游戏后，再次来到电脑前突然想起了海博学长，海博学长是一个学霸而且人特别好。记得上一次和海博学长联系好像是6年前的事情了，刚上大一的时候听完东大留学群的讲座之后内心无比激动，心心念念地想去CMU，然后和学长聊了两三次，学长还和我说了他对自己的规划，以及希望在CMU看到我。但后来由于某些原因我放弃了去CMU的念头。 刚刚去看了海博学长在 QQ 空间的日志，最近无比颓废的我被他的积极乐观感染到了，也许我给别人的印象有点像学长给我的印象，学长讲述了他在 CMU 求学求职的经历给了我不小的震撼，尤其是他那种做事情全力以赴的性格。对于写日志这件事，我曾经是比较喜欢的而后又拒绝，也可能生活不近如意难以用文字描述吧。不过写日志这件事有助于记录过往，也有助于认识自己，对于未来的自己可能是一笔宝贵的财富和回忆，但是我每每写到一半就放弃了，觉得有点浪费时间。 最近还是有事情困扰着我，工作越来越繁忙，我也越来越烦躁，还有一些工作之外的事情同时困扰着我。不过了解了学长的生活之后，我突然觉得可能是自己最近太懒散了吧，心态是第一位的，提高工作效率是第二位的，挤时间可以排到第三位。emm，我又看了沈学长的博客，感觉顿时又充满了力量。 高效工作需要充沛的体力，另外我觉得我还是适合夜间工作，白天始终静不下来，这是毛病，得治。 学霸养成中。","tags":[{"name":"觉悟","slug":"觉悟","permalink":"http://aeyoo.net/tags/觉悟/"}]},{"title":"TFRecord读写数据","date":"2020-02-22T09:08:56.000Z","path":"2020/02/22/TFRecord读写数据/","text":"tensorflow 官方推荐使用TFRecord进行数据读写，因为这样效率更高。TFRecord是一种使用pb协议序列化的二进制存储格式。为了高效读取数据，TFRecord将数据序列化并存储在一组文件中实现线性读取（每个文件大概100M-200M，官方说的）。tf.train.Example就是 pb 协议中的消息(Message)定义，下面是代码。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#coding:utf8import tensorflow as tfdef _parse_record_train_dat(example_proto): features = &#123; 'idx' : tf.FixedLenFeature([], tf.int64), 'fields_num': tf.FixedLenFeature([], tf.int64), 'data' : tf.FixedLenFeature([], tf.string) &#125; parsed_feats = tf.parse_single_example(example_proto, features = features) return parsed_featsdef gen_tfrecord_train_dat(input, output): writer = tf.python_io.TFRecordWriter(output) # data = tf.read_file(input) fin = open(input) lines = fin.readlines() fields_num = len(lines[0].split(\",\")) for i, line in enumerate(lines): line = line.strip(\"\\r\\n\") # 这里kv中的k不能写错 example = tf.train.Example(features = tf.train.Features(feature = &#123; 'idx': tf.train.Feature(int64_list = tf.train.Int64List(value = [i])), 'fields_num': tf.train.Feature(int64_list = tf.train.Int64List(value = [fields_num])), 'data': tf.train.Feature(bytes_list = tf.train.BytesList(value = [line])) &#125;)) writer.write(example.SerializeToString()) writer.close()def write_to_local(ary, path): fout = open(path, \"a+\") for ele in ary: fout.write(ele + \"\\n\") fout.close()def read_tfrecord_train_dat(input, output): dataset = tf.data.TFRecordDataset(input) dataset = dataset.map(_parse_record_train_dat) iter = dataset.make_one_shot_iterator() rows = [] with tf.Session() as sess: try: while True: example = sess.run(iter.get_next()) idx = example['idx'] fields_num = example['fields_num'] data = example['data'] rows.append(data) print(\"--------\") print(idx) print(fields_num) print(data) except tf.errors.OutOfRangeError: print(\"OutOfRangeError\") write_to_local(rows, output)if __name__ == \"__main__\": print(tf.version) gen_tfrecord_train_dat(\"data/test.dat\", \"data/test.dat.tfrecord\") read_tfrecord_train_dat(\"data/test.dat.tfrecord\", \"data/test.dat.tfrecord.recover\") print(\"success!\") 上述代码使用 python 生成了 TFRecord文件，但是通常使用Spark 生成，具体方法参考ecosystem。上述代码不是最优的，仅仅为了理解TFRecord。 参考： https://www.tensorflow.org/tutorials/load_data/tfrecord","tags":[{"name":"TFRecord","slug":"TFRecord","permalink":"http://aeyoo.net/tags/TFRecord/"}]},{"title":"《Network Pruning via Transformable Architecture Search》论文实验解读","date":"2020-02-18T02:17:50.000Z","path":"2020/02/18/《Network-Pruning-via-Transformable-Architecture-Search》论文实验解读/","text":"该论文在CIFAR-10，CIFAR-100 [27]和ImageNet [6]上进行了评估。 CIFAR-10包含10个类别的50K训练图像和10K测试图像。 CIFAR-100与CIFAR-10类似，但有100个类别。 ImageNet包含128万个训练图像和50000个测试图像以及1000个类别。 论文在这三个数据集上进行了数据扩充，具体地，在CIFAR-10和CIFAR-100上，随机裁剪成32×32的块(patch)，在每个边界填充4个像素，并且还应用了随机水平翻转。 在ImageNet上，我们使用经典方法随机裁剪大小，随机更改亮度&#x2F;对比度&#x2F;饱和度，并随机进行水平翻转以进行数据增强。 在评估过程中，论文将图像大小调整为256×256，并在中央裁剪了224×224的块。 1 设置1.1 搜索设置We search the number of channels over {0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0} of the original number in the unpruned network。 我们在每个卷积阶段搜索深度，同时设置$I&#x3D;2$ ($I$表示候选集个数)，为了减少搜索过程中的GPU内存成本，我们根据修剪算法的FLOP设置R，并将$λ_{cost}$设置为2。此外，通过SGD优化权重，通过Adam评估结构参数。 对于权重，我们设置学习率从0.1开始，并通过余弦调度器（cosine scheduler）降低学习率[34]。 对于结构参数，我们使用0.001的恒定学习率和0.001的权重衰减值。 在CIFAR-10和CIFAR-100上，我们训练模型的单个batch 大小为256，共600个epochs。在ImageNet上，我们训练ResNets的单个batch 大小为256，共120个epochs [17]。容忍度$t$始终设置为5％。 等式3中的 $\\tau$ 从10线性衰减到0.1。 1.2 训练对于CIFAR实验，我们使用动量为0.9，权重衰减值为0.0005的SGD。 我们将每个模型训练300个epoch，设置学习率从0.1开始，并通过余弦调度器降低学习率[34]。 我们使用\u0010大小为256的batch和2个GPU。 在CIFAR上使用KD时，我们设置$\\lambda$为0.9，温度T为4。 对于ImageNet上的ResNet模型，我们遵循大多数CIFAR的超参数，但是设置权重衰减为0.0001。 我们使用4个GPU，120个epoch训练模型，batch大小为256。在ImageNet上使用KD时，在ImageNet上将$\\lambda$设置为0.5，将T设置为4。 2 实验分析在本节中，我们评估了TAS的不同方面。 我们还将其与不同的搜索算法和知识迁移方法进行比较，以证明TAS的有效性。 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} });","tags":[{"name":"NAS","slug":"NAS","permalink":"http://aeyoo.net/tags/NAS/"}]},{"title":"极限生存的思考","date":"2020-02-16T16:10:06.000Z","path":"2020/02/17/极限生存的思考/","text":"今天又是虚度的一天。早上还志向满满，结果上午经受不住诱惑，mac升级了最新的系统 catalina，然后电脑开启疯狂 bug 模式，对于我这样有完美倾向的人来说简直是一场灾难。不过也确实是我大意了，尽管事先问了两个朋友新系统体验如何，但这就像小马过河的故事，因人而异。那两位朋友基本不怎么使用命令行工具所以感觉还行，对于我这个基本上依赖于命令行生活的人来说，此次 mac 最大的变化就是提升了命令行下的权限，普通用户不能随意在根目录下操作，否则会提示Read-only file system。如果你之前在根目录下新建了一个目录 a，那么升级 catalina时会将目录 a 移动至别的地方。 其实这个问题也不算大问题，曲线救国也是可以解决的。方法如下： 开机cmd+r，进入恢复模式，然后关闭 SIP(在终端执行 csrutil disable)，重启； 重新挂在根目录，执行sudo mount -uw / ，重新挂载根目录的目的在于可以有短暂的权限操作根目录； 建立软链接，执行sudo ln -s xxx/a /。 开机cmd+r，进入恢复模式，然后开启 SIP(在终端执行 csrutil enable)，重启。 这样就暂时解决上述问题。 不过问题远不止如此，像 git 环境，hexo 环境在这次升级过程中都会遭到破坏，例如升级后在终端执行 git 会报错如下： 1xcrun: error: invalid active developer path, missing xcrun 解决如下： 1xcode-select --install 还有风扇更容易狂转不止，掉电很快的问题，不忍直视。 这个故事告诉我们，除了科研，其它事情上我们不要好奇心那么重，太惨了。 本来想使用 shift+opt+cmd+r直接系统降级的，但是一直报错1008F，即使执行了如下操作： 恢复模式下，在启动安全性实用工具中的“安全启动”更改为“无安全性”设置； 在上述界面，将”外部启动“更改为“允许从外部介质启动”，完成更改后请先关闭您的 Mac。 我觉得有时间可以尝试 u 盘安装，毕竟我基本上没有使用shift+opt+cmd+r降级成功的经历。还有人说 catalina 的很多坑是由10.14直接升级带来的，如果抹盘装 catalina 的话基本没有问题，这个我就不尝试了，万一再出点啥问题我怕是周一上不了班了。 在重装系统，整理资料的过程中思考一个问题：如果电脑突然坏掉里面的数据再也找不回来了，会发生什么。想到这里不禁打了一个冷战。 周一上班加油吧，下次不再瞎折腾了，稳定优先。","tags":[{"name":"极限生存","slug":"极限生存","permalink":"http://aeyoo.net/tags/极限生存/"}]},{"title":"pytorch Module介绍","date":"2020-02-05T14:13:51.000Z","path":"2020/02/05/pytorch-Module介绍/","text":"之前没有学过 pytorch，最近在看 pytorch的代码时以 tf 的思维去看，很多 module 相关的内容看的似懂非懂，所以把 module 部分拿出来学习一下。先附上相关资源连接。 官方 api, 英文 翻译 api, 中文 module 是 pytorch nn包下的一个类（class torch.nn.Module）。torch nn下包含了一些常见的网络结构供我们使用，其中，class torch.nn.Module是所有网络的基类。Modules也可以包含其它Modules，允许使用树结构嵌入它们，可以将子Module赋值给Module的属性。 1 torch.nn首先看下torch.nn包里都有些什么东西。 可以看到，torch.nn 已经为我们实现了常见的 cnn 网络层、rnn 网络层，另外还实现了dropout 层、损失函数等。Parameters是一种tensor，可以被看做是 module 的参数。Parameters是tensor 的一个子类，它有一个特别的属性：当作为 module 的属性时，它会自动被加入到module 的参数列表（也就是parameters()迭代器中)。但是将tensor赋给module 属性则不会产生上述效果。这样做的原因是可能要在模型中缓存一些临时状态，如 RNN 最后一个隐状态。**如果没有 Parameters，那么这些临时变量也会注册为模型变量【这个没看懂】**。 需要注意的是，在 pytorch0.3.1版本及其之前，Parameters是 torch.autograd.Variable 的一个子类；而在高版本的 pytorch 中，Variable类已经被废弃，Autograd 自动支持 tensor 并设置 reguires_grad 为 True，下面是一些变化。 Variable(tensor)和Variable(tensor, requires_grad)仍然可以使用，但是返回的不是 Variable不是tensor。 Variable.data 和 tensor.data 是相同的。 Variable.backward(), Variable.detach(), Variable.register_hook() 等方法可以在 tensor 上以相同的方法名使用。 可以创建 tensor 并设置 requires_grad为True。例如：autograd_tensor=torch.randn((2,3,4),requires_grad=True)。 再看下Parameter的实现： 123456789101112131415161718192021222324252627282930class Parameter(torch.Tensor): \"\"\" Arguments: data (Tensor): parameter tensor. requires_grad (bool, optional): if the parameter requires gradient. See :ref:`excluding-subgraphs` for more details. Default: `True` \"\"\" def __new__(cls, data=None, requires_grad=True): if data is None: data = torch.Tensor() return torch.Tensor._make_subclass(cls, data, requires_grad) def __deepcopy__(self, memo): if id(self) in memo: return memo[id(self)] else: result = type(self)(self.data.clone(memory_format=torch.preserve_format), self.requires_grad) memo[id(self)] = result return result def __repr__(self): return 'Parameter containing:\\n' + super(Parameter, self).__repr__() def __reduce_ex__(self, proto): # See Note [Don't serialize hooks] return ( torch._utils._rebuild_parameter, (self.data, self.requires_grad, OrderedDict()) ) 在 pytorch0.3.1之前存在 Tensor、Variable、Parameter 等名词，如果不清楚的话可以参考博客《Pytorch 中的 Tensor , Variable &amp; Parameter》。 2 torch.nn.Module在官方文档中，Module 被放在Containers下，我觉得可能是考虑到Module 类是最基本的类吧。Containers下主要是一些容器类，如下图所示。 上面这些容器类讲起来比较久，下次再介绍，这里大概知道有这些就好了。 下图是 torch.nn.Module 的所有方法。 如果要实现自己的module 的话，必须重写forward(*input)方法，网络的计算逻辑（将不同的网络层连接在一起）都在该函数中实现。而网络层通常在__init__函数中实现。如下： 123456789101112import torch.nn as nnimport torch.nn.functional as Fclass Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5)# submodule: Conv2d self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x)) return F.relu(self.conv2(x)) 3 参考文献 Pytorch 中的 Tensor , Variable &amp; Parameter 官方 api, 英文 翻译 api, 中文","tags":[{"name":"pytorch","slug":"pytorch","permalink":"http://aeyoo.net/tags/pytorch/"},{"name":"module","slug":"module","permalink":"http://aeyoo.net/tags/module/"}]},{"title":"阅读《Network Pruning via Transformable Architecture Search》论文源码","date":"2020-02-04T08:21:56.000Z","path":"2020/02/04/阅读《Network-Pruning-via-Transformable-Architecture-Search》论文源码/","text":"最近在阅读论文《Network Pruning via Transformable Architecture Search》的源码，其主要实现了结构化自动裁剪神经网络的逻辑（也算是autoML的部分），由 pytorch 实现。特此记录。 1 先说几个值得学习的地方 解耦。eg，网络层解耦；声明专门的类用于神经网络层的各种定义，包括网络层（输入输出），网络的连接，前向传播逻辑，优化器的定义等等。定义各个网络层之后，在 forwords 方法中构建网络。如下所示。 123456789def basic_forward(self, inputs): if self.InShape is None: self.InShape = (inputs.size(-2), inputs.size(-1)) x = inputs for i, layer in enumerate(self.layers): x = layer( x ) features = self.avgpool(x) features = features.view(features.size(0), -1) logits = self.classifier(features) return features, logits 充分使用日志。这个是之前自己做的不好的部分，往往只会在调试时才开始加入全面的日志。 其实网络层的解耦是最最基础的，通过阅读 github 源码你会发现但凡是一些知名学者的代码都是进行良好的封装，实现各个模块解耦以便于后期快速增减各种逻辑，不过对于初学者来说阅读这样的代码就会感觉项目异常庞大，因为存在许多不相关的逻辑。某种程度上来说，过高的抽象封装可能会导致可阅读性的降低。 2 架构搜索思想分析论文提出到的 NAS 架构搜索主要是搜索网络的宽度和深度。宽度指的是各层的 channal 数量(层输出)，深度指的是网络的层数。论文着重介绍了如何求解各层最优的 channal。 3 重点剖析论文的重点在于如何实现自动裁剪网络结构，核心代码如下： 12345678910111213141516171819def search_forward(self, inputs): flop_probs = nn.functional.softmax(self.width_attentions, dim=1) selected_widths, selected_probs = select2withP(self.width_attentions, self.tau) with torch.no_grad(): selected_widths = selected_widths.cpu() x, last_channel_idx, expected_inC, flops = inputs, 0, 3, [] for i, layer in enumerate(self.layers): selected_w_index = selected_widths[last_channel_idx: last_channel_idx+layer.num_conv] selected_w_probs = selected_probs[last_channel_idx: last_channel_idx+layer.num_conv] layer_prob = flop_probs[last_channel_idx: last_channel_idx+layer.num_conv] x, expected_inC, expected_flop = layer( (x, expected_inC, layer_prob, selected_w_index, selected_w_probs) ) last_channel_idx += layer.num_conv flops.append( expected_flop ) flops.append( expected_inC * (self.classifier.out_features*1.0/1e6) ) features = self.avgpool(x) features = features.view(features.size(0), -1) logits = linear_forward(features, self.classifier) return logits, torch.stack( [sum(flops)] ) 下面一行一行进行分析。 3.1 line 1先看下self.width_attentions是个什么东西，其相关定义在类SearchWidthCifarResNet中： 123456789101112# parameters for widthself.Ranges = []self.layer2indexRange = []for i, layer in enumerate(self.layers): start_index = len(self.Ranges) self.Ranges += layer.get_range() self.layer2indexRange.append( (start_index, len(self.Ranges)) )assert len(self.Ranges) + 1 == depth, 'invalid depth check &#123;:&#125; vs &#123;:&#125;'.format(len(self.Ranges) + 1, depth)self.register_parameter('width_attentions', nn.Parameter(torch.Tensor(len(self.Ranges), get_choices(None))))nn.init.normal_(self.width_attentions, 0, 0.01)self.apply(initialize_resnet) 这里，width_attentions是一个参数化的 tensor，而 tensor 的参数是(len(self.Ranges, get_choices(None) ))。从上述代码中可以看到，self.Ranges是累加了各个 layer的 get_range() ，所以 len(self.Ranges) 的值也就是网络层数。 再看下get_choices的实现，因为传入的 None，所以 tensor 的参数实际上是(网络层数, 8))。 1234567891011from .SoftSelect import get_width_choices as get_choicesdef get_width_choices(nOut): xsrange = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] if nOut is None: return len(xsrange) else: Xs = [int(nOut * i) for i in xsrange] #xs = [ int(nOut * i // 10) for i in range(2, 11)] #Xs = [x for i, x in enumerate(xs) if i+1 == len(xs) or xs[i+1] &gt; x+1] Xs = sorted( list( set(Xs) ) ) return tuple(Xs) 这里我们再看下self.Ranges，其通过layer.get_range()获得，而layer在类SearchWidthCifarResNet初始化的过程中定义： 1234567891011self.layers = nn.ModuleList( [ ConvBNReLU(3, 16, 3, 1, 1, False, has_avg=False, has_bn=True, has_relu=True) ] ) # 初始化layersself.InShape = Nonefor stage in range(3): for iL in range(layer_blocks): iC = self.channels[-1] planes = 16 * (2**stage) stride = 2 if stage &gt; 0 and iL == 0 else 1 module = block(iC, planes, stride) self.channels.append( module.out_dim ) self.layers.append ( module ) # 增加 layer 到 layers self.message += \"\\nstage=&#123;:&#125;, ilayer=&#123;:02d&#125;/&#123;:02d&#125;, block=&#123;:03d&#125;, iC=&#123;:3d&#125;, oC=&#123;:3d&#125;, stride=&#123;:&#125;\".format(stage, iL, layer_blocks, len(self.layers)-1, iC, module.out_dim, stride) 可以看到，layer实际上是类ConvBNReLU，看看类ConvBNReLU是怎么实现get_range()的。 123456789class ConvBNReLU(nn.Module): def __init__(self, nIn, nOut, kernel, stride, padding, bias, has_avg, has_bn, has_relu): super(ConvBNReLU, self).__init__() self.InShape = None self.OutShape = None self.choices = get_choices(nOut) self.register_buffer('choices_tensor', torch.Tensor( self.choices )) def get_range(self): return [self.choices] 可以看到，get_range()的底层是通过函数get_choices实现的，通过参数nOut进行控制。参数nOut是类ConvBNReLU初始化的时候传入的。在ConvBNReLU初始化的过程中，nOut 表示当前网络层的输出维度。当 nOut !&#x3D; None时，get_width_choices()函数返回的是大小为nOut的 tuple。","tags":[{"name":"NAS","slug":"NAS","permalink":"http://aeyoo.net/tags/NAS/"},{"name":"结构化搜索","slug":"结构化搜索","permalink":"http://aeyoo.net/tags/结构化搜索/"}]},{"title":"20200202","date":"2020-02-02T07:29:01.000Z","path":"2020/02/02/20200202/","text":"假期的效率真的有点低，搞了两天才完成了blog的迁移工作，没想到在普通网络下访问github是如此的慢，最后选择了码云作为托管仓库。从今天起要好好工作了，不然论文真的要延期了。。。除了论文要开始搞起了，计算广告的专业词汇也要大概了解下，OJ的题要刷么么么？啊，要做的事情太多了。。自闭！","tags":[]},{"title":"已悟","date":"2019-11-02T08:42:49.000Z","path":"2019/11/02/已悟/","text":"很久没有写一些东西了，也许真的是因为最近心情差到极点了吧。 戏谑可能是因为本命年运势才这么差，不过闲暇时间想过无数次，可能从我答应老师发一篇论文的时候开始，一切早已命中注定。我从来不信命，即使到现在也是如此，不过最近还真的想去拜拜佛。现在看来，所发生的一切皆有根有据。倘若认真分析的话，可能要从本科的教育体制开始了，虽然这些都不是主观因素，但是量变产生质变。 时间节点回退到刚去ZJU的时候，去ZJU真不知是福是祸。作为过来人，我真的认为如果要从事算法研究，两年的硕士机制真的是性价比最低的一种了，在天赋相近的情况下，一方面拼不过博士和三年的硕士；另一方面相比本科生没有太大的优势。如果时间可以从来，我想我可能还会选择两年的，骨子里是有些自负的。 在过去的一年里，经历过很多的大起大落，幸运的是，自己对待这些事更加的平常心，不过也可能是另外一种无奈吧。有时也会存在巨大的身心压力，但是依然会尽可能地乐观待人。时间有的时候是一把双刃剑，在你渴望需要更多的时间去证明自己的同时，它也会潜移默化地腐蚀你的雄心壮志，适当的危机感是很重要的。 对于我而言，变强是一种内在精神和习惯，在大多数的时间里，我其实不太喜欢懒散的生活。我更倾向于人生是一种体验，而不是以一栋房子或金钱为终极目标。我的目标是做自己想做的事，每天可以体验不同的生活。 过去的一年里，我还有一些体会，随着时间的变化，人总是会发生一些潜移默化的变化，这些变化一方面是源于心智的成熟，另一方面源于环境的变化。即便是思辨能力很强的人，也会不可豁免的接受环境的侵蚀。我一直认为，社交媒体不仅有揭露社会阴暗的责任，更应该有弘扬正能量的使命。环境真的很影响人。一个有意思的现象是，当一个人在某处看到一个有利于自己的观点时，便会产生某种共鸣并坚信这一观点，而很少去思考这个观点正确吗。 我想在机器革命的同时，科技向善，人性向善，思辨向善显得尤为重要。 而我，依然在追求卓越生命力的路上渐行渐远。 每个人都有自己的底线，请不要随意触碰（Don’t push me over the limit at will.）。","tags":[{"name":"thinking","slug":"thinking","permalink":"http://aeyoo.net/tags/thinking/"}]},{"title":"《Network Pruning via Transformable Architecture Search》论文阅读","date":"2019-10-29T12:46:02.000Z","path":"2019/10/29/《Network-Pruning-via-Transformable-Architecture-Search》论文阅读/","text":"网络修剪可减少过度参数化的网络的计算成本，而不会影响性能。现有的修剪算法会预先定义修剪网络的宽度和深度，然后将参数从未修剪的网络传输到修剪的网络。为了突破修剪网络的结构限制，我们提出应用神经架构搜索（NAS）直接搜索具有灵活的通道大小和层大小的网络。通过最小化修剪网络的损失来学习通道&#x2F;层的数量。修剪后的网络的特征图是K个特征图片段的集合（由不同大小的K个网络生成），这些片段是根据概率分布进行采样的。损耗不仅可以反向传播到网络权重，还可以反向传播到参数化分布，以显式调整通道&#x2F;层的大小。具体来说，我们应用逐通道插值（填充）以使具有不同通道大小的特征图在聚合过程中保持对齐。每个分布中的size的最大概率用作修剪网络的宽度和深度，修剪网络的参数是通过知识迁移（例如知识蒸馏）从原始网络中获知的。与传统的网络修剪算法相比，在CIFAR-10，CIFAR-100和ImageNet上进行的实验证明了我们的网络修剪新观点的有效性。进行了各种搜索和知识转移方法以显示这两个组件的有效性。代码位于：https://github.com/D-X-Y/NAS-Projects 1 介绍深度卷积神经网络（CNN）正在变得更宽更深，以在不同的应用程序上实现高性能[17、22、48]。 尽管它们取得了巨大的成功，但将它们部署到资源受限的设备（如移动设备和无人机）上并不可行。 解决该问题的一个直接方案是使用网络修剪[29、12、13、20、18]来减少过参数化CNN的计算成本。 如图1(a)所示，用于网络修剪的典型pipeline是通过删除冗余过滤器，然后基于原始网络微调修剪网络来实现的。基于滤波器重要性的不同技巧被使用，例如滤波器的L2范数[30]，重构误差[20]和可学习的缩放因子[32]。最后，研究人员对修剪后的网络应用了各种微调策略[30，18]，以有效地传递未修剪网络的参数并最大化修剪后的网络的性能。 传统的网络修剪方法在保持准确性的同时，对网络进行了有效地压缩。它们的网络结构是直观设计的，例如，在每一层中裁减30％的滤波器[30、18]，预测稀疏率[15]或利用正则化[2]。修剪后的网络精度受限于人工设计的结构或结构规则。为了克服这个限制，我们使用神经架构搜索（NAS）将架构设计转变为学习过程，并提出了一种新的网络修剪范例，如图1(b)所示。 现有的NAS方法[31、48、8、4、40]优化了网络拓扑，而本文的重点是自动网络规模。为了满足要求并公平地比较以前的修剪策略，我们提出了一种称为可迁移架构搜索（TAS）的新NAS方案。** TAS旨在搜索最佳网络规模而不是拓扑，通过最小化计算成本进行正则化（浮点操作FLOPs）。然后，通过知识迁移来学习搜索&#x2F;修剪网络的参数**[21、44、46]。 TAS是一种可微分的搜索算法，可以有效且高效地搜索网络的宽度和深度。具体而言，不同的候选通道&#x2F;层以可学习的概率被添加到网络中。通过反向传播修剪网络产生的损失来学习概率分布，修剪后网络的特征图是根据概率分布采样的K个特征图片段（不同大小的网络输出）的集合。这些不同通道大小的特征图借助通道插值方式进行汇总。每个分布中概率最大的size用作修剪网络的宽度和深度。 在实验中，我们证明，通过知识蒸馏（KD）传递参数的搜索架构优于之前在CIFAR-10，CIFAR-100和ImageNet上的修剪方法。我们还对传统的人工修剪方法[30，18]和随机架构搜索方法[31]生成的架构测试了不同的知识迁移方法。对不同架构的相同改进证明了知识迁移的普遍性。 2 相关工作网络修剪[29，33]是压缩和加速CNN的有效技术，因此允许我们在存储和计算资源有限的硬件设备上部署有效的网络。已经提出了多种技术，例如低秩分解[47]，权重修剪[14、29、13、12]，通道修剪[18、33]，动态计算[9、7]和量化[23， 1]。它们有两种模式：非结构化修剪[29、9、7、12]和结构化修剪[30、20、18、33]。 非结构化修剪方法[29、9、7、12]通常会 **强制卷积权重[29、14]或特征图[7、9]稀疏**。非结构化修剪的先驱 LeCun等[29]和Hassibi等[14]研究了使用二阶导数信息来修剪浅层CNN的权重。在深度网络于2012年诞生后[28]，Han等人[12，13，11]提出了一系列基于L2正则化获得高度压缩的深度CNN的工作。经过这一发展，许多研究人员探索了不同的正则化技术来提高稀疏度，同时又保持了准确性，例如L0正则化[35]和输出灵敏度[41]。由于这些非结构化方法使大型网络稀疏而不是改变网络的整体结构，因此它们需要针对依赖项的专用设计[11]和特定的硬件来加快推理过程。 结构化修剪方法[30、20、18、33]的目标是 **对卷积过滤器或所有层进行修剪**，因此可以轻松开发和应用修剪后的网络。该领域的早期工作[2，42]利用组Lasso来实现深度网络的结构化稀疏性。之后，李等人[30]提出了典型的三阶段修剪范例（训练大型网络，修剪，再训练）。这些修剪算法将具有较小范数的过滤器视为不重要，并且倾向于修剪它们，但是这种假设在深层非线性网络中不成立[43]。因此，许多研究人员专注于信息过滤器的更好标准。例如，刘等[32]利用L1正则化；Ye等[43]对ISTA施加了惩罚(applied a ISTA penalty)；He等[19]利用了基于几何中位数的标准。与以前的修剪pipeline相反，我们的方法允许显式优化通道&#x2F;层的数量，从而使学习到的结构具有高性能和低成本。 除了信息过滤器的标准，网络结构的重要性在[33]中被提出。通过自动确定每一层的修剪和压缩率，某些方法可以隐式地找到特定于数据的架构[42、2、15]。相比之下，我们使用NAS明确发现了该架构。先前的大多数NAS算法[48、8、31、40]会自动发现神经网络的拓扑结构，而我们专注于搜索神经网络的深度和宽度。基于强化学习（RL）的[48，3]方法或基于进化算法的[40]方法可以搜索具有灵活宽度和深度的网络，但是它们需要大量的计算资源，因此无法直接用于大规模目标数据集。可微分的方法[8，31，4]显着降低了计算成本，但它们通常假定不同搜索候选集的通道数相同。 TAS是一种可微分的NAS方法，它能够有效地搜索具有灵活宽度和深度的迁移网络。 网络迁移(Network transformation)[5，10，3]也研究了网络的深度和宽度。 Chen等[5]手动拓宽和加深网络，并建议使用Net2Net初始化更大的网络。 Ariel等[10]提出了一种启发式策略，通过在缩小和扩展之间交替来找到合适的网络宽度。蔡等[3]利用RL代理来增加CNN的深度和宽度，而我们的TAS是一种可微分的方法，不仅可以扩大CNN，而且可以缩小CNN。 在网络修剪相关的文献中，知识迁移已被证明是有效的。网络的参数可以从预训练的初始化[30，18]中迁移。Minnehan等[37]通过逐块重构损失来迁移未压缩网络的知识。在本文中，我们应用了一种简单的KD方法[21]来进行知识转移，从而使架构搜索具有良好的性能。 3 方法我们的修剪方法包括三个步骤：（1）通过标准分类训练程序训练未修剪的大型网络。 （2）通过TAS搜索小型网络的深度和宽度。（3）通过简单的KD方法将知识从未修剪的大型网络迁移到搜索得到的小型网络[21]。 下面将介绍背景知识，TAS的详细信息，并说明知识迁移过程。 3.1 迁移架构搜索网络通道修剪旨在减少网络每一层中的通道数量。 给定输入图像，网络会将其作为输入，并在每个目标类别上产生概率。 假设$X$和$O$是第$l$个卷积层的输入和输出特征张量（我们以3×3卷积为例），该层计算过程如下： $$O_j&#x3D;\\sum_{k&#x3D;1}^{c_{in}}{X_k,:,: \\ast W_{j,k},:,:} \\qquad where ; 1\\leq j \\leq c_{out} \\tag{1}$$ 其中$W\\in R^{c_{out\\times c_{in} \\times 3 \\times 3}}$表示卷积核权重，$c_{in}$为输入通道，$c_{out}$为输出通道。 $W_{j,k,:,:}$对应第$k$个输入通道和第$j$个输出通道。$\\ast$表示卷积运算。 通道修剪方法可以减少$c_{out}$的数量，因此，也减少了下一层的$c_{in}$。 搜索宽度 我们使用参数$\\alpha \\in R^{|C|}$来表示一层中可能的通道数分布，其中，$max(C)≤c_{out}$。 选择通道数量的第$j$个候选的概率可以表示为： $$p_j&#x3D;\\frac{exp(\\alpha_j)}{\\sum_{k&#x3D;1}^{|C|}{exp(\\alpha_k)}} \\qquad where; 1\\leq j \\leq |C| \\tag{2}$$ 但是，**上述过程中的采样操作是不可微的**（可以参考《Gumbel-Softmax的采样技巧》），这阻止了我们将梯度从$p_j$反向传播到$\\alpha_j$。 受[8]的启发，我们应用Gumbel-Softmax [26，36]来软化采样过程以优化$\\alpha$： 其中$U(0,1)$表示0和1之间的均匀分布。$\\tau$是softmax温度参数。 当$\\tau \\to 0$时，$\\hat{p}&#x3D;[\\hat{p}_1,…,\\hat{p}_j,…]$变为one-shot?（此处暂时没想明白，可以参考《Gumbel-Softmax 对离散变量再参数化》），并且基于$\\hat{p}$的Gumbel-softmax分布与类别分布相同。当$\\tau \\to \\infty$，Gumbel-softmax分布在$C$上变为均匀分布。我们方法中的特征图定义为具有不同大小的原始特征图片段的加权和，其中权重为$\\hat{p}$。 通过逐通道插值（CWI）对齐具有不同大小的特征图，以便计算加权和。 为了减少内存成本，我们选择索引$I\\subseteq[|C|]$为的小子集进行聚合，而不是使用所有channel候选集（ **此处提出了针对形如等式2中的概率计算不可微问题可以采取的策略，即使用Gumbel-Softmax进行软化 **）。此外，权重根据所选size的概率重新归一化，公式如下： 其中$\\tau_{\\hat{p}}$表示由$\\hat{p}$参数化的多项式概率分布。CWI是将不同尺寸的特征图对齐的一般操作。它可以通过多种方式实现，例如空间迁移网络（ spatial transformer network）的3D变体[25]或自适应池操作[16]。在本文中，我们选择3D自适应平均池化操作[16]作为${CWI}^2$，因为它没有带来额外的参数并且可以忽略不计的额外成本。我们在CWI之前使用批规范化[24]来规范化不同的片段。图2以$|I|&#x3D;2$为例阐述了上述过程。 需要注意的是，$I&#x3D;2$表示有两个 channel 值不同的卷积核进行CWI。具体做法如下： 12345678910if self.avg : out = self.avg( inputs )else : out = inputs #走这个分支# convolutional layerout_convs = conv_forward(out, self.conv, [self.choices[i] for i in index]) # nn.Conv2dout_bns = [self.BNs[idx](out_conv) for idx, out_conv in zip(index, out_convs)]# mergeout_channel = max([x.size(1) for x in out_bns]) # 因为 I=2，这里取最大的size作为CWI的对齐标准outA = ChannelWiseInter(out_bns[0], out_channel) # out_channel作为最大的sizeoutB = ChannelWiseInter(out_bns[1], out_channel)out = outA * prob[0] + outB * prob[1] # 对应公式4，因为设置I=2比较小，所以这里直接写死了 而conv_forward中是怎么实现的呢？ 12345678910111213141516def conv_forward(inputs, conv, choices): \"\"\" :param inputs: 输入数据 :param conv: 一个定义的卷积层 :param choices: 经过选择的输出channel集合，I=2则 channel size=2 :return: \"\"\" iC = conv.in_channels fill_size = list(inputs.size()) fill_size[1] = iC - fill_size[1] filled = torch.zeros(fill_size, device=inputs.device) xinputs = torch.cat((inputs, filled), dim=1) outputs = conv(xinputs) #Conv2的输出是[batch_size, out, height, width],所以outputs[:,:oC]中，逗号之前表示batch, 逗号之后表示 selecteds = [outputs[:,:oC] for oC in choices] return selecteds 看15行，也就是说先按照候选 channel 的最大值进行卷积，然后根据候选 channel 使用切片进行获取。这样就金额以方便地获取不同 channel 对应的卷积输出。 讨论等式4中的抽样策略 $\\quad$ 该策略旨在仅仅通过反向传播采样架构的梯度（而不是整个架构），将内存成本和训练时间减少到可接受的数量。与通过均匀分布采样相比，所应用的采样方法（基于概率的采样）可以减弱多次迭代后每次迭代采样所导致的梯度差。 搜索深度 我们使用参数来表示具有$L$个卷积层的网络中可能的层数分布。我们使用和等式3类似的策略来采样层数。并使用深度为$l$的采样分布$\\hat{q}_l$使$\\beta$与$\\alpha$可微分。然后，对于所有可能的深度，我们计算出修剪后的网络的最终输出特征，进行汇总，其表示为： 其中$\\hat{O^l}$表示在等式4中第$l$层的输出特征图。$C_{out}$表示所有$\\hat{O^l}$中的最大采样通道。 将最终输出的特征图$O_{out}$喂入最后的分类层以进行预测。 这样，我们可以将梯度反向传播到宽度参数$\\alpha$和深度参数$\\beta$。 搜索目标 最终的架构$A$是通过选择具有最大概率的候选项而得出的，该候选项由架构参数(等式8中形如$A$的字符即表示架构参数，此处不知如何书写)获知，该架构参数由每层的$\\alpha$和$\\beta$组成。 我们的TAS的目标是通过将训练损失$\\zeta_{train}$最小化，找到经过训练后具有最小验证损失$\\zeta_{val}$的架构$A$： 其中$w_A^{\\ast}$表示$A$的优化权重。训练损失是网络的交叉熵分类损失。 现有的NAS方法[31、48、8、4、40]通过具有不同拓扑的网络候选项优化$A$，而我们的TAS则是搜索具有相同拓扑结构以及较小宽度和深度的候选项。 所以，我们搜索过程中的验证损失不仅包括分类验证损失，还包括计算成本的惩罚： 其中$z$是一个向量，表示修剪后网络的输出对数，$y$表示相应输入的真实类别，而$\\lambda_{cost}$是$\\zeta_{cost}$的权重。 成本损失会促使网络的计算成本（例如FLOP）收敛到目标R，以便可以通过设置不同的$R$来动态调整成本。我们使用的分段计算成本损失如下： 其中$E_{cost}(A)$基于架构参数$A$计算期望的计算成本。具体地说，它是所有候选网络的计算成本的加权总和，其中权重是采样概率。$F_{cost}(A)$表示搜索到的架构的实际成本，其宽度和深度从$A$得出。$t\\in [0,1]$表示容忍度，它减慢了更改搜索架构的速度。需要注意的是，我们使用FLOP来评估网络的计算成本，并且很容易用其它度量标准（例如延迟[4]）来代替FLOP。 我们在Alg1中展示了整个算法。在搜索过程中，我们使用等式5迁移网络，使权重和架构参数可区分。我们也可以在训练集上最小化$\\zeta_{train}$来优化修剪的网络的权重，而在验证集上最小化$\\zeta_{val}$来优化架构参数$A$。搜索之后，我们以最大的概率选择通道数作为宽度，以最大概率选择层数作为深度。最终搜索的网络由选定的宽度和深度构成。该网络将通过KD进行优化，我们将在3.2小结中详细介绍。 3.2 知识迁移知识迁移对于学习健壮的修剪网络非常重要，我们在搜索的网络架构上采用了简单的KD算法[21]。 此算法鼓励小型网络的预测$z$通过以下目标，与未修剪网络的软目标匹配： 其中$T$是温度参数，$\\hat{z}$表示来自预训练的未修剪网络的logit输出向量。 此外，它使用带有交叉熵损失的softmax来鼓励小型网络预测真实目标。 KD的最终目标如下： 其中$y$表示相应输入的真实目标类别。$\\lambda$是平衡标准分类损失和软匹配损失的损失权重。 在搜索到目标网络（第3.1节）之后，我们首先对未修剪的网络进行预训练，然后通过等式10从未修剪的网络迁移来优化搜索到的网络。 实验部分见下文。 参考文献 Gumbel-Softmax 对离散变量再参数化 Gumbel-Softmax的采样技巧 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} });","tags":[{"name":"NAS","slug":"NAS","permalink":"http://aeyoo.net/tags/NAS/"},{"name":"网络修剪","slug":"网络修剪","permalink":"http://aeyoo.net/tags/网络修剪/"},{"name":"知识迁移","slug":"知识迁移","permalink":"http://aeyoo.net/tags/知识迁移/"},{"name":"神经架构搜索","slug":"神经架构搜索","permalink":"http://aeyoo.net/tags/神经架构搜索/"}]},{"title":"论文《A Simple Convolutional Generative Network for Next Item》阅读笔记","date":"2019-10-20T11:00:41.000Z","path":"2019/10/20/论文《A-Simple-Convolutional-Generative-Network-for-Next-Item》阅读笔记/","text":"最近，卷积神经网络（CNN）被引入到基于会话的next item推荐中。用户在会话（或序列）中交互过的item的有序集合被嵌入到二维隐矩阵中，并被视为图像，然后将卷积和池化操作应用在item embedding上。在本文中，我们首先研究了经典的基于会话的CNN推荐器，并证明在对item序列的长期依赖关系进行建模时，其生成模型和网络结构都不理想。为了解决这些问题，我们引入了一个简单但非常有效的生成模型，该模型能够从短期和长期item依赖项中学习高级表示。所提出模型的网络结构由有孔的卷积层堆叠而成，可以在不依赖于池化操作的情况下有效地增加感受野。另一个贡献是在推荐系统中有效使用残差块结构，这可以简化对更深层网络的优化。所提出的生成模型在next item推荐任务中以最短的训练时间获得了最出色的准确性。因此，它可以用作推荐基线，尤其是在用户反馈序列较长时。 1 介绍近年来，利用用户交互的item序列（例如点击或购买）来改善现实世界的推荐系统已经变得越来越流行。当用户在会话（例如购物会话或音乐收听会话）中与在线系统互动时，会自动生成这些序列。例如，Last.fm1或Weishi2上的用户通常在一定时间段内欣赏一系列歌曲&#x2F;视频，而不会受到任何干扰，即听或看。在一个会话中播放的一组音乐视频通常具有很强的相关性[6]，例如，共享同一张专辑，作家或流派。因此，一个好的推荐系统应该通过利用会话中的这些序列模式来进行推荐。 经常用于这些交互序列的一类模型是递归神经网络（RNN）。 RNN通常会生成softmax输出，其中概率越大代表推荐的相关程度越高。虽然这些基于RNN的模型行之有效，如[3,15]，但是其取决于整个过去的隐状态[8]，不能在序列中充分利用并行计算。因此，它们的速度在训练和评估中都受到限制。 相比之下，训练CNN不依赖于先前时间步长的计算，因此可以对序列中的每个元素进行并行化。受到在图像任务中成功使用CNN的启发，一个新的序列推荐器（称为Caser [29]）被提出，其放弃了RNN结构，提出了卷积序列嵌入模型，并证明了在前topN的序列推荐任务中，基于CNN的推荐器能够实现相近的或优于主流RNN模型的性能。卷积过程的基本思想是将t×k嵌入矩阵视为k维隐空间中先前t次交互的“图像”，并将序列模式视为“图像”的局部特征。执行仅保留卷积层最大值的最大池化操作以增加感受野，并处理输入序列的变化长度。图1描述了Caser的关键架构。 考虑到网络的训练速度，在本文中，我们遵循序列卷积技术的思路进行next item推荐任务。我们证明，在Caser中使用的典型网络体系结构有几个明显的缺点-例如：（1）在对长期序列数据进行建模时，用于计算机视觉的安全方案max pooling可能会丢弃重要的位置和循环信号； （最大池化有问题）（2）仅为所需item生成softmax分布无法有效使用竞争性依赖集。随着会话和序列长度的增加，这两个缺点变得更加严重。为了解决这些问题，我们引入了一个简单但完全不同的基于CNN的序列推荐模型，该模型即使在很长的item序列中也可以对复杂的条件分布进行建模。更具体地说，首先，我们的生成模型被设计为显式编码item之间的依赖关系，从而可以直接估计原始item序列上的输出序列（而不是所需item）分布。其次，代替使用低效的大型滤波器，我们将一维扩张的卷积层[31]彼此堆叠，目的是在对长期依赖进行建模时增加感受野。在上述网络结构中可以安全地移除池化层。值得注意的是，尽管发明了扩张卷积用于图像生成任务[4，26，31]中的dense prediction（稠密预测），并已应用于其他领域（例如声学[22，26]和翻译[18]任务），但是在具有大量稀疏数据的推荐系统中，尚未对此进行探索。此外，为了简化深度生成架构的优化工作，我们建议使用残差网络通过残差块包装卷积层。据我们所知，这也是采用残差学习为推荐任务建模的首次工作。这些选择的组合使我们能够解决大规模问题，并在短期和长期序列推荐数据集中获得最先进的结果。总之，我们的主要贡献包括新颖的推荐生成模型（第3.1节）和完全不同的卷积网络架构（第3.2至3.4节） 2 准备工作本小节首先描述了序列推荐问题的定义。 然后简要概述了最近的卷积序列嵌入推荐模型（Caser）及其局限性。 最后回顾了基于序列的推荐系统的已有工作。 2.1 基于会话推荐的Top-N问题令$x_0,x_1,..,x_{t-1},x_t$是一个用户交互的item序列，其中$x_i$是点击的item的索引。序列推荐的目标是找到一个模型，为所有的候选集生成一个排序或者类别分布$y&#x3D;[y_1,y_2,…,y_n]\\in R^n$，$y_i$是一个分数，也可能是待推荐的下一个item的候选集的排序。实际上，我们通常通过从y中选择n个item用于推荐任务，这就是基于会话推荐的Top-N问题。 2.2 Caser的局限Caser的基本思想是通过嵌入查找操作（embedding look-up operation）将先前的t个item嵌入为t×k矩阵E，如图1（a）所示。矩阵的每一行向量对应一个item的隐特征。嵌入矩阵可以看作是k维隐空间中t个item的“图像”，直观地，可以将成功应用于计算机视觉中的各种CNN模型用于对item序列的“图像”进行建模。但是，有两个方面将序列建模与图像处理区分开，这使得基于CNN的模型的使用不直观。首先，在现实世界中，可变长度的item序列会产生大量不同大小的“图像”，而带有固定大小的过滤器的传统卷积结构可能会失败；其次，最有效的图像过滤器，例如3× 3和5×5不适用于序列“图像”，因为这些小的过滤器（就行方向而言）不适合捕获全宽度嵌入向量的表示。为了解决上述限制，Caser中的过滤器会通过大型过滤器在序列“图像”的所有列上滑动。也就是说，过滤器的宽度通常与输入“图像”的宽度相同，其高度由一个滑动窗口确定，滑动窗口一次滑过2-5个item（图1（a））。卷积后生成可变长度的特征图（图1（b）），为确保所有图具有相同的大小，对每个图执行max pooling，仅选择每个特征图的最大值，从而得到1×1映射（图1（c））。最后，将所有过滤器的1×1映射连接起来形成特征向量，然后是softmax层，产生下一项的概率（图1（d）））。注意，由于它不能解决下面讨论的主要问题，因此我们省略了图1中的垂直卷积。 根据以上对Caser中卷积的分析，可能会发现当前设计存在一些缺点。首先，max pooling运算符有明显的缺点，无法区分重要特征在特征图中出现的次数仅发生一次或多次，并且忽略了它发生的位置。 max pooling运算符虽然可以安全地用于图像处理时（使用小型池化过滤器，例如3×3），但是其可能对建模长期序列（使用大型过滤器，例如1×20）有害。其次，在对复杂关系或长期依赖进行建模时，Caser中仅适合一个隐层卷积层的浅层网络结构可能会失败。最后一个重要的缺点来自next item的生成过程，我们将在第3.1节中详细介绍。 2.3 相关工作序列推荐中的早期工作主要依赖于马尔可夫链[5]和基于特征的矩阵分解[12，32–34]方法。与神经网络模型相比，基于马尔可夫链的方法无法对序列数据中的复杂关系进行建模。例如，在Caser中，作者表明马尔可夫链方法无法对联合级序列模式进行建模，并且不允许item序列中的跳跃行为。基于因子分解的方法（例如因子分解机）通过序列中item的向量和对序列建模。但是，这些方法没有考虑item的顺序，也不是专门为序列推荐而发明的。与传统模型相比，最近的深度学习模型显示了最新的推荐准确性。此外，RNN是一类深层神经网络，几乎在序列推荐领域占据主导地位。例如，[15]提出了一种基于排序损失的门控循环单元（GRURec）体系结构，用于基于会话的推荐。在后续论文中设计了各种RNN变体，以针对不同的应用场景扩展经典的RNN变体，例如通过添加个性化[25]，内容[9]和上下文特征[27]，注意力机制[7、20]和不同的排序损失函数[14]。相比之下，基于卷积神经网络的序列推荐模型更具挑战性，而且探索也少得多，因为卷积不是捕获序列模式的自然方法。据我们所知，迄今为止，仅提出了两种类型的序列推荐架构：第一种是基于Caser的标准2D CNN，而第二种是设计用于建模高维特征的3D CNN [30]。与上述示例不同，我们计划使用有效的扩展卷积过滤器和残差块来研究一维CNN的效果，以构建推荐架构。 3 模型设计3.1 一个简单的生成模型在本节中，我们介绍一个直接作用于item交互序列的简单但非常有效的生成模型。 我们的目的是估计原始item交互序列上的分布，该分布可用于精确计算item的可能性并生成用户希望进行交互的next item。 令p(x)为item序列x&#x3D;{x0, …, xt}的联合分布。 为了建模p(x)，我们可以通过链式规则将其分解为条件分布的乘积。 $$p(x)&#x3D;\\prod_{i&#x3D;1}^t{p(x_i|x_{0:i-1},\\theta)p(x_0)} \\tag{1}$$ 由于神经网络具有建模复杂非线性关系的能力，因此本文中我们通过堆叠一维卷积网络对user-Item交互的条件分布进行了建模。更具体地说，网络接收$x_{0:t-1}$作为输入，并输出可能的$x_{1:t}$上的分布，其中$x_t$的分布是我们的最终期望。例如，如图2所示，$x_{15}$的输出分布由$x_{0:14}$确定，而$x_{14}$由$x_{0:13}$确定。值得注意的是，在先前的序列推荐文献中，例如Caser，GRURec和[20、25、28、30]，他们仅对单个条件分布 $p(x_i|x_{0:i-1},θ)$ 进行建模，而不是对所有条件概率 $\\prod_{i&#x3D;1}^t{p(x_i|x_{0:i-1},θ)p(x_0)}$进行建模。在上述示例的上下文中，假设给出$\\lbrace x_0,…, x_{14}\\rbrace$，像Caser这样的模型仅估算下一项$x_{15}$的概率分布（即softmax）（另请参见图1（d）），而我们的生成方法会估算$\\lbrace x_0,…, x_{14},x_{15}\\rbrace$中所有单个item的分布。生成过程的比较如下所示。 显然，我们提出的模型在捕获所有序列关系的集合方面更为有效，而Caser和GRURec未能明确建模$\\lbrace x_0,…, x_{14}\\rbrace$之间的内部序列特征。 在实践中，**为了解决该缺陷（这种缺陷是否对推荐效果有影响?）**，这样的模型通常通过数据增强技术[28]（例如，对输入序列进行填充，拆分或移位）生成大量子序列（或子会话）以进行训练。如方程式（3）所示（请参阅[20、25、29、30]）。 尽管有效，但是由于每个子会话的单独优化，上述生成子会话的方法不能保证最佳结果。 另外，分别优化这些子会话将导致相应的计算成本。 我们的实验部分也报告了与经验结果的详细比较。 3.2 网络结构3.1.1 嵌入查找层：给定item序列$\\lbrace x_0,…,x_{t}\\rbrace$，模型通过查找表检索前t个item$\\lbrace x_0,…,x_{t-1}\\rbrace$中的每一个，并堆叠这些item的embedding。假设嵌入维数为2k，其中k可以设置为卷积网络中内部通道的数量。这将生成尺寸为t×2k的矩阵。请注意，与Caser在卷积期间将输入矩阵视为2D“图像”不同，我们提出的架构通过1D卷积过滤器学习嵌入层，稍后将对其进行介绍。 3.2.2 扩张层：如图2(a)所示，标准滤波器只能与感受野线性地进行卷积，其深度取决于网络的深度,这使得很难处理长期序列。类似于Wavenet [22]，我们采用扩张卷积来构造提出的生成模型。扩张的基本思想是通过用零扩张将卷积滤波器应用于大于其原始长度的场。这样，由于它使用较少的参数，因此效率更高。因此，扩张过滤器也称为带孔过滤器或稀疏过滤器。另一个好处是，扩展的卷积可以保留输入的空间尺寸，这对于卷积层和残差结构都使堆叠操作更加容易。 图2显示了标准卷积和扩张卷积之间的网络比较。 (b)中的扩张因子为1、2、4和8。为了描述网络架构，我们分别将感受野，第j卷积层，通道和扩张分别表示为$r, F_j, C和l$。通过将卷积滤波器$f$的宽度设置为3，我们可以看到扩张的卷积(图2(b))允许感受野的大小成指数增长$(r&#x3D;2^{j+1}-1)$，而相同的堆叠标准卷积的结构(图2(a))仅具有线性感受野 $(r&#x3D;2j+1)$。形式上，使用扩张$l$，从位置i开始的过滤器窗口为： $$[x_i\\quad x_{i+l}\\quad x_{i+2l}\\quad …\\quad x_{i+(f-l)\\cdot l}]$$ 下面给出了item序列中的元素h的一维扩张卷积算子$*l$： $$(x \\ast_{l} g)(h)&#x3D;\\sum_{i&#x3D;0}^{f-1}{x_{h-l\\cdot x}\\cdot g(i)}$$ 其中g是过滤功能。 显然，扩张的卷积结构对长期item序列建模更有效，因此在不使用较大过滤器或变得更深的情况下更为有效。 实际上，为了进一步增加模型容量和接感受野，只需要通过堆叠例如1、2、4、8、1、2、4、8多次重复图2中的架构即可。 3.2.3一维变换：尽管我们的扩张卷积算子依赖于2D输入矩阵E，但所提出的网络架构实际上是由所有1D卷积层组成的。 为了对2D embedding输入建模，我们执行简单的reshape操作，这是执行1D卷积的前提。 具体而言，将2D矩阵E从t×2k整形为大小为1×t×2k的3D张量T，其中2k被视为“图像”通道，而不是Caser中标准卷积滤波器的宽度。 图3（b）说明了reshape过程： Figure 3: Dilated residual blocks (a), (b) and one-dimensional transformation (c). (c) shows the transformation from the 2D filter (C&#x3D;1)(left) to the 1D 2-dilated filter (C&#x3D;2k) (right); the vertical black arrows represent the direction of the sliding convolution. In this work, the default stride for the dilated convolution is 1. Note the reshape operation in (b) is performed before each convolution in (a) and (b) (i.e., 1 × 1 and masked 1 × 3), which is then followed by a reshape back step after convolution. 3.3 蒙版卷积残差网络尽管增加网络层的深度可以帮助获得更高级别的特征表示，但它也很容易导致梯度消失问题，这使学习过程变得更加困难。为了解决退化问题，针对深度网络引入了残差学习[10]。尽管残差学习在计算机视觉领域取得了巨大的成功，但尚未出现在推荐系统的文献中。 残差学习的基本思想是将多个卷积层堆叠在一起作为一个块，然后采用跳跃连接方案，将前一层的特征信息传递到后一层。跳跃连接方案允许显式拟合残差映射而不是原始恒等映射，这可以维护输入信息并扩大传播梯度。形式上，将所需的映射表示为H(E)，我们让残差块拟合F(E)&#x3D; H(E)-E的另一个映射。现在，将所需的映射通过按位相加的方式转为F(E)+ E（假设F(E)和E具有相同的维数）。正如[10]中所证明的那样，优化残差映射F(E)比原始的未引用映射H(E)容易得多。受[11，18]的启发，我们在图3(a)和(b)中引入了两个残差模块。 在图3(a)中，我们用残差块包裹每个扩张卷积层，而在图3(b)中，我们用不同的残差块包裹每两个扩张层。即，在块(图3b)的设计中，输入层和第二卷积层应通过跳跃连接（即，图2中的蓝线）连接。具体地，每个块由归一化、激活、卷积层和跳跃连接以特定的顺序组合而成。在这项工作中，我们在每个激活层之前都采用了最新的层归一化方法[1]，因为与批量归一化方法相比[16]，它非常适合序列处理和在线学习。 关于这两个残差网络的性质，(a)中的残差块由3个卷积滤波器组成：一个大小为1×3的膨胀滤波器和两个大小为1×1的常规滤波器。引入1×1滤波器来改变C的大小，以减少1×3的核要学习的参数。第一个1×1滤波器（接近图3(a)中的输入E）将C从2k更改为k，而第二个1×1滤波器进行相反的转换，以保持下一个堆叠操作的的空间维度。为了显示(a)中1×1滤波器的有效性，我们计算了(a)和(b)中参数的数量。为简单起见，我们省略了激活层和normalization层。如我们所见，没有1×1滤波器的1×3滤波器的参数数目为$1\\times 3\\times 2k\\times 2k&#x3D;12k^2$（即(b)中）。在(a)中，要学习的参数数量为$1\\times 1\\times 2k\\times k + 1\\times 3\\times k\\times k + 1\\times 1\\times k\\times 2k&#x3D;7k^2$。(a)和(b)中的残差映射表示为： 其中$\\sigma$和$\\psi$表示ReLU和层归一化，$W_1$和$W_3$表示标准1×1卷积的卷积权重函数，$W_2, W_2^{‘}$和$W_4^{‘}$表示尺寸为1×3的l型卷积滤波器的权重函数。 注意，为了简化符号省略了偏置项。 3.3.1 Dropout-mask：为避免将来出现信息泄漏问题，我们为一维扩张卷积提出了一种基于掩码的dropout技巧，以防止网络接触到将来的item。 具体而言，当预测$p(x_i|x_{0：i-1})$时，不允许卷积滤波器使用$x_{i:t}$的信息。 图4显示了执行卷积的几种不同方式。 如图所示，可以通过填充输入序列(d)或将输出序列移位几个时间步(e)来实现我们的dropout-masking操作。(e)中的填充方法很可能导致序列中的信息损失，尤其是对于短序列。 因此，在这项工作中，我们应用了在(d)中的填充策略，其填充大小为$(f-1)*l$。 3.4 最后一层，网络训练和生成如上所述，在卷积结构最后一层中的矩阵（见图2）由$E^o$表示，保持了输入E的相同尺寸，即$E^o\\in R^{t\\times 2k}$。但是，输出应为包含输出序列$x_{1:t}$中所有项的概率分布的矩阵或张量，其中$x_t$的概率分布是生成前N个预测的期望值。为此，我们可以简单地在图2中最后一个卷积层的顶部再使用一个卷积层，其过滤器的大小为$1×1×2k×n$（[卷积核的高度，卷积核的宽度，图像通道数&#x2F;输入 channel，卷积核个数&#x2F;输出 channel]），其中n是项数。按照图3（c）中的一维变换的过程，我们获得了预期的输出矩阵$E^p \\in R^{t\\times n}$，其中softmax操作之后的每个行向量都表示$x_i(0&lt;i≤t)$上的分类分布。优化的目的是使训练数据的对数似然性最大化。显然，在数学上最大化$log p(x)$等效于最小化$x_{1:t}$中每个item的二项分布交叉熵损失之和。对于具有数千万个item的真实推荐系统，可以采用负采样策略来绕过全softmax分布的生成，其中将1×1卷积层替换为权重矩阵为$E^g\\in R^{2k\\times n}$的全连接层（FC）。例如，我们可以应用采样的softmax [17]或基于核的采样[2]。这些负采样策略的推荐精度几乎与采样大小经过适当调整的全softmax方法相同。 为了进行比较，我们仅预测评估中的下一个item，然后停止生成过程。然而，该模型能够简单地通过将预测的一个item（或序列）输入网络以预测下一个item来生成item序列，因此在生成阶段的预测是连续的。这与大多数实际推荐方案相匹配，在观察到当前推荐方案后，将执行下一个操作。但是在训练和评估阶段，可以并行进行所有时间步的条件预测，因为输入项x的完整序列已经可用。 实验细节见下文。 参考文献1 A Simple Convolutional Generative Network for Next Item Recommendation MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} });","tags":[{"name":"nextitnet","slug":"nextitnet","permalink":"http://aeyoo.net/tags/nextitnet/"},{"name":"序列推荐","slug":"序列推荐","permalink":"http://aeyoo.net/tags/序列推荐/"}]},{"title":"FM工程实现细节","date":"2019-08-23T08:17:38.000Z","path":"2019/08/23/FM工程实现细节/","text":"关于FM算法网上已经介绍了很多，这里介绍一下FM算法的实现细节。 FM的模型方程为: $$y(x)&#x3D;w_0 + \\sum^n_{i&#x3D;1}w_ix_i + \\sum^n_{i&#x3D;1}\\sum^n_{j&#x3D;i+1}v_iv_j^Tx_ix_j$$ $$\\begin{aligned} \\sum_{i&#x3D;1}^{n}{\\sum_{j&#x3D;i+1}^{n}{&lt;v_i,v_j^{T}&gt;x_ix_j}} &amp;&#x3D; \\frac{1}{2}\\sum_{i&#x3D;1}^{n}{\\sum_{j&#x3D;1}^{n}{&lt;v_i,v_j^{T}&gt;x_ix_j}} - \\frac{1}{2} {\\sum_{i&#x3D;1}^{n}{&lt;v_i,v_j^{T}&gt;x_ix_i}} \\\\ &amp;&#x3D; \\frac{1}{2} \\left( \\sum_{i&#x3D;1}^{n}{\\sum_{j&#x3D;1}^{n}{\\sum_{f&#x3D;1}^{k}{v_{i,f}v_{j,f}x_ix_j}}} - \\sum_{i&#x3D;1}^{n}{\\sum_{f&#x3D;1}^{k}{v_{i,f}v_{i,f}x_ix_i}} \\right) \\\\ &amp;&#x3D; \\frac{1}{2}\\sum_{f&#x3D;1}^{k}{\\left[ \\left( \\sum_{i&#x3D;1}^{n}{v_{i,f}x_i} \\right) \\cdot \\left( \\sum_{j&#x3D;1}^{n}{v_{j,f}x_j} \\right) - \\sum_{i&#x3D;1}^{n}{v_{i,f}^2 x_i^2} \\right]} \\\\ &amp;&#x3D; \\frac{1}{2}\\sum_{f&#x3D;1}^{k}{\\left[ \\left( \\sum_{i&#x3D;1}^{n}{v_{i,f}x_i} \\right)^2 - \\sum_{i&#x3D;1}^{n}{v_{i,f}^2 x_i^2} \\right]}\\end{aligned}$$ 在上式中，$&lt;v_i,v_j^{T}&gt;$可以看做一个常数，其中$v_i&#x3D;[v_{i,1},v_{i,2}, .. ,v_{i,f}], i\\in \\lbrace1,2,..,n\\rbrace$；$&lt;v_i,v_j^{T}&gt;&#x3D;\\sum_{f&#x3D;1}^{k}{v_{i,f}v_{j,f}}$。 实现时，$\\sum_{i&#x3D;1}^{n}{v_{i,f}x_i}$ 式子可以直接将每行样本$X$和一个$n*k$的隐向量矩阵相乘($n$是特征数，$k$是隐向量长度）。 如果要用 FM 做二分类，需要在上面模型外面套上一层sigmoid函数，即： $$output&#x3D;sigmoid(y(x))&#x3D;\\frac{1}{1+e^{-y(x)}}$$ 损失函数 回归问题 通常使用平方损失，即$1&#x2F;2(y-y(x))^2$。 分类问题（此处指的是二分类问题）通常使用逻辑损失函数（也叫交叉熵损失函数），即$ln(1+e^{-yy(x)})，y\\in{-1,1}$。 所以对于二分类问题，FM 算法的损失函数如下： $$loss(x) &#x3D; ln(1+e^{-yy(x)})$$ 加上 L2正则化之后，损失函数如下：$$\\begin{aligned} loss(x) &amp;&#x3D; ln(1+e^{-yy(x)}) + \\frac{\\beta}{2}{\\theta}^2 \\\\ &amp;&#x3D; ln(1+e^{-yy(x)}) + \\frac{\\beta}{2}{w_0}^2 + \\frac{\\beta}{2}{w_i}^2 + \\frac{\\beta}{2}{v_{i,f}v_{i,f}^T} \\\\ &amp;&#x3D; ln(1+e^{yy(x)})-ln(e^{yy(x)}) + \\frac{\\beta}{2}{w_0}^2 + \\frac{\\beta}{2}{w_i}^2 + \\frac{\\beta}{2}{v_{i,f}v_{i,f}^T} \\\\ &amp;&#x3D; ln(1+e^{yy(x)})-yy(x) + \\frac{\\beta}{2}{w_0}^2 + \\frac{\\beta}{2}{w_i}^2 + \\frac{\\beta}{2}{v_{i,f}v_{i,f}^T}\\end{aligned}$$ 梯度求导，以$w_0$为例： $$\\begin{aligned} \\frac{\\partial loss(x)}{\\partial w_0} &amp;&#x3D; \\frac{1}{1+e^{yy(x)}}\\cdot e^{yy(x)} \\cdot y \\cdot \\frac{\\partial y(x)}{\\partial w_0} - y\\frac{\\partial y(x)}{\\partial w_0} + \\beta w_0 \\\\ &amp;&#x3D; sigmoid(yy(x)) \\cdot y \\cdot \\frac{\\partial y(x)}{\\partial w_0} - y\\frac{\\partial y(x)}{\\partial w_0} + \\beta w_0 \\\\ &amp;&#x3D; (sigmoid(yy(x)) - 1 )\\cdot y\\frac{\\partial y(x)}{\\partial w_0} + \\beta w_0 \\qquad (1) \\\\ &amp;&#x3D; (sigmoid(yy(x)) - 1 )\\cdot y + \\beta\\end{aligned}$$ 在实现的时候通常可以将(1)处的$(sigmoid(yy(x)) - 1 )\\cdot y$计算保存，不同参数的梯度求导在于其它项的不同。 参考文献 深入FFM原理与实践 第09章：深入浅出ML之Factorization家族 FM算法解析及Python实现 深度学习中的正则化 因子分解机FM-高效的组合高阶特征模型 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} });","tags":[{"name":"FM","slug":"FM","permalink":"http://aeyoo.net/tags/FM/"}]},{"title":"惠州双月湾游记","date":"2019-07-29T16:01:42.000Z","path":"2019/07/30/惠州双月湾游记/","text":"上周和同事一起去惠州团建，玩的还是蛮开心的。大家一起出海捕鱼，去双月湾观景台，海边游泳+烧烤，潜水等活动，这里记录一下。 1 出海捕鱼我们早上九点出发，大概中午11:30到达饭店，哗哗哗吃了饭，大家一起玩了两局游戏，就回到『别墅』休息了。下午三点大家出发开始了第一站——出海捕鱼，首先到达港口。 刚刚出海。 海鸥! 出海成果! 返程。 2 双月湾接下来我们去到了观景台俯瞰双月湾风貌。 右月 左月 全景 3 烧烤观景之后就去海边游泳了，然后吃烧烤！ 4 潜水 海底世界 没想到初次潜水的我潜到了7-8米，起来后教练问我，”你以前潜过水吗？”, “没有啊”, “你耳朵不疼吗？”，”完全没感觉啊”。貌似我好像可以控制耳膜动.. 玩的还不错，也算是重压下的一次放松吧。","tags":[{"name":"游记","slug":"游记","permalink":"http://aeyoo.net/tags/游记/"},{"name":"潜水","slug":"潜水","permalink":"http://aeyoo.net/tags/潜水/"}]},{"title":"在线最优化求解(FOBOS,RDA,FTRL)-冯扬","date":"2019-07-19T08:40:48.000Z","path":"2019/07/19/在线最优化求解-Online-Optimization-冯扬/","text":"本文以模型的稀疏性作为主线，逐一介绍几个在线最优化求解算法，并进行推导，力求讲清楚算法的来龙去脉，以及不同算法之间的区别和联系，达到融会贯通。在各个算法原理介绍之后，都会给出该算法的工程实现伪代码，可以用于实际工作的参考。作者是新浪微博-商业平台及产品部-冯扬。","tags":[{"name":"在线学习","slug":"在线学习","permalink":"http://aeyoo.net/tags/在线学习/"}]},{"title":"FTRL算法的理论分析与工程化实现","date":"2019-07-15T12:21:07.000Z","path":"2019/07/15/FTRL算法的理论分析与工程化实现/","text":"FTRL算法本质上是针对梯度下降类算法的参数更新过程进行优化，在FTRL之前还有FOBOS和RDA算法。本文以逻辑回归算法（LR）为例，深入阐述一下FOBOS，RDA，FTRL算法。 关于FTRL算法的发展历程可以参考《各大公司广泛使用的在线学习算法FTRL详解》一文；本文关于逻辑回归算法推导的部分主要参考《LR+FTRL算法原理以及工程化实现》，原文讲的很好，但是一些细节表述有些许不正确，本文做了校正；本文关于FOBOS，RDA，FTRL算法部分的阐述是知乎作者张戎博文《FOLLOW THE REGULARIZED LEADER (FTRL) 算法总结》的精炼版。 1. 逻辑回归算法推导逻辑回归模型是一种分类模型，由条件概率分布P(Y|X)表示，形式为参数化的logistic分布，如下所示。 $$P(Y&#x3D;1|x)&#x3D;\\frac{exp(w\\cdot x+b)}{1+exp(w\\cdot x+b)}$$ $$P(Y&#x3D;0|x)&#x3D;\\frac{1}{1+exp(w\\cdot x+b)}$$ 有时为了方便，将权重w和输入向量x进行扩充，即$w&#x3D;(w^{(1)},w^{(2)},…,w^{(n)},b)^T, x&#x3D;(x^{(1)},x^{(2)},…,x^{(n)},1)^T$。扩充后如下所示： $$ P(Y&#x3D;1|x)&#x3D;\\frac{exp(w\\cdot x)}{1+exp(w\\cdot x)}$$ $$ P(Y&#x3D;0|x)&#x3D;\\frac{1}{1+exp(w\\cdot x)}$$ 在学习LR模型时通常使用极大似然法估计模型参数，从而得到LR模型。设 $$ P(Y&#x3D;1|x)&#x3D;\\pi(x)$$ $$ P(Y&#x3D;0|x)&#x3D;1-\\pi(x)$$ 似然函数为 $$\\prod_{i&#x3D;1}^N [\\pi(x_i)]^{y_i}[1-\\pi(x_i)]^{1-y_i}$$ 对数似然函数为： $$ \\begin{aligned} L(w) &amp;&#x3D; -\\sum_{i&#x3D;1}^N [y_{i}log\\pi(x_i)+(1-y_i)log(1-\\pi(x_i))] \\\\ &amp;&#x3D; -\\sum_{i&#x3D;1}^N [y_{i}(w\\cdot x_i)-log(1+exp(w\\cdot x_i))] \\\\ \\end{aligned}$$ 对$L(w)$求极大值，得到$w$的估计值。这样，问题就变成了以对数似然函数为目标函数的最优化问题。可以看出，$L(w)$函数是一个高阶可导连续凸函数，可以使用梯度下降法、拟牛顿法求解。 在实际应用中，通常是以最小化损失函数为目标，这里为描述方便，取$L(x)&#x3D;-L(x)$，转为求$L(x)$的极小值。 以梯度下降法为例：计算$L(w)$的梯度为： $$\\frac{\\partial L(w)}{\\partial w}&#x3D;\\sum_{i&#x3D;1}^N[(\\pi(x_i)-y_i)\\cdot x_i]$$ 第j个参数的梯度为： $$ \\begin{aligned} g_j &amp;&#x3D; \\frac{\\partial L(w)}{\\partial w} \\\\ &amp;&#x3D; \\sum_{i&#x3D;1}^N[(\\pi(x_i)-y_i)\\cdot x^j_i] \\\\ \\end{aligned}$$ 样本第j个参数的更新方式为： $$ \\begin{aligned} w^{k+1}j &amp;&#x3D; w^k_j-\\alpha\\cdot g_i \\\\ &amp;&#x3D; w^k_j-\\alpha\\cdot \\sum^N{i&#x3D;1}(\\pi(x_i)-y_i)\\cdot x^j_i\\\\ \\end{aligned}$$ 上述推导基于梯度下降法，当样本量很大的时候，通常使用随机梯度下降法。 FOBOS, RDA, FTRL算法都是针对梯度下降类算法的参数更新过程进行的优化。 2. FOBOS(Forward Backward Splitting)FOBOS又叫前向后向切分算法，在该算法中，权重的更新主要分为两个步骤： $$W^{(t+0.5)}&#x3D;W^{t}-\\eta^{t}G^{(t)},$$ $$W^{(t+1)}&#x3D;argmin_W \\lbrace\\frac{1}{2}||W-W^{(t+0.5)}||^2_2+\\eta^{(t+0.5)}\\Psi(W) \\rbrace$$ 第一个步骤是一个标准的梯度下降，第二个步骤是对第一个步骤的结果进行局部调整。将两个式子合并之后如下： $$W^{(t+1)}&#x3D;argmin_W \\lbrace\\frac{1}{2}||W-W^{t}+\\eta^{t}G^{(t)}||^2_2+\\eta^{(t+0.5)}\\Psi(W) \\rbrace$$ 假设$F(w)&#x3D;\\frac{1}{2}||W-W^{t}+\\eta^{t}G^{(t)}||^2_2+\\eta^{(t+0.5)}\\Psi(W)$，如果$W^{(t+1)}$存在一个最优解，则必有$F(W)$导数为0： $$0\\in\\partial{F(W)}&#x3D;W-W^{t}+\\eta^{t}G^{(t)}+\\eta^{(t+0.5)}\\partial\\Psi(W)$$ 因为$W^{(t+1)}&#x3D;argmin_WF(W)$，则可以得到权重更新的另外一种形式： $$W^{(t+1)}&#x3D;W^{t}-\\eta^{t}G^{(t)}-\\eta^{(t+0.5)}\\partial\\Psi(W^{(t+1)})$$ 从上面公式可以看出，更新后的$W^{(t+1)}$不仅和$W^{(t)}$有关，还和自己的$\\Psi(W^{(t+1)})$有关。$\\Psi(W^{(t+1)})$是权重的惩罚项。 3. RDA(Regularized Dual Averaging Algorithm)RDA又叫正则对偶平均算法，特征权重的更新策略是： $$W^{(t+1)}&#x3D;argmin_W\\lbrace \\frac{1}{t}\\sum^t_{r&#x3D;1}G^{(r)}\\cdot W+\\Psi(W) + \\frac{\\beta^{(t)}}{t}h(W) \\rbrace$$ 其中，$G^{(t)}\\cdot W$指的是向量$G^{(t)}$和$W$的内积，$\\Psi(W)$是正则项，$h(W)$是一个严格凸函数，${ \\beta^{(t)}|t\\geq 1 }$是一个非负递增序列。 解释： $\\frac{1}{t}\\sum^t_{r&#x3D;1}G^{(r)}\\cdot W$包括了之前所有梯度的平均值； 正则项$\\Psi(W)$； 额外项$\\frac{\\beta^{(t)}}{t}h(W)$。 4. FTRL(FOLLOW THE REGULARIZED LEADER)FTRL 算法综合考虑了 FOBOS 和 RDA 对于梯度和正则项的优势和不足，其特征权重的更新公式是： $$W^{(t+1)}&#x3D;argmin_W \\lbrace G^{(1:t)}\\cdot W+ \\lambda_1||W||1+\\frac{\\lambda_2}{2}||W||^2_2+\\frac{1}{2}\\sum^t{s&#x3D;1}\\sigma^{(s)}||W-W^{(s)}||^2_2 \\rbrace$$ 其中，$G^{(1:t)}&#x3D;\\sum^t_{s&#x3D;1}G^{(s)}$。 未完待续。 参考文献 各大公司广泛使用的在线学习算法FTRL详解 FOLLOW THE REGULARIZED LEADER (FTRL) 算法 FTRL（Follow The Regularized Leader） FOLLOW THE REGULARIZED LEADER (FTRL) 算法总结 LR+FTRL算法原理以及工程化实现 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} });","tags":[{"name":"FTRL","slug":"FTRL","permalink":"http://aeyoo.net/tags/FTRL/"}]},{"title":"如何打造一个惊艳的终端","date":"2019-07-12T14:06:42.000Z","path":"2019/07/12/如何打造一个惊艳的终端/","text":"最近发现了一个不错的插件zsh-autosuggestions，这是oh-my-zsh的一个试用插件，可以实现在终端下动态显示历史输入记录的效果。 在 OSX 和 linux 下默认是bash，但是提示功能不够强大。zsh的功能极其强大，只是配置过于复杂，起初只有极客才在用。后来，程序员robbyrussell创建了一个名为oh-my-zsh的开源项目，然后出现了oh-my-zsh的一个试用插件zsh-autosuggestions。 所以安装 zsh-autosuggestions的步骤 是：安装zsh-&gt;安装oh-my-zsh-&gt;安装zsh-autosuggestions。本文以 mac 为例进行介绍。 1 安装 zsh使用命令cat /etc/shells可以查看系统安装了哪些 shell。在 mac 中默认安装了zsh，所以将默认 shell 修改为 zsh。 12echo $SHELL #查看默认shellchsh -s /bin/zsh #修改shell为zsh 2 安装 oh my zsh安装 oh my zsh 之前必须安装zsh，否则会收到如下提示：Zsh is not installed! Please install zsh first! 1git clone git://github.com/robbyrussell/oh-my-zsh.git ~/.oh-my-zsh 3 配置 oh my zshoh my zsh的配置文件是~&#x2F;.zshrc，该文件默认是没有的，可以直接拷贝oh-my-zsh中的模板。命令如下： 1cp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc 在模板文件zshrc.zsh-template中，默认使用的是robbyrussell主题。 通过命令ls ~/.oh-my-zsh/themes可以查看oh my zsh的所有主题。 1ls ~/.oh-my-zsh/themes 4 安装配置 zsh-autosuggestions首先 clone zsh-autosuggestions。 1git clone git://github.com/zsh-users/zsh-autosuggestions ~/.zsh/zsh-autosuggestions 然后配置zsh-autosuggestions。在~&#x2F;.zshrc文件中添加如下代码： 1source ~/.zsh/zsh-autosuggestions/zsh-autosuggestions.zsh 5 配置zsh的命令提示符主题oh-my-zsh默认的命令提示符样式比较繁琐，可以根据自身需要在robbyrussell主题中配置oh-my-zsh命令提示符的样式。需要注意的是，对于bash，其命令提示符配置在.bashrc文件中。 此外，为了避免oh-my-zsh 更新对我们自定义的配置造成影响，所以可以拷贝一份主题进行配置。 1cp ~/.oh-my-zsh/themes/robbyrussell.zsh-theme ~/.oh-my-zsh/themes/my_robbyrussell.zsh-theme 在my_robbyrussell.zsh-theme中，PROMPT变量就是用来配置命令提示符的格式的，而在 bash 中，PS1变量是用来配置命令提示符格式的。可以修改PROMPT的值如下： 1PROMPT='%&#123;$fg_bold[magenta]%&#125;%n%&#123;$fg_bold[cyan]%&#125;@%&#123;$fg[green]%&#125;%m %&#123;$fg_bold[green]%&#125;%p%&#123;$fg[cyan]%&#125;%1d %&#123;$fg_bold[blue]%&#125;$(git_prompt_info)%&#123;$fg_bold[blue]%&#125;% %&#123;$fg[magenta]%&#125;%(?..%?%1v)%&#123;$fg_bold[blue]%&#125;? %&#123;$fg[yellow]%&#125;# ' 上面代码中出现的变量，如下表所示： 变量 含义 %% 一个’%’ #%). 一个’)’ %y 当前的tty名 %l 当前的tty名，如 pts&#x2F;1 %M 完整主机名 %m 主机名（在第一个句号之前截断） %n 当前用户名 %. %c %C 前两个显示相对路径的当前文件夹名，最后一个是绝对路径（也就是说，前两个在家目录下显示’~’，最后那个显示你的用户名），’%’后的数字表示显示几层路径 %N zsh 正在执行的脚本&#x2F;函数名。如果’%’后跟了数字，似乎还有其他作用 %L 当前shell的层数，可以参考《盗梦空间》的层数 %j 当前正在进行的工作数量 %i 与%!类似：The line number currently being executed in the script, sourced file, or shell function given by %N. This is most useful for debugging as part of $PS4. %! 显示当前历史事件号码（也就是打开shell后第几条命令） %&#x2F; %d 显示当前工作路径（$pwd）。如果’％’后面是一个整数，它指定显示路径的元件的数量;没有数字就显示整个路径。一个负整数就是指定主目录，即％-1d代表第一部分 %~ 目前的工作目录相对于～的相对路径 %? 返回最后命令的执行结果的代码 %# 用户组，#（普通用户）&#x2F;%（超级用户） 然后在.zshrc 文件中修改主题： 1ZSH_THEME=\"my_robbyrussell\" 大功告成！ 参考文献 Mac、Linux 安装zsh &amp; ohmyzsh oh-my-zsh 安装 zsh-autosuggestions 插件 zsh 自定义命令提示符(PS1&#x2F; prompt) zsh 命令提示符 PROMPT oh-my-zsh终端用户名设置（PS1）","tags":[{"name":"mac","slug":"mac","permalink":"http://aeyoo.net/tags/mac/"}]},{"title":"centos7安装zookeeper集群","date":"2019-07-11T01:22:27.000Z","path":"2019/07/11/centos7安装zookeeper集群/","text":"最近打算搭建一个storm集群学习下storm，发现storm使用zookeeper进行管理的，所以需要先搭建一下zookeeper集群。本文记录一下过程。 zookeeper是一个分布式的协调服务，它为大型分布式计算提供开源的分布式配置服务、同步服务和命名注册。如果将 storm，kafka 这些分布式组件的集群节点比喻成一个个小动物的话，zookeeper扮演的就是动物管理员的角色，负责集群中各个节点的通信协调等，就像它的名字一样。例如在 storm 集群中，各个 storm 节点是无状态的，状态信息是由zookeeper存储,storm 节点增加删除通信都是通过 zookeeper 完成的。通过将 kafka集群 和storm 集群使用同一个 zookeeper 维护，可以很方便地将 kafka 的数据传给 storm 消费。 系统环境本文使用vmware15创建了三个centos7实例。选择centos7的主要原因是其支持docker容器，后续可以学习docker。vmware安装centos7的过程很简单，直接按照提示安装即可。如果在公司内网安装的话还需要设置相应的代理。 本人使用2k显示器，所以安装完centos7之后图形界面的字体特别小，目前只调整了terminal的字体，字体Liberation，字号16。 安装jdk在安装好centos之后，第一件事就是安装jdk（三个centos实例执行相同的操作）。因为storm是基于Java的。首先需要将centos7自带的Java组件删除，查看自带Java组件的命令是： 1rpm -qa|grep java 然后将所有自带的组件删除： 1sudo rpm -e --nodeps java-1.7.0-openjdk-1.7.0.75-2.5.4.2.el7_0.x86_64 python-javapackages-3.4.1-6.el7_0.noarch tzdata-java-2015a-1.el7.noarch java-1.7.0-openjdk-headless-1.7.0.75-2.5.4.2.el7_0.x86_64 javapackages-tools-3.4.1-6.el7_0.noarch 下载jdk（tar.gz格式的，本文下载的是jdk-8u211-linux-x64.tar.gz），然后在&#x2F;home目录下新建java目录，将jdk压缩包放置该目录下，然后执行如下命令解压： 1sudo tar -zxvf jdk-8u211-linux-x64.tar.gz 在&#x2F;home&#x2F;java目录下会生成解压之后的文件，即jdk1.8.0_211。接下来需要将Java路径配置到系统路径中，即将如下代码添加到&#x2F;etc&#x2F;profile文件中。 1234ZOOKEEPER_HOME=/home/dzb/app/zookeeper-3.4.9 # 这个是zookeeper的变量，暂且忽略export JAVA_HOME=/home/java/jdk1.8.0_211export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarexport PATH=$PATH:$JAVA_HOME/bin:$ZOOKEEPER_HOME/bin # 最后一个分号后面的是zookeeper的变量，暂且忽略 然后执行命令使配置立即生效： 1source /etc/profile 然后就可以执行java,javac查看Java环境是否配置成功。 安装zookeeper在jdk安装成功之后就可以安装zookeeper了，过程也十分简单。首先在一个centos实例上安装zookeeper。 本文使用的是zookeeper-3.4.9，下载tar.gz格式的。然后放置&#x2F;home&#x2F;dzb&#x2F;app目录下（也可以是其它目录，只不过配置系统路径时需要相应修改），进入该目录，使用如下命令解压： 1tar -zxvf zookeeper-3.4.9.tar.gz 解压完成之后，需要对zookeeper进行配置，首先需要拷贝一份样例配置文件。 12cd zookeeper-3.4.9/conf/cp zoo_sample.cfg zoo.cfg 然后在zoo.cfg中增加自己的配置，可以参考下图进行配置。 在上图中，dataDir负责存储内存中的数据库快照的位置，如果没有指定dataLogDir，还将存储数据库更新的事务日志。dataLogDir负责存储数据库更新的事务日志。上图中配置了zookeeper-3.4.9&#x2F;data&#x2F;和zookeeper-3.4.9&#x2F;logs&#x2F;两个路径，但是data和logs目录并不存在，所以需要手动创建。 server.1&#x3D;192.168.9.128:2888:3888是用来配置集群节点的，格式为server.id&#x3D;host:port1:port2,具体含义如下： server.id中的id为一个数字，表示zk进程的id，这个id也是data目录下myid文件的内容（myid文件需要自己新建，并且写入对应的id）,各个进程的id不可以重复。 host 是该zk进程（zookeeper节点）所在的IP地址 port1 表示follower和leader交换消息所使用的端口 port2 表示选举leader所使用的端口 在上述配置文件中一共配置了三个zookeeper节点。在配置完成之后，需要在每个zookeeper节点的data目录下生成myid文件，保存进程的id。以server.1&#x3D;192.168.9.128:2888:3888对应的节点为例，在zookeeper-3.4.9目录下执行如下命令（其它节点同理）： 1echo &quot;1&quot; &gt; data/myid 三个centos实例均按照上述流程安装zookeeper。 需要注意的是，每新增一个zookeeper节点，都需要在集群每个节点的zoo.cfg增加server.id&#x3D;host:port1:port2。并且在新增节点的data目录下生成myid文件。 之后需要将zookeeper路径追加到系统路径中，参见安装jdk部分的图示。 为了避免防火墙对zookeeper造成影响，还需要关闭防火墙。执行如下命令： 12禁用防火墙命令 systemctl disable firewalld.service 停止防火墙 systemctl stop firewalld.service 最后，测试zookeeper服务。测试之前首先要启动所有节点的zookeeper服务，zookeeper服务管理可以使用脚本控制（见参考文献3）。下面是zookeeper基础命令。 123zkServer.sh start #启动zkServer.sh status #查看状态zkServer.sh start #关闭 参考文献1 zookeeper3.4.9集群模式安装部署2 zookeeper三节点集群安装记录3 CentOs7.3 搭建 ZooKeeper-3.4.9 Cluster 集群服务4 Zookeep启动正常，却报错：Error contacting service. It is probably not running.5 CentOS7 下载安装jdk1.8","tags":[{"name":"zookepper","slug":"zookepper","permalink":"http://aeyoo.net/tags/zookepper/"},{"name":"centos7","slug":"centos7","permalink":"http://aeyoo.net/tags/centos7/"}]},{"title":"深度学习调参初级版","date":"2019-05-30T08:35:44.000Z","path":"2019/05/30/深度学习调参初级版/","text":"今天介绍一些深度学习调参的初级经验。其实知乎上已经有相关问题了，见《 深度学习调参有哪些技巧？》，这里总结一下，并做一些补充。对于初学者来说，深度学习调参有几个比较重要的参数。学习率，损失函数，层大小，参数正则化，参数初始化的分布，优化函数，模型深度，dropout，batch大小。先引入量子位的一张图： 1 学习率学习率是深度学习调参中一个比较重要的参数，其决定了模型收敛的速度，以及是否可以收敛到极值。学习率很大模型收敛地很快，但是收敛到一定程度模型容易发生震荡，无法达到极值点；将学习率设置很大也容易导致loss变成Nan。如果学习率设置地很小，模型会训练地比较慢，也可能落入局部极小值。 一般学习率可以从0.1或0.01开始尝试。大多数情况下，使用衰减学习率有助于模型训练，在TF中实现了学习率的指数衰减函数 tf.train.exponential_decay()。函数原型如下： 12345678tf.train.exponential_decay( learning_rate, # 上一轮学习率 global_step, # 自增 decay_steps, # 通常表示完整使用一遍训练数据所需要的迭代轮数,总训练样本/一个batch样本数 decay_rate, # 衰减系数 staircase=False, # 当staircase=True, global_step/decay_steps为整数,此时学习率变成阶梯函数 name=None) 上述函数实现了如下功能： 12decayed_learning_rate = learning_rate * decay_rate ^ (global_step / decay_steps) 举个例子: 123456789global_step = tf.Variable(0, trainable=False)starter_learning_rate = 0.1learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step, 100, 0.96, staircase=True)# Passing global_step to minimize() will increment it at each step.learning_step = ( tf.train.GradientDescentOptimizer(learning_rate) .minimize(...my loss..., global_step=global_step)) 上述代码指定了staircase&#x3D;True，所以每训练100轮后学习率乘以0.96。 2. 损失函数TF既支持经典的损失函数，也支持自定义损失函数。一般用的交叉熵，别的损失函数没有怎么实践过。 3. 参数正则化一般使用L2正则化对权重和偏置参数做限制，通过函数 tf.nn.l2_loss 实现。具体用法： 12regularizers = tf.nn.l2_loss(weights['h1']) + tf.nn.l2_loss(biases['b1']) cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y) + beta * regularizers) L2正则的beta参数可以设置0.0001，也可以尝试下0.001。 4. 层大小知道这个有影响，但是还没有摸索出什么经验。 5. 参数初始化的分布参数初始化一般就是高斯分布&#x2F;均匀分布，但是在使用上述两种方式初始化时，可以采用一定的技巧，引用知乎用户萧瑟的回答： uniform均匀分布初始化：w &#x3D; np.random.uniform(low&#x3D;-scale, high&#x3D;scale, size&#x3D;[n_in,n_out]) Xavier初始法，适用于普通激活函数(tanh,sigmoid)：scale &#x3D; np.sqrt(3&#x2F;n) He初始化，适用于ReLU：scale &#x3D; np.sqrt(6&#x2F;n) normal高斯分布初始化：w &#x3D; np.random.randn(n_in,n_out) * stdev # stdev为高斯分布的标准差，均值设为0 Xavier初始法，适用于普通激活函数 (tanh,sigmoid)：stdev &#x3D; np.sqrt(n) He初始化，适用于ReLU：stdev &#x3D; np.sqrt(2&#x2F;n)svd初始化：对RNN有比较好的效果。参考论文：https://arxiv.org/abs/1312.6120 Xavier初始法论文：http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdfHe初始化论文：https://arxiv.org/abs/1502.01852 Xavier初始化基本思想是：保持输入和输出的方差一致，这样就避免了所有输出值都趋向于0 He初始化基本思想是：在ReLU网络中，假定每一层有一半的神经元被激活，另一半为0，所以，要保持variance不变，只需要在Xavier的基础上再除以2。 详细可以看下这篇文章《聊一聊深度学习的weight initialization》，讲的挺好的。 大多数情况下使用上述初始化方式已足够，但是也有例外。有人使用全0初始化取得了不错的效果，所以参数初始化并没有什么固定的结论，多尝试下吧。一般来说，良好的初始化可以让参数更加逼近最优解，大大提高收敛速度，防止局部最小。 另外，TF的随机数生成函数如下表所示： 函数名称 随机数分布 主要参数 tf.random_normal 正太分布 平均值，标准差，取值类型 tf.truncated_normal 正太分布，但如果随机出来的值偏离平均值超过2个标准差，则重新随机 平均值，标准差，取值类型 tf.random_uniform 均匀分布 最小、最大取值、 取值类型 tf.random_gamma Gamma 分布 形状参数、尺度参数beta，取值类型 1tf.Variable(tf.random_normal([gender_emlen], stddev=std)) TF也支持通过常数初始化一个变量，下表是常用的常量声明方法： 函数名称 功能 样例 tf.zeros 产生全0的数组 tf.zeros([2,3], int32) -&gt; [[0,0,0],[0,0,0]] tf.ones 产生全0的数组 tf.ones([2,3], int32) -&gt; [[1,1,1],[1,1,1]] tf.fill 产生全为给定数字的数组 tf.fill([2,3],9) -&gt; [[9,9,9],[9,9,9]] tf.constant Gamma 分布 tf.constant([1,2,3] -&gt; [1,2,3]) 6. 优化函数我目前使用adam函数多一些，据说adam在大多数场景表现良好。另外，sgd +momentum据说也不错？ 7. 模型深度在工业上一般使用浅层模型，我一般尝试不超过4层网络，多了效果通常不太理想，收敛太慢。 8. dropoutdropout一般设置0.4-0.6，通常设置0.5，这样网络变化最大。但是也不是绝对的。 9. batch大小之所以神经网络模型会分batch训练，是因为当数据集很大时内存放不下，而一条一条数据集进行训练会导致模型震荡不收敛，所以选择了一个折中方案，即批训练。 增大batch的好处: 内存利用率提高，每个epoch训练的轮次减少，训练相同的数据量时间更短； 一定范围内，提高batch可以使得模型训练更稳定，不至于严重震荡(相对地，参数更新相对更慢，达到相同精度所需要的时间增加)。 增大batch可能引起的问题: 内存不够； 跑完一个epoch的轮次减少，达到相同精度所需要的epoch次数增加，即增加了训练时间； batch增大到一定程度，其下降方向基本不再变化； 过大的batch会大大降低了下降的随机性，模型可能达到局部极小值，精度降低； 过大的batch会大大降低了下降的随机性，模型的泛化性能可能会下降，见知乎用户龙鹏-言有三的回答。 知乎用户龙鹏-言有三还给出了两个建议： 如果增加了学习率，那么batch size最好也跟着增加，这样收敛更稳定。 尽量使用大的学习率，因为很多研究都表明更大的学习率有利于提高泛化能力。如果真的要衰减，可以尝试其他办法，比如增加batch size，学习率对模型的收敛影响真的很大，慎重调整。 对于batch大小的取值，知乎用户夕小瑶也给出的自己的经验： 对于SGD（随机梯度下降）及其改良的一阶优化算法如Adagrad、Adam等是没问题的，但是对于强大的二阶优化算法如共轭梯度法、L-BFGS来说，如果估计不好一阶导数，那么对二阶导数的估计会有更大的误差，这对于这些算法来说是致命的。 因此，对于二阶优化算法，减小batch换来的收敛速度提升远不如引入大量噪声导致的性能下降，因此在使用二阶优化算法时，往往要采用大batch哦。此时往往batch设置成几千甚至一两万才能发挥出最佳性能。 另外，听说GPU对2的幂次的batch可以发挥更佳的性能，因此设置成16、32、64、128…时往往要比设置为整10、整100的倍数时表现更优（不过我没有验证过，有兴趣的同学可以试验一下~） 参考文献 tf.train.exponential_decay 聊一聊深度学习的weight initialization 你有哪些deep learning（rnn、cnn）调参的经验？ 深度学习调参有哪些技巧？ 深度学习中的batch的大小对学习效果有何影响？龙鹏-言有三 训练神经网络时如何确定batch size？夕小瑶","tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://aeyoo.net/tags/深度学习/"},{"name":"调参","slug":"调参","permalink":"http://aeyoo.net/tags/调参/"}]},{"title":"记一次深度学习实践之空间复杂度的坑","date":"2019-05-28T12:12:23.000Z","path":"2019/05/28/记一次深度学习实践之空间复杂度的坑/","text":"本文简要谈一下深度学习模型的空间复杂度，初学者在第一次写神经网络模型时很容易忽视空间复杂度导致内存溢出。 最近因为工作需要尝试一些深度学习的模型，之前少有做深度学习的经验，所以踩了一些坑。刚开始写了一个简单的DNN模型，然后放到集群上跑，很快跑出了结果，于是就例行化了。 在例行化第一个版本的时候，按照默认设置，申请了大概10g的内存。但是集群是动态扩容的，在模型训练过程中会根据需要自动扩充内存。由于第一次写深度学习模型，并没有去估计实际的空间复杂度，所以对其空间复杂度并不清晰。模型实际用了大概100g+的内存，但是我是无感的，集群自动帮我做了扩容。 最近因为效果不好排查问题，发现模型好久没有跑出来了，看了下日志，并没有发现有异常。一度以为是同事占用的资源太多被影响了，于是减少了训练集发现还是不行。然后我询问了运维。运维看了下日志，说：是宿主机的内存不够了，gpu虚拟集群 会动态根据程序的需求进行动态扩容，如果宿主机还存在剩余的内存，那么进行扩容。如果内存不足，则无法扩容。在宿主机内存耗尽之后监控进程会根据需要杀死超出预设内存最大的任务，且不会自动恢复。由于我的程序超出了大概100g，所以被杀死了。 之所以我的模型占用了很大内存，是因为对特征进行one-hot之后空间复杂度陡增，仅特征大小就是40w*7w*4byte&#x3D;104g，无疑是超了，我都怀疑之前是怎么跑完模型的。解决： 按需one-hot。为了方便，还是直接加载全部特征到内存，分批次梯度求导的时候，对当前批次进行one-hot，设置batch小一些，大概500-1000左右。设置batch&#x3D;500，特征大小为0.13g，参数数量基本上也是这个量级，估计0.5g的空间复杂度，基本上符合内存需求。 也考虑过使用稀疏矩阵的方式，这样更具泛化性。但是没有找到怎么获取稀疏矩阵的子矩阵，所以没有采用该方式。在tensorflow中，类SparseTensor表是一个稀疏张量。函数为 SparseTensor(values, indices, dense_shape): indices: 一个二维的张量，数据类型是int64，数据维度是[N, ndims]。 values: 一个一维的张量，数据类型是任意的，数据维度是[N]。 dense_shape: 一个一维的张量，数据类型是int64，数据维度是[ndims]。其中，N表示稀疏张量中存在N个值，ndims表示SparseTensor的维度。 因为特征很稀疏，所以也可以考虑使用特征矩阵非零列id 乘 权重矩阵对应的行。个人猜想，tf.sparse_tensor_dense_matmul 可能使用了相似的思想，之后研究一下。 附上通过list生成稀疏矩阵的代码，来自GCN作者，github可搜到。 1234567891011121314151617181920212223242526272829# 生成稀疏向量的元组表示def sparse_to_tuple(sparse_mx): sparse_mx = sp.csc_matrix(sparse_mx) \"\"\"Convert sparse matrix to tuple representation.\"\"\" def to_tuple(mx): if not sp.isspmatrix_coo(mx): mx = mx.tocoo() coords = np.vstack((mx.row, mx.col)).transpose() values = mx.data shape = mx.shape return coords, values, shape print(\"sparse_mx shape:\") print(sparse_mx.shape) # (2708, 1433) if isinstance(sparse_mx, list): for i in range(len(sparse_mx)): sparse_mx[i] = to_tuple(sparse_mx[i]) else: sparse_mx = to_tuple(sparse_mx) return sparse_mxdata = [[1,0,0],[0,0,2]]sparse_data = sparse_to_tuple(data)sess=tf.Session()# 根据稀疏向量的元组表示生成稀疏向量a=tf.SparseTensor(sparse_data[0], sparse_data[1], sparse_data[2])print(sess.run(a)) 接下来专攻一下tensorflow语法及深度学习模型，顺便看下pytorch。立flag为证！ 相关文献 Tensorflow Python API 翻译（sparse_ops）这篇文章很不错。","tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://aeyoo.net/tags/深度学习/"}]},{"title":"正太分布简介","date":"2019-05-19T13:13:11.000Z","path":"2019/05/19/正太分布简介/","text":"本文将介绍概率论与数理统计中的一个重要分布—正太（高斯）分布。在机器学习中，很多算法都假定其先验分布是正太分布。几乎可以说，正太分布是最常用的分布。 1. 概率密度函数和概率分布函数概率密度函数和概率分布函数都是基于随机变量的。在概率论中，随机变量分为离散型随机变量和连续型随机变量。 如果随机变量的值可以都可以逐个列举出来，则为离散型随机变量。如果随机变量X的取值无法逐个列举则为连续型变量。 概率论的核心在于研究随机变量的概率分布。为了理解更加直观，我们首先介绍离散型随机变量的概率密度函数和概率分布函数。 1.1 离散型随机变量的概率密度函数和概率分布函数概率函数是描述随机变量取值概率的函数。以掷骰子为例，其概率函数可以描述为： $$p_i&#x3D;P(X&#x3D;a_i) , i&#x3D;1,2,3,4,5,6$$ 在上式中，X是一个随机变量表示在掷骰子的值，$a_i$表示掷骰子所有可能的取值，$p_i$表示一次实验中掷骰子取值为$a_i$的概率，而P就是我们所说的概率函数。在掷骰子这个事件中，$p_i&#x3D;\\frac{1}{6}$。 离散型随机变量的概率分布依然在描述随机变量取值的概率，不过它更侧重于分布，例如下表： X $x_1$ $x_2$ … $x_n$ $p_i$ $p_1$ $p_2$ … $p_n$ 上表很清晰地描述了随机变量X所有取值的概率分布，实际上，概率函数和概率分布本质上都是在描述随机变量的概率，只不过是两种不同的形式。需要注意的是，概率分布必须要所有取值的概率分布。 概率分布函数有时也被叫做累积概率函数或累积分布函数。设离散型随机变量X的概率函数是$P \\lbrace X&#x3D;X_k \\rbrace &#x3D;p_k$，则概率分布函数F(x)为： $$F(x)&#x3D;P(X \\leq x)&#x3D;\\sum_{x_k \\leq x} {p_k}$$ 由于F(x)是X取$\\leq x$的诸值$x_k$的概率之和，所以F(x)也叫累积概率函数。 1.2 连续型随机变量的概率密度函数和概率分布函数连续型随机变量的概率函数和概率分布函数和在离散型随机变量中的定义类似。连续型随机变量的概率函数也叫概率密度函数。这里可以讲一下“密度函数”的由来。在陈希孺老师所著的《概率论与数理统计》描述如下： “密度函数”这个名词的来由可以解释如下，取定一个点x，则按分布函数的定义，事件$\\lbrace x\\lt X \\leq x+h\\rbrace$的概率（h&gt;0 为常数),应为F(x + h) - F(x)，所以，比值[F(x+h) - F(x)]&#x2F;h可以解释为在x点附近h这么长的区间(x,x+h)内，单位长所占有的概率。令 $h \\to 0$，则这个比的极限，即 $F’(x)&#x3D;f(x)$，也就是在x点处(无穷小区段内)单位长的概率，或者说，它反映了概率在x点处的“密集程度“。你可以设想一条极细的无穷长的金属杆，总质量为1，概率密度相当于杆上个点的质量密度。 也就是 $$P(a \\leq X \\leq b)&#x3D;F(b)-F(a)&#x3D;\\int_a^b {P(x)} ,{\\rm d}x$$ 2. 正太分布2.1 正态分布若连续性随机变量X的的概率密度函数为 $$f(x)&#x3D;\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}, \\quad -\\infty &lt;x&lt;+\\infty$$ 其中$\\mu, \\sigma (\\sigma&gt;0)$为常数，则称X服从参数为$\\mu, \\sigma$的正太分布或高斯分布，记为$X\\sim N(\\mu, \\sigma^2)$。 f(x)具有以下性质： f(x)关于$x&#x3D;\\mu$对称； 当$x&#x3D;\\mu$时，f(x)取得最大值； x离$\\mu$越远，f(x)的值越小。这表明对于同样长度的区间，当区间离$\\mu$越远，X落在这个区间的概率越小。 X的分布函数为 $$F(x)&#x3D;\\frac{1}{\\sqrt{2\\pi}\\sigma}\\int_{ -\\infty }^x {e^{-\\frac{(t-\\mu)^2}{2\\sigma^2}} ,{\\rm d}t}$$ 特别地，当$\\mu&#x3D;0, \\sigma&#x3D;1$时，称随机变量X服从标准正太分布，其概率密度和分布函数分别用$\\varphi(x), \\Phi(x)$表示，即： $$\\varphi(x)&#x3D;\\frac{1}{\\sqrt{2\\pi}}e^{-t^2&#x2F;2}$$$$\\Phi(x)&#x3D;\\frac{1}{\\sqrt{2\\pi}}\\int_{ -\\infty }^x {e^{-t^2&#x2F;2} ,{\\rm d}t}$$ 易知 $$\\Phi(-x)&#x3D;1-\\Phi(x)$$ 2.2 标准正太分布一般，若$X\\sim N(\\mu, \\sigma^2)$，我们只需要通过一个线性变换就可以将其转为标准正太分布。 引理： 若$X\\sim N(\\mu, \\sigma^2)$，则$Z&#x3D;\\frac{X-\\mu}{\\sigma} \\sim N(0,1)$ 证： $Z&#x3D;\\frac{X-\\mu}{\\sigma}$的分布函数为 $$P\\lbrace Z\\leq x\\rbrace&#x3D;P \\lbrace \\frac{ X-\\mu}{\\sigma} \\leq x \\rbrace&#x3D; P\\lbrace X\\leq \\mu + \\sigma x\\rbrace$$ $$&#x3D;\\frac{1}{\\sqrt{2\\pi}\\sigma}\\int_{ -\\infty }^{\\mu + \\sigma x} {e^{-\\frac{(t-\\mu)^2}{2\\sigma^2}} ,{\\rm d}t}$$ 令$\\frac{t-\\mu}{\\sigma}&#x3D;u$，则 $$P\\lbrace Z\\leq x\\rbrace &#x3D; \\frac{1}{\\sqrt{2\\pi}}\\int_{ -\\infty }^x {e^{-u^2&#x2F;2} ,{\\rm d}u}&#x3D;\\Phi(x)$$ 由此可知$Z&#x3D;\\frac{t-\\mu}{\\sigma}\\sim N(0,1)$。于是，若$X\\sim N(\\mu, \\sigma^2)$，则它的分布函数可写成 $$F(x)&#x3D;P\\lbrace X\\leq x\\rbrace&#x3D;P\\lbrace \\frac{X-\\mu}{\\sigma} \\leq \\frac{x-\\mu}{\\sigma}\\rbrace&#x3D;\\Phi(\\frac{x-\\mu}{\\sigma})$$ 对于任意区间$(x_1,x_2]$，有 $$P\\lbrace x_1 &lt; X \\leq x_2\\rbrace&#x3D;P\\lbrace \\frac{x_1-\\mu}{\\sigma} &lt; \\frac{X-\\mu}{\\sigma} \\leq \\frac{x_2-\\mu}{\\sigma} \\rbrace$$ $$&#x3D;\\Phi(\\frac{x_2-\\mu}{\\sigma})-\\Phi(\\frac{x_1-\\mu}{\\sigma})$$ 此外，由$\\Phi(x)$的函数表可知 $$P\\lbrace \\mu-\\sigma &lt; X \\leq \\mu + \\sigma\\rbrace&#x3D;\\Phi(1)-\\Phi(-1)&#x3D;2\\Phi(1)-1&#x3D;0.6826$$ $$P\\lbrace \\mu-2\\sigma &lt; X \\leq \\mu + 2\\sigma\\rbrace&#x3D;\\Phi(2)-\\Phi(-2)&#x3D;2\\Phi(2)-1&#x3D;0.9544$$ $$P\\lbrace \\mu-3\\sigma &lt; X \\leq \\mu + 3\\sigma\\rbrace&#x3D;\\Phi(3)-\\Phi(-3)&#x3D;2\\Phi(3)-1&#x3D;0.9974$$ 由此可知，虽然正太变量的取值范围是$(-\\infty,+\\infty)$，但是它的值基本落在$(\\mu-3\\sigma,\\mu+3\\sigma)$中，即“$3\\sigma$”法则。 2.3 上$\\alpha$分位点为了便于数理统计上的应用，对于标准正太变量，引入上$\\alpha$分位点的定义。 设$X\\sim N(0, 1)$，若$z_{\\alpha}$满足条件 $$P\\lbrace X&gt;z_{\\alpha}\\rbrace&#x3D;\\alpha, \\quad 0&lt;a&lt;1$$ 则称点$z_{\\alpha}$为标准正太分布的上$\\alpha$分位点，如下图所示。 下面是几个常用的$z_{\\alpha}$的值。 $\\alpha$ 0.001 0.005 0.01 0.025 0.05 0.10 $z_{\\alpha}$ 3.090 2.576 2.326 1.960 1.645 1.282 由$\\varphi(x)$图形的对称性可知，$z_{1-\\alpha}&#x3D;-z_{\\alpha}$。 2.4 正太分布的一些性质 如果$X\\sim N(\\mu, \\sigma^2)$且a与b都是实数，那么$aX+b\\sim N(a\\mu+b, (a\\sigma)^2)$； 如果$X\\sim N(\\mu_X, \\sigma^2_X)$与如果$Y\\sim N(\\mu_Y, \\sigma^2_Y)$是相互独立的正太随机变量，则： 它们的和满足正太分布$U&#x3D;X+Y\\sim N(\\mu_X+\\mu_Y,\\sigma^2_X +\\sigma^2_Y)$； 它们的差满足正太分布$U&#x3D;X-Y\\sim N(\\mu_X-\\mu_Y,\\sigma^2_X +\\sigma^2_Y)$； U与V两者是相互独立的。（要求X与Y的方差相等？） 如果$X_1,…,X_n$为独立标准正太随机变量，那么$X^2_1+\\cdots +x^2_n$服从自由度为n的卡方分布。 正太分布是无限可分的概率分布。 2.5 中心极限定理正态分布有一个非常重要的性质：在特定条件下，大量统计独立的随机变量的平均值的分布趋于正态分布，这就是中心极限定理。中心极限定理的重要意义在于，根据这一定理的结论，其他概率分布可以用正态分布作为近似。 参数为n和p的二项分布，在n相当大且p接近于0.5的时候近似于正太分布，近似正太分布平均数为$\\mu&#x3D;np$且方差为$\\sigma^2&#x3D;np(1-p)$； **泊松分布带有参数 $\\lambda$ 当取样样本数很大时将近似正态分布$\\lambda$**，近似正态分布平均数为$ \\mu &#x3D; \\lambda$且方差为 $\\sigma^2 &#x3D; \\lambda$。 参考文献 应该如何理解概率分布函数和概率密度函数？ 《浙江大学概率论与数理统计》盛骤等 正态分布 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} });","tags":[{"name":"正态分布","slug":"正态分布","permalink":"http://aeyoo.net/tags/正态分布/"},{"name":"概率密度函数","slug":"概率密度函数","permalink":"http://aeyoo.net/tags/概率密度函数/"},{"name":"概率分布函数","slug":"概率分布函数","permalink":"http://aeyoo.net/tags/概率分布函数/"}]},{"title":"mac下配置多个git账户","date":"2019-05-12T03:24:56.000Z","path":"2019/05/12/mac下配置多个git账户/","text":"关于mac下如何配置多个git账户，文章《Mac下配置多个Git账户》已经讲的非常好了，我这里再简要补充一下。 背景本人之前使用github托管了hexo博客，使用coding.net托管了hexo博客源码。现在想新增一个git账户。 补充文章《Mac下配置多个Git账户》讲的非常好了。但是仍然有几点需要注意： 1 如果你之前基于hexo+github搭建博客，那么你很大概率使用了 git config --global user.name &quot;xxx&quot; 命令配置git账户。当你按照《Mac下配置多个Git账户》文章清除了git全局配置之后，github的git账户其实是没有配置用户名和邮箱的。此时可能会报错：『fatal: unable to auto-detect email address』。你并不能期望使用 git config user.name &quot;xxx&quot; 命令进行配置，因为gitHub的git默认配置位于 .deploy_git/git/config下， git config user.name &quot;xxx&quot; 默认修改的是文件.&#x2F;.git&#x2F;config，所以只会修改针对coing.net的git账户的用户名和密码。 针对上述错误，只需要在.deploy_git&#x2F;git&#x2F;config配置文件中，加入相应的用户名和邮箱即可。例如： 123[user] name = xxx email = xxx hexo blog的git目录情况如下： 2 如果使用了coding.net，那么其 HostName 是 git.coding.net，也就是git clone url命令中的url的域名部分，需注意。 3 在.ssh&#x2F;config文件中配置了别名是为了区分不同的ssh公钥，在各仓库中的config配置中，既可以使用别名，也可以使用原来的域名。 4 有些git仓库可能需要在.ssh&#x2F;config中修改端口号，不然无法访问。 参考文献1.《Mac下配置多个Git账户》","tags":[{"name":"git","slug":"git","permalink":"http://aeyoo.net/tags/git/"}]},{"title":"spark源码剖析之textFile函数","date":"2019-05-11T06:42:17.000Z","path":"2019/05/11/spark源码剖析之textFile函数/","text":"最近因为工作需要，打算阅读一下spark的源码。首先研究一下spark是如何读入数据的。关于spark读取数据的机制，其实知乎上已经有大牛回答了，见@连城（内存有限的情况下 Spark 如何处理 T 级别的数据？），如果对spark源码已经有一定的了解，该回答还是非常形象易懂的。 一 阅读spark源码的姿势因为我并非系统地研究spark,只是想在需要的时候查询一下某个函数的实现，所以可以直接在IDEA中，选中某个函数，使用快捷键ctrl+b（mac下是cmd+b），查看该函数的实现，这时候会提示 download source code，按照提示下载之后，再使用该命令就可以查看函数实现。 二 spark数据读取机制2.1 textFile函数textFile函数是spark中的数据读取函数，其path参数可以是HDFS，本地文件，或者其它hadoop支持的文件系统地URL，其返回类型是 RDD[String]。 minPartitions&#x3D; math.min(defaultParallelism, 2) 是指定数据的分区，如果不指定分区，当你的核数大于2的时候，不指定分区数那么就是 2 1234567891011/** * Read a text file from HDFS, a local file system (available on all nodes), or any * Hadoop-supported file system URI, and return it as an RDD of Strings. */def textFile( path: String, minPartitions: Int = defaultMinPartitions): RDD[String] = withScope &#123; assertNotStopped() hadoopFile(path, classOf[TextInputFormat], classOf[LongWritable], classOf[Text], minPartitions).map(pair =&gt; pair._2.toString).setName(path)&#125; textFile函数读取数据的n种姿势： 读取当前目录下的一个文件 12val path = \"hello.txt\"val rdd = sc.textFile(path) 读取当前目录下的多个文件 12val path = \"hello1.txt,hello2.txt\"val rdd = sc.textFile(path) 从本地文件系统读取一个文件 12val path = \"file:///usr/local/spark/hello.txt\" //local fileval rdd1 = sc.textFile(path) 读取hdfs的一个目录 12val path = \"hdfs://xxx/xxx/traindata/\"val rdd = sc.textFile(path) 通配符 12val path = \"hdfs://xxx/xxx/traindata/2019051120*\"val rdd = sc.textFile(path) 2.2 RDD 的转换之所以要讲spark rdd的转换和计算流程(章节2.3)，是因为spark数据读取机制是基于spark rdd转换和计算的。众所周知，spark是惰性计算的，在spark中有两种操作：transform 和 action。spark会将所有的transform操作连接成图，如果遇到action操作就计算该图。也就是说，使用textFile函数并非立即读取数据的，而是等到执行action操作的时候才会真正地读取数据。 首先给出结论：在spark内部，单个executor进程内rdd的分片数据是流式访问的。以下面代码为例： 123var rdd = sc.textFile(\"hdfs://xxx/hello.txt\"); var rdd_new = rdd.map(_.split(\",\")); print(rdd_new.count())； 上面代码比较简单，不再介绍。我们再看一下textFile函数的实现： 12345678def textFile( path: String, minPartitions: Int = defaultMinPartitions): RDD[String] = withScope &#123; assertNotStopped() hadoopFile(path, classOf[TextInputFormat], classOf[LongWritable], classOf[Text], minPartitions).map(pair =&gt; pair._2.toString).setName(path)&#125; 可以看出，textFile函数的核心是，调用了一个hadoopFile函数，然后进行了一个map操作，获取了第二个元素。hadoopFile的参数除了path之外，还有 classOf[TextInputFormat], classOf[LongWritable], classOf[Text]。如果有过hadoop的开发经验，肯定对这三个参数比较熟悉。最后还有一个minPartitions参数。 然后我们看一下hadoopFile对象是什么样子的。 123456789101112131415161718192021222324252627/** Get an RDD for a Hadoop file with an arbitrary InputFormat * * '''Note:''' Because Hadoop's RecordReader class re-uses the same Writable object for each * record, directly caching the returned RDD or directly passing it to an aggregation or shuffle * operation will create many references to the same object. * If you plan to directly cache, sort, or aggregate Hadoop writable objects, you should first * copy them using a `map` function. */def hadoopFile[K, V]( path: String, inputFormatClass: Class[_ &lt;: InputFormat[K, V]], keyClass: Class[K], valueClass: Class[V], minPartitions: Int = defaultMinPartitions): RDD[(K, V)] = withScope &#123; assertNotStopped() // A Hadoop configuration can be about 10 KB, which is pretty big, so broadcast it. val confBroadcast = broadcast(new SerializableConfiguration(hadoopConfiguration)) val setInputPathsFunc = (jobConf: JobConf) =&gt; FileInputFormat.setInputPaths(jobConf, path) new HadoopRDD( this, confBroadcast, Some(setInputPathsFunc), inputFormatClass, keyClass, valueClass, minPartitions).setName(path)&#125; 可以看到，hadoopFile返回了k-v格式的rdd。在hadoopFile内部，首先对hadoopConfiguration进行了广播，然后设置了一个setInputPathsFunc 函数。最重要的，在hadoopFile函数内部，新建了一个HadoopRDD对象并返回。也就是说，textFile函数中实际上是调用了HadoopRDD对象的map函数。而通过查看HadoopRDD的源码可以发现，class HadoopRDD是继承自抽象类RDD的。此外，在类HadoopRDD中，并没有重写类RDD中的map，reduce函数，也就是说，所有继承了RDD类的对象都是直接调用抽象类RDD中的map，reduce等方法。 在抽象类中的map方法长这个样子： 1234567891011121314abstract class RDD[T: ClassTag]( @transient private var _sc: SparkContext, @transient private var deps: Seq[Dependency[_]] ) extends Serializable with Logging &#123; /** * Return a new RDD by applying a function to all elements of this RDD. */ def map[U: ClassTag](f: T =&gt; U): RDD[U] = withScope &#123; // clean方法实际上调用了ClosureCleaner的clean方法，旨在清除闭包中的不能序列化的变量，防止RDD在网络传输过程中反序列化失败[1] val cleanF = sc.clean(f) new MapPartitionsRDD[U, T](this, (context, pid, iter) =&gt; iter.map(cleanF)) &#125;&#125; 可以看出，map方法首先对穿传进来的函数进行clean操作，然后构造了一个MapPartitionsRDD对象，它的参数我们一会再分析。这里可以确定一点，即到目前为止并没有进行数据读取，计算操作。 再看第二行代码： 1var rdd_new = rdd.map(_.split(\",\")); 通过上面的分析可知，这里的rdd其实是一个MapPartitionsRDD对象，同样地，在执行了map操作之后，也返回了一个MapPartitionsRDD对象。 再看最后一行代码： 1print(rdd_new.count())； 这里的count是一个action操作。前面提到，action操作会触发spark的图计算操作。我们可以看一下count的实现： 1234/** * Return the number of elements in the RDD. */def count(): Long = sc.runJob(this, Utils.getIteratorSize _).sum 可以看到，在count内部执行了sc.runJob()操作。runJob函数会触发DagScheduler去分解任务并提交到集群执行。 2.3 RDD的计算在action操作触发了spark的图计算之后，该任务将会被分解执行。具体地，task首先会执行最后一个rdd的compute方法。在上述代码中，最后一个rdd是一个MapPartitionsRDD对象。我们看一下MapPartitionsRDD的compute函数。 123456789101112131415161718192021/** * An RDD that applies the provided function to every partition of the parent RDD. */private[spark] class MapPartitionsRDD[U: ClassTag, T: ClassTag]( var prev: RDD[T], f: (TaskContext, Int, Iterator[T]) =&gt; Iterator[U], // (TaskContext, partition index, iterator) preservesPartitioning: Boolean = false) extends RDD[U](prev) &#123; override val partitioner = if (preservesPartitioning) firstParent[T].partitioner else None override def getPartitions: Array[Partition] = firstParent[T].partitions override def compute(split: Partition, context: TaskContext): Iterator[U] = f(context, split.index, firstParent[T].iterator(split, context)) override def clearDependencies() &#123; super.clearDependencies() prev = null &#125;&#125; 可以看到，compute函数的参数有两个：分区 split 和 Task上下文，在compute函数内部实际上调用了 f 函数。f函数是怎么来的呢？它其实是类MapPartitionsRDD的构造函数的参数，在构造MapPartitionsRDD对象的时候被传递进来的。上面分析提到，MapPartitionsRDD对象是在抽象类RDD的map函数内部构造的，f 函数也是在该地方实现的。f函数的参数有三个：第一个是task上下文，第二个是分区索引，第三个是父rdd的迭代器。 1234def map[U: ClassTag](f: T =&gt; U): RDD[U] = withScope &#123; val cleanF = sc.clean(f); new MapPartitionsRDD[U, T](this, (context, pid, iter) =&gt; iter.map(cleanF));&#125; 可以看到，f 函数的实现就是 (this, (context, pid, iter) &#x3D;&gt; iter.map(cleanF) 部分，f函数实际上调用了第三个函数参数的map方法，map方法的参数是用户调用map函数时传入的函数，本例中是split()。刚刚已经提到，f函数的第三个参数是父rdd(因为该MapPartitionsRDD的父rdd也是MapPartitionsRDD，而MapPartitionsRDD中没有iterator函数的实现，所以MapPartitionsRDD实际上调用了抽象类RDD中的)的迭代器方法iterator，我们可以看一下它是什么样子。 12345678910111213/** * Internal method to this RDD; will read from cache if applicable, or otherwise compute it. * This should ''not'' be called by users directly, but is available for implementors of custom * subclasses of RDD. */ final def iterator(split: Partition, context: TaskContext): Iterator[T] = &#123; if (storageLevel != StorageLevel.NONE) &#123; SparkEnv.get.cacheManager.getOrCompute(this, split, context, storageLevel) &#125; else &#123; computeOrReadCheckpoint(split, context) &#125;&#125; 可以看到，iterator函数首先判断，该rdd的storageLevel是否为NONE，如果不为NONE，则尝试从缓存中读取数据，如果缓存中没有，则通过计算获取对应分区数据的迭代器。如果该rdd的storageLevel为NONE，则尝试从checkpoint获取对应分区数据的迭代器，如果checkpoint不存在则通过计算获取。 iterator会返回一个迭代器，可以通过该迭代器访问父rdd的某个分区中的每个元素。如果内存在没有父rdd的数据，则调用父rdd的compute方法进行计算。 我们可以再看一下computeOrReadCheckpoint这个方法 ( 这个方法比较简单，好分析 ) 。 1234567891011/** * Compute an RDD partition or read it from a checkpoint if the RDD is checkpointing. */private[spark] def computeOrReadCheckpoint(split: Partition, context: TaskContext): Iterator[T] =&#123; if (isCheckpointedAndMaterialized) &#123; firstParent[T].iterator(split, context) &#125; else &#123; compute(split, context) &#125;&#125; 可以看到，在computeOrReadCheckpoint内部，通过调用父rdd的compute方法获取父rdd的split分区的迭代器。 可以想象，经过一层层transform操作溯源之后，最终会调用类HadoopRDD中的compute函数，它长这个样子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485override def compute(theSplit: Partition, context: TaskContext): InterruptibleIterator[(K, V)] = &#123; val iter = new NextIterator[(K, V)] &#123; val split = theSplit.asInstanceOf[HadoopPartition] logInfo(\"Input split: \" + split.inputSplit) val jobConf = getJobConf() val inputMetrics = context.taskMetrics.getInputMetricsForReadMethod(DataReadMethod.Hadoop) // Sets the thread local variable for the file's name split.inputSplit.value match &#123; case fs: FileSplit =&gt; SqlNewHadoopRDDState.setInputFileName(fs.getPath.toString) case _ =&gt; SqlNewHadoopRDDState.unsetInputFileName() &#125; // Find a function that will return the FileSystem bytes read by this thread. Do this before // creating RecordReader, because RecordReader's constructor might read some bytes val bytesReadCallback = inputMetrics.bytesReadCallback.orElse &#123; split.inputSplit.value match &#123; case _: FileSplit | _: CombineFileSplit =&gt; SparkHadoopUtil.get.getFSBytesReadOnThreadCallback() case _ =&gt; None &#125; &#125; inputMetrics.setBytesReadCallback(bytesReadCallback) var reader: RecordReader[K, V] = null val inputFormat = getInputFormat(jobConf) HadoopRDD.addLocalConfiguration(new SimpleDateFormat(\"yyyyMMddHHmm\").format(createTime), context.stageId, theSplit.index, context.attemptNumber, jobConf) reader = inputFormat.getRecordReader(split.inputSplit.value, jobConf, Reporter.NULL) // Register an on-task-completion callback to close the input stream. context.addTaskCompletionListener&#123; context =&gt; closeIfNeeded() &#125; val key: K = reader.createKey() val value: V = reader.createValue() override def getNext(): (K, V) = &#123; try &#123; finished = !reader.next(key, value) &#125; catch &#123; case eof: EOFException =&gt; finished = true &#125; if (!finished) &#123; inputMetrics.incRecordsRead(1) &#125; (key, value) &#125; override def close() &#123; if (reader != null) &#123; SqlNewHadoopRDDState.unsetInputFileName() // Close the reader and release it. Note: it's very important that we don't close the // reader more than once, since that exposes us to MAPREDUCE-5918 when running against // Hadoop 1.x and older Hadoop 2.x releases. That bug can lead to non-deterministic // corruption issues when reading compressed input. try &#123; reader.close() &#125; catch &#123; case e: Exception =&gt; if (!ShutdownHookManager.inShutdown()) &#123; logWarning(\"Exception in RecordReader.close()\", e) &#125; &#125; finally &#123; reader = null &#125; if (bytesReadCallback.isDefined) &#123; inputMetrics.updateBytesRead() &#125; else if (split.inputSplit.value.isInstanceOf[FileSplit] || split.inputSplit.value.isInstanceOf[CombineFileSplit]) &#123; // If we can't get the bytes read from the FS stats, fall back to the split size, // which may be inaccurate. try &#123; inputMetrics.incBytesRead(split.inputSplit.value.getLength) &#125; catch &#123; case e: java.io.IOException =&gt; logWarning(\"Unable to get input size to set InputMetrics for task\", e) &#125; &#125; &#125; &#125; &#125; new InterruptibleIterator[(K, V)](context, iter)&#125; 三 Spark在内存有限情况下的执行机制正如知乎连城所说，spark内部使用迭代器流式访问数据，用这个Iterator访问整个数据集，空间复杂度是O(1)。可见，Spark RDD的immutable语义并不会造成大数据内存计算任务的庞大内存开销。然而，如果spark任务被划分为多个stage，那么在 stage 0 中，通过流式访问的机制，如果内存足够大，可以容纳经过各种transform操作之后的数据，那么 stage 0 并不需要考虑内存的问题，但是如果 stage 0 和 stage 1 是通过reduce操作划分的，那么就会涉及shuffle。 在 shuffle 过程中，前一个 stage 的 ShuffleMapTask 进行 shuffle write， 把数据存储在 blockManager 上面，并且把数据位置元信息上报到 driver 的 mapOutTrack 组件中，下一个 stage 根据数据位置元信息，进行 shuffle read， 拉取上个 stage 的输出数据。例如：在原始数据中有10个字段（大小100g），在 stage 0 中经过各种transform后只留下4个字段（大小40g），那么stage 0 的ShuffleMapTask 进行 shuffle write，将40g的数据写到blockManager中，供 stage 1 进行shuffle读。 引用 知乎连城的回答： 在Spark内部，单个executor进程内RDD的分片数据是用Iterator流式访问的，Iterator的hasNext方法和next方法是由RDD lineage上各个transformation携带的闭包函数复合而成的。该复合Iterator每访问一个元素，就对该元素应用相应的复合函数，得到的结果再流式地落地（对于shuffle stage是落地到本地文件系统留待后续stage访问，对于result stage是落地到HDFS或送回driver端等等，视选用的action而定）。如果用户没有要求Spark cache该RDD的结果，那么这个过程占用的内存是很小的，一个元素处理完毕后就落地或扔掉了（概念上如此，实现上有buffer），并不会长久地占用内存。只有在用户要求Spark cache该RDD，且storage level要求在内存中cache时，Iterator计算出的结果才会被保留，通过cache manager放入内存池。 参考文献 Spark从外部读取数据之textFile spark中ClosureClean中的clean方法 Spark RDD深度解析-RDD计算流程 内存有限的情况下 Spark 如何处理 T 级别的数据？ 彻底搞懂 Spark 的 shuffle 过程（shuffle write）","tags":[{"name":"spark","slug":"spark","permalink":"http://aeyoo.net/tags/spark/"},{"name":"textFile","slug":"textFile","permalink":"http://aeyoo.net/tags/textFile/"},{"name":"源码剖析","slug":"源码剖析","permalink":"http://aeyoo.net/tags/源码剖析/"},{"name":"rdd计算","slug":"rdd计算","permalink":"http://aeyoo.net/tags/rdd计算/"}]},{"title":"trie树","date":"2018-12-17T14:35:31.000Z","path":"2018/12/17/trie树/","text":"最近了解es相关知识，发现term index是一棵trie树，于是参考网上blog，实现了一下trie数，发现这个数据结构非常实用。特记载于此。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#include&lt;iostream&gt;using namespace std;#define SIZE 26typedef struct trie_node&#123; int count; trie_node* childs[SIZE];&#125;* trie;trie create()&#123; trie_node* node = new trie_node(); node-&gt;count = 0; for(int i=0;i&lt;SIZE;i++) &#123; node-&gt;childs[i]=NULL; &#125; return node;&#125;void insert(trie root, char* k)&#123; trie_node* node = root; char* p = k; while(*p) &#123; if(node-&gt;childs[*p-'a'] == NULL) &#123; node-&gt;childs[*p-'a'] = create(); &#125; node = node-&gt;childs[*p-'a']; node-&gt;count +=1; ++p; &#125; &#125;int search(trie root, char* k)&#123; trie_node* node = root; char* p = k; while(*p &amp;&amp; node!=NULL) &#123; node = node-&gt;childs[*p-'a']; ++p; &#125; if(node == NULL) return 0; else return node-&gt;count;&#125;int main()&#123; char keys[][8]=&#123;\"the\", \"a\", \"there\", \"answer\", \"any\", \"by\", \"bye\", \"their\"&#125;; trie root = create(); for(int i=0;i&lt;8;i++) insert(root, keys[i]); printf(\"%s --- %d\\n\", \"the\", search(root, \"the\")); printf(\"%s --- %d\\n\", \"these\", search(root, \"these\")); printf(\"%s --- %d\\n\", \"their\", search(root, \"their\")); printf(\"%s --- %d\\n\", \"thaw\", search(root, \"thaw\")); printf(\"%s --- %d\\n\", \"a\", search(root, \"a\")); printf(\"%s --- %d\\n\", \"b\", search(root, \"b\")); return 0;&#125; 参考 1 elasticsearch 倒排索引原理2 Trie树（Prefix Tree）介绍这篇文章的代码貌似有点问题，看思路即可。","tags":[{"name":"trie","slug":"trie","permalink":"http://aeyoo.net/tags/trie/"}]},{"title":"一个完整的神经网络程序","date":"2018-12-02T12:00:36.000Z","path":"2018/12/02/一个完整的神经网络程序/","text":"最近需要练习一下tensorflow的使用，看了一下实战Google深度学习框架这本书，感觉不错，照着书上的例子敲一下。纯用来记忆一些语法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#coding:utf-8import tensorflow as tffrom numpy.random import RandomState# 一个完整的神经网络程序batch_size=8#tf,Variable的作用就是保存和更新神经网络的参数5w1=tf.Variable(tf.random_normal([2,3],stddev=1,seed=1))w2=tf.Variable(tf.random_normal([3,1],stddev=1,seed=1))x=tf.placeholder(tf.float32,shape=(None,2),name='x-input')y_=tf.placeholder(tf.float32,shape=(None,1),name='y-input')a=tf.matmul(x,w1)y=tf.matmul(a,w2)#定义损失函数cross_entropy=-tf.reduce_mean(y_*tf.log(tf.clip_by_value(y,1e-10,1.0)))#设置优化器，进行权重参数(w)的自动更新，这是tensorflow实现的train_step=tf.train.AdamOptimizer(0.001).minimize(cross_entropy)# generate a random dataset.rdm=RandomState(1)dataset_size=128X=rdm.rand(dataset_size,2)Y=[[int(x1+x2&lt;1)] for (x1, x2) in X]with tf.Session() as sess: init_op=tf.initialize_all_variables() sess.run(init_op) print sess.run(w1) print sess.run(w2) STEPS=10000 for i in range(STEPS): start=(i * batch_size) % dataset_size end=min(start + batch_size, dataset_size) sess.run(train_step,feed_dict=&#123;x:X[start:end],y_:Y[start:end]&#125;) if i%1000==0: total_cross_entropy=sess.run(cross_entropy,feed_dict=&#123;x:X, y_:Y&#125;) print(\"After %d training step(s), cross entropy on all data is %g\" % (i,total_cross_entropy)) print sess.run(w1) print sess.run(w2)","tags":[]},{"title":"test in ubuntu","date":"2018-12-02T06:21:07.000Z","path":"2018/12/02/test-in-ubuntu/","text":"在ubuntu下搭建了hexo blog，感觉不错。 使用Remarkable写markdown文件. 使用coding.net作为多终端同步的远程库. 感觉很清爽。真心感觉很强大啊！唯一的不足在于ubuntu没有微信，qq客户端，这是唯一的鸡肋。 记录一下ubuntu下安装指定版本的nodejs步骤. 123456789cd ~/Downloads wget https://nodejs.org/dist/v8.12.0/node-v8.12.0-linux-x64.tar.xz// 安装cd /usr/local //先cd到该目录下 tar --strip-components 1 -xJf ~/Downloads/node-v8.12.0-linux-x64.tar.xz// 验证node -v","tags":[{"name":"test in ubuntu","slug":"test-in-ubuntu","permalink":"http://aeyoo.net/tags/test-in-ubuntu/"}]},{"title":"shell常用技巧浅谈","date":"2018-11-28T09:32:45.000Z","path":"2018/11/28/shell常用技巧浅谈/","text":"好久没有更新博客了，今天来介绍一些基本的常用于Linux文本处理的shell命令，对于初入Linux任务的人兴许有一些帮助。本文不介绍命令的基础使用，只阐述一些能够提高效率的tips。shell下的几个文本处理 关于 vi跳到文本第一行，按gg跳到文本最后一行， 按G跳到行首，按0跳到行尾，按$vi加密：输入 “:” + “X” 之后，会提示输入两次密码。之后 :wq 保存退出。如果想取消密码，输入 :X ，然后输入密码，连续按两次回车ok。 tailtail命令用于输出文件中的尾部内容。默认显示文件末尾10行。如果给定的文件不止一个，则在显示的每个文件前面加一个文件名标题。 删除文件的前k-1行 12tail -n +k old_file &gt; new_file mv new_file old_file 123tail file （显示文件file的最后10行）tail +20 file （显示文件file的内容，从第20行至文件末尾）tail -c 10 file （显示文件file的最后10个字符） datedate +%s 可以得到UNIX的时间戳; awk使用外部变量有的时候我们可能需要在shell脚本中使用到外部变量。例如，判断文件中的过期时间expire_time，将其和当前时间比较。这时候就需要用到外部变量了。 12curtime=`date -d &quot;-1 days ago&quot; +%s` cat test.txt | awk -F &apos;[,;]&apos; &apos;&#123;if ($16==1 &amp;&amp; $24&gt;curtime)&#123;print $0&#125;&#125;&apos; curtime=&quot;$curtime&quot; &gt;&gt; items.txt 参考http://man.linuxde.net/taillinux中tail 命令使用详解(显示最尾部的内容)linux shell awk获得外部变量（变量传值）简介","tags":[{"name":"shell","slug":"shell","permalink":"http://aeyoo.net/tags/shell/"}]},{"title":"图卷积研究的相关进展0","date":"2018-11-11T14:09:55.000Z","path":"2018/11/11/图卷积研究的相关进展0/","text":"最近因需要调研了一下目前图卷积网络的一些研究进展，主要侧重于其理论研究及其在大规模推荐系统中的应用。现在总结一下看过的一些论文，以备后查。以下论文均为2018年发表。 1 《Stochastic Training of Graph Convolutional Networks with Variance Reduction》 图形卷积网络（GCN）是用于图形结构数据的一种强大的深度神经网络。 然而，GCN从其邻居递归地计算节点的表示，使得感受野大小随着层数呈指数增长。 先前通过对邻居节点二次采样进而减小感受野的大小的尝试没有收敛保证，并且它们每个节点的感受野大小仍然保持在数百。 这篇论文提出了一种基于控制变量的算法，该算法允许对任意小的邻居大小进行采样。 此外，该论文给出了算法收敛到GCN的局部最优的新理论保证。实证结果表明，论文中的算法与每个节点仅使用两个邻居的精确算法拥有类似的收敛，且在大型Reddit数据集上的运行时间仅为先前的邻居采样算法的七分之一。 2 《Large-Scale Learnable Graph Convolutional Networks》 卷积神经网络（CNN）在类似网格的数据（如图像）上取得了巨大成功，但在学习更通用的数据（类似于图）时面临巨大挑战。在CNN中，可训练的本地过滤器可以自动提取高维特征。基于过滤器的计算需要感受野中存在固定数量的有序单元。但是，在一般图中，相邻单元的数量既不固定，也不是有序的，从而阻碍了卷积运算的应用。在这里，我们通过提出可学习的图卷积层（LGCL）来解决这些挑战。 LGCL基于值排序自动为每个特征选择固定数量邻居节点，以便将图数据转换为一维的网格结构，从而能够在通用图上使用常规卷积运算。为了在大规模图上进行模型训练，我们提出了一种子图训练方法，以减少现有方法对图卷积所带来的过多内存和计算资源需求。我们实验结果表明，对于转导和归纳学习环境中的节点分类任务，我们的方法可以在Cora, Citeseer, Pubmed citation network 和 protein-protein interaction network datasets数据集上实现更好的性能，且性能稳定。结果还表明，与现有方法相比，使用子图训练策略的方法更有效。 3 《Confidence-based Graph Convolutional Networks for Semi-Supervised Learning》 基于置信度的半监督学习图卷积网络 预测图中节点的属性是各个领域应用的重要问题。基于图的半监督学习（SSL）方法旨在通过将一小部分节点标记为种子来解决该问题，然后利用图结构来预测图中其余节点的标签分数。最近，图形卷积网络（GCN）在基于图形的SSL任务上取得了令人印象深刻的性能。除了标签分数之外，还希望具有与它们相关联的置信度分数。不幸的是，之前没有探讨过GCN背景下的置信度估计。在本文中，我们填补了这一重要空白，并提出了ConfGCN，它基于GCN中设置的关于标签的置信度估计标签得分。 ConfGCN使用这些估计的置信度来确定邻域聚合期间一个节点对另一个节点的影响，从而获得各向异性能力。通过对标准基线的广泛分析和实验，我们发现ConfGCN能够明显优于最先进的基线。本文公开了ConfGCN的源代码，以鼓励可重复的研究。 4 《Graph Convolutional Neural Networks for Web-Scale Recommender Systems》 这篇文章主要讲了GCN在推荐系统中的应用。思路就是由 item和 user 组成的二分图（边只发生在 item 和 user 之间）。首先由各节点生成各自的初始向量（不同类型的节点的初始向量生成方法不同，如 item 和 user）。然后根据每个节点找到数量为 k 的邻居节点，如果没有节点的邻居节点数量&lt;k，那么可以使用随机游走的方式获得 k 个。然后将节点 v 的 k个邻居节点的向量拼接（论文中说实验表明，拼接比相加效果更好），和节点 v 做卷积，得到节点 v 的向量表达。 5 《FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling》 Submitted on 30 Jan 2018 最近由Kipf和Welling提出的图卷积网络（GCN）是一个有效的用于半监督学习的图模型。然而，该模型最初设计为在训练和测试数据存在的情况下学习。此外，跨层的递归邻域扩展对于使用大而密集的图数据进行训练提出了时间和内存上的挑战。为了放宽对测试数据同时可用性的要求，我们将图卷积解释为概率测度下嵌入函数的积分变换。这种解释允许使用蒙特卡罗方法来一致地估计积分，这反过来引出了我们在这项工作中提出的批量训练方案-FastGCN。通过增强重要性采样，FastGCN不仅可以有效地进行训练，而且可以很好地推广。我们展示了一套全面的实验来证明其与GCN、相关模型相比的有效性。特别是在训练效率提高了几个数量级的情况下，预测仍保持相对准确。 6 《Multi-dimensional Graph Convolutional Networks)》 ICLR 2018 卷积神经网络（CNN）在基于图像和视频等常规网格数据的表示学习上表现了强大的能力。最近，人们越来越关注将CNN应用于高度不规则的图形或网络数据。一些专注于图层次的表示学习，而另一些专注于节点层次的表示学习。已经证明这些方法可以提高任务的性能，例如图分类和节点分类。这些方法中的大多数都是针对一维的图设计的，其中一对节点只能通过一种关系连接。然而，许多真实世界的图具有多种类型的关系，并且它们可以自然地建模为多维图，每种类型的关系作为维度。多维图带来了维度之间更丰富的相关性，这对被设计用于单维图的GCN提出了巨大的挑战。在本文中，我们研究了多维图的卷积网络问题，并提出了一种多维卷积神经网络模型mGCN，旨在捕获在多维图中学习节点表示的丰富信息。对真实世界多维图的综合实验证明了所提出框架的有效性。","tags":[{"name":"GCN","slug":"GCN","permalink":"http://aeyoo.net/tags/GCN/"},{"name":"图卷积","slug":"图卷积","permalink":"http://aeyoo.net/tags/图卷积/"}]},{"title":"图卷积研究的相关进展1","date":"2018-11-11T14:09:55.000Z","path":"2018/11/11/图卷积研究的相关进展1/","text":"最近因需要调研了一下目前图卷积网络的一些研究进展，主要侧重于其理论研究及其在大规模推荐系统中的应用。现在总结一下看过的一些论文，以备后查。以下论文均为2018年发表。 1 《Adaptive Graph Convolutional Neural Networks》 自适应图卷积神经网络 图卷积神经网络（Graph CNN）是经典 CNN 的方法，可用于处理分子数据、点云和社交网络等图数据。Graph CNN 领域当前的过滤器是为固定的和共享的图结构构建的。但是，对于大多数真实数据而言，图结构的规模和连接性都会改变。本论文提出了一种有泛化能力的且灵活的Graph CNN，其可以使用任意图结构的数据作为输入。通过这种方式，可以在训练时为每个图数据都学习到一个任务驱动的自适应图。为了有效地学习这种图，我们提出了一种距离度量学习。我们在九个图结构数据集上进行了大量实验，结果表明我们的方法在收敛速度和预测准确度方面都有更优的表现[1]。 2 《A Sequential Embedding Approach for Item Recommendation with Heterogeneous Attributes》 具有异构属性的商品推荐的序列嵌入方法 诸如元数据和配置文件之类的属性携带有用的信息，这些信息原则上可以帮助提高推荐系统的准确性。然而，由于诸如异构性和稀疏性的实际挑战，现有方法难以完全利用属性信息。这些方法也无法将最近在视频和音乐推荐中显示出有效性的RNN结合起来。为了克服这些挑战并获得序列模型的优势，我们提出了一种新方法，即异构属性递归神经网络（HA-RNN），它结合了异构属性并捕获item和属性中的顺序依赖性。 HA-RNN扩展了递归神经网络，1） 是分层属性组合输入层，2）是输出属性嵌入层。我们对两个大型数据集进行了大量实验，发现与目前的模型相比，该方法有了重大提升。我们的ablation experiments 证明了这两个组件解决异构属性挑战的有效性，包括可变长度和属性稀疏性。我们进一步研究为什么序列建模可以很好地工作，并且当数据规模增加时，序列模型更有效。 3 《Leveraging Long and Short-term Information in Content-aware Movie Recommendation》 基于长短期信息的内容感知的电影推荐 电影推荐系统根据个人的偏好和约束为用户提供电影的排名列表。通常使用两种类型的模型来生成排名结果：长期模型和基于会话的模型。长期模型反映了用户和电影之间的相关性，但这些相关性应该随着时间的推移而缓慢变化；基于会话的模型会对用户兴趣和电影属性动态变化的信息进行编码。在本文中，我们提出了一个LSIC模型，其利用对抗训练方法训练在内容感知电影推荐中利用的长期和短期信息。在对抗过程中，我们训练一个生成器作为强化学习的代理，它按顺序向用户推荐下一部电影。我们还训练一个鉴别器，试图将生成的电影列表与真实记录区分开来。电影的宣传信息被收集用以进一步提高电影推荐的性能，这在电影评分很少时特别重要。实验表明，所提出的模型相比别的算法有很大优势。我们将在发布后发布这项工作的源代码。 4 《NeuRec: On Nonlinear Transformation for Personalized Ranking》 NeuRec:关于个性化排序的非线性变换 对user-item交互模式建模是个性化推荐的重要任务。 许多推荐系统基于这样的假设：用户和项目之间存在线性关系，而忽略了现实生活中交互的复杂性和非线性。 在本文中，我们提出了一种基于神经网络的推荐模型（NeuRec），它解决了user-item交互的复杂性，并建立了一个集成网络，将非线性变换与潜在特征结合起来。 我们进一步设计NeuRec的两个变体：基于用户的NeuRec和基于项目的NeuRec，其侧重于交互矩阵的不同方面。 对四个真实世界数据集的广泛实验证明了它们在个性化排名任务方面的卓越表现。 5 《xDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems》 xDeepFM: 结合显式和隐式特征交互的推荐系统 组合特征对于对于推荐任务是十分重要的，最近研究人员提出了几种基于DNN的分解模型来学习低阶和高阶特征的相互组合。尽管DNN具有很强的学习能力，但是普通的DNN隐式地并且在逐位级别上生成特征交互。在本文中，我们提出了一种新颖的压缩交互网络（CIN），旨在以显式方式和向量级别生成特征交互。我们证明了CIN与卷积神经网络（CNN）和递归神经网络（RNN）共享一些功能。我们进一步将CIN和经典DNN组合成一个统一的模型，并将这个新模型命名为eXtreme深度分解机（xDeepFM）。一方面，xDeepFM能够明确地学习某些有界度特征交互;另一方面，它可以隐式地学习任意低阶​​和高阶特征交互。我们对三个真实数据集进行了全面的实验。我们的结果表明xDeepFM优于最先进的模型。我们已经在github上发布了xDeepFM的源代码。 6 《[Modeling Cognitive Processes in Social Tagging to Improve Tag Recommendations(https://arxiv.org/pdf/1805.11878.pdf)》 对社会标签中的认知过程进行建模以改进标签的推荐 With the emergence of Web 2.0, tag recommenders have become important tools, which aim to support users in finding descriptive tags for their bookmarked resources. Although current algorithms provide good results in terms of tag prediction accuracy, they are often designed in a data-driven way and thus, lack a thorough understanding of the cognitive processes that play a role when people assign tags to resources. This thesis aims at modeling these cognitive dynamics in social tagging in order to improve tag recommendations and to better understand the underlying processes. As a first attempt in this direction, we have implemented an interplay between individual micro-level (e.g., categorizing resources or temporal dynamics) and collective macro-level (e.g., imitating other users’ tags) processes in the form of a novel tag recommender algorithm. The preliminary results for datasets gathered from BibSonomy, CiteULike and Delicious show that our proposed approach can outperform current state-of-the-art algorithms, such as Collaborative Filtering, FolkRank or Pairwise Interaction Tensor Factorization. We conclude that recommender systems can be improved by incorporating related principles of human cognition. 参考文献[1]【AAAI 2018】腾讯 AI Lab 11篇论文精选：图像描述、NMT 模型、图卷积神经网络、DNN优化等[2] https://cloud.tencent.com/developer/article/1168921","tags":[{"name":"GCN","slug":"GCN","permalink":"http://aeyoo.net/tags/GCN/"},{"name":"图卷积","slug":"图卷积","permalink":"http://aeyoo.net/tags/图卷积/"}]},{"title":"Mac下sublime安装及常用配置","date":"2018-11-07T14:01:02.000Z","path":"2018/11/07/Mac下sublime安装及常用配置/","text":"今天发现sublime3176版本很好看，遂在mac下安装使用了一番，感觉比原来的界面好看多了。本文介绍一下mac下如何安装sublime3及常用配置。 一 下载安装sublime下载地址 破解输入如下许可代码,若经济能力允许请支持正版。 12345678910111213----- BEGIN LICENSE -----sgbteamSingle User LicenseEA7E-11532598891CBB9 F1513E4F 1A3405C1 A865D53F115F202E 7B91AB2D 0D2A40ED 352B269B76E84F0B CD69BFC7 59F2DFEF E267328F215652A3 E88F9D8F 4C38E3BA 5B2DAAE4969624E7 DC9CD4D5 717FB40C 1B9738CF20B3C4F1 E917B5B3 87C38D9C ACCE7DD85F7EF854 86B9743C FADC04AA FB0DA5C0F913BE58 42FEA319 F954EFDD AE881E0B------ END LICENSE ------ 二 配置C&#x2F;C++运行环境1.首先确保你有gcc环境。在终端键入命令：gcc -v 查看是否有gcc环境(安装xcode会帮你装gcc)。在mac下，安装gcc可以通过在终端键入如下命令获得： 1brew install gcc 2.安装好gcc环境就可以直接在sublime编写C&#x2F;C++文件，然后通过command+B编译运行了。但是会出现一个问题，无法使用scanf,cin等命令。可以通过新建Build System解决。 在sublime主面板，单击菜单栏 Tools-&gt;Build System-&gt;New Build System。输入以下代码。如果sublime提示多余字符的话请删掉。 123456&#123; &quot;file_regex&quot;: &quot;^(..[^:]*):([0-9]+):?([0-9]+)?:? (.*)$&quot;, &quot;working_dir&quot;: &quot;$&#123;file_path&#125;&quot;, &quot;selector&quot;: &quot;source.c, source.c++&quot;, &quot;cmd&quot;: [&quot;bash&quot;, &quot;-c&quot;, &quot;g++ &apos;$&#123;file&#125;&apos; -o &apos;$&#123;file_path&#125;/$&#123;file_base_name&#125;&apos; &amp;&amp; open -a Terminal.app &apos;$&#123;file_path&#125;/$&#123;file_base_name&#125;&apos;&quot;], 6. &#125; 保存（保存到默认位置，命令为gcc.sublime-build）。然后单击菜单栏 Tools-&gt;Build System，选择gcc。 编写好C&#x2F;C++文件后，再次使用command+B命令，命令行会被调出，用以输入内容。 三 配置文件的编辑在sublime的preferences下有两个选项：一个是Setting-Defalut，一个是Setting-User。Setting-Default是系统默认的配置文件，我们无法进行修改。我们的所有配置都是在Setting-User文件下进行的，例如说配置sublime的Tab缩进问题。在Setting-User加入如下代码： 12&quot;tab_size&quot;: 4, &quot;translate_tabs_to_spaces&quot;: true 即设置一个Tab等于4个空格。 大功告成！效果图如下：","tags":[{"name":"sublime","slug":"sublime","permalink":"http://aeyoo.net/tags/sublime/"}]},{"title":"Hive基础教程","date":"2018-11-06T13:59:03.000Z","path":"2018/11/06/Hive基础教程/","text":"本来想对官方文档《Hive Tutorial》进行翻译整理的，但是发现网上已经有人做了这方面工作，就不重复造轮子了。将作者 strongyoung88 的博文转载了过来备查，建议查看原文《Hive 教程（官方Tutorial）》。 目录 概念 什么是 Hive Hive 的局限 快速入门 数据单元 类型系统 内置运算符和函数 语言能力 使用和示例 创建、展示、修改、删除 hive 表 加载数据 查询和插入数据 一 概念1.1 Hive是什么Hive是一个基于Apache Hadoop的数据仓库。对于数据存储与处理，Hadoop提供了主要的扩展和容错能力。 Hive设计的初衷是：对于大量的数据，使得数据汇总，查询和分析更加简单。它提供了SQL，允许用户更加简单地进行查询，汇总和数据分析。同时，Hive的SQL给予了用户多种方式来集成自己的功能，然后做定制化的查询，例如用户自定义函数（User Defined Functions，UDFs). 1.2 Hive不适合做什么Hive不是为在线事务处理而设计。它最适合用于传统的数据仓库任务。 1.3 Getting Started对于Hive, HiveServer2 和Beeline的设置详情，请参考 指南 。 对于学习Hive，这些 书单 可能对你有所用处。 以下部分提供了一个关于Hive系统功能的教程。先描述数据类型，表和分区的概念，然后使用例子来描述Hive的功能。 1.4 数据单元根据颗粒度的顺序，Hive数据被组织成： 数据库：命名空间功能，为了避免表，视图，分区，列等等的命名冲突。数据库也可以用于加强用户或用户组的安全。 表：相同数据库的同类数据单元。例如表page_views，表的每行包含以下列： timestamp －这是一个INT类型，是当页面被访问时的UNIX时间戳。 userid －这是一个BIGINT类型，用于惟一识别访问页面的用户。 page_url －这是一个STRING类型，用于存储页面地址。 referer_url －这是一个STRING类型，用于存储用户是从哪个页面跳转到本页面的地址。 IP －这是一个STRING类型，用于存储页面请求的IP地址。 分区：每个表可以有一个或多个用于决定数据如何存储的分区键。分区（除存储单元之外）也允许用户有效地识别满足指定条件的行；例如，STRING类型的date_partition和STRING的country_partition。这些分区键的每个唯一的值定义了表的一个分区。例如，所有的“2009－12－23”日期的“US”数据是表page_views的一个分区。（注意区分，分区键与分区，如果分区键有两个，每个分区键有三个不同的值，则共有6个分区）。因此，如果你只在日期为“2009－12－23”的“US”数据上执行分析，你将只会在表的相关数据上执行查询，这将有效地加速分析。然而要注意，那仅仅是因为有个分区叫2009-12-23，并不意味着它包含了所有数据，或者说，这些数据仅仅是那个日期的数据。用户需要保证分区名字与数据内容之间的关系。分区列是虚拟列，它们不是数据本身的一部分，而是源于数据加载。 桶（Buckets or Clusters）：每个分区的数据，基于表的一些列的哈希函数值，又被分割成桶。例如，表page_views可能通过userid分成桶，userid是表page_view的一个列，不同于分区列。这些桶可以被用于有效地抽样数据。 1.5 类型系统Hive支持原始类型和复要类型，如下所述，查看 Hive Data Types。 1.5.1 原始类型类型与表的列相关。支持以下原始类型： Integers（整型） TINYINT －1位的整型 SMALLINT －2位的整型 INT －4位的整型 BIGINT －8位的整型 布尔类型 BOOLEAN －TRUE&#x2F;FALSE 浮点数 FLOAT －单精度 DOUBLE －双精度 定点数 DECIMAL －用户可以指定范围和小数点位数 字符串 STRING －在特定的字符集中的一个字符串序列 VARCHAR －在特定的字符集中的一个有最大长度限制的字符串序列 CHAR －在特定的字符集中的一个指定长度的字符串序列 日期和时间 TIMESTAMP －一个特定的时间点，精确到纳秒。 DATE －一个日期 二进制 BINARY －一个二进制位序列 1.5.2 复杂类型复杂类型可以由原始类型和其他组合类型构建： 结构体类型（Stuct): 使用点（.)来访问类型内部的元素。例如，有一列c，它是一个结构体类型{a INT; b INT}，字段a可以使用表达式c.a来访问。 Map(key-value键值对)：使用[‘元素名’]来访问元素。例如，有一个MapM，包含’group’-&gt;gid的映射，则gid的值可以使用M[‘group’]来访问。 数组：数组中的元素是相同的类型。可以使用[n]来访问数组元素，n是数组下标，以0开始。例如有一个数组A，有元素[‘a’,’b’,’c’]，则A[1]返回’b’。 1.6 内置运算符和函数Hive所有关键词的大小写都不敏感，包括Hive运算符和函数的名字。 1.6.1 内置运算符关系运算 数学运算 逻辑运算 复杂类型的运算 1.6.2 内置函数Hive支持以下内置函数 Hive支持以下内置聚合函数 1.7 语言能力Hive’s SQL提供了基本的SQL操作。这些操作工作于表或分区上。这些操作是： 可以使用WHERE从表中筛选行 可以使用SELECT从表中查询指定的列 两个表之间可以join 可以在多个group by的列上使用聚合 可以存储查询结构到另一个表 可以下载表的内容到本地目录 可以存储查询结果到hadoop的分布式文件系统目录上 可以管理表和分区（创建，删除和修改） 可以使用自定义的脚本，来定制map&#x2F;reduce作业 二 使用和实例以下的例子有一些不是最新的，更多最新的信息，可以参考 LanguageManual。 以下的例子强调了Hive系统的显著特征。详细的查询测试用例和相应的查询结果可以在 Hive Query Test Cases 上找到。 创建，显示，修改，和删除表 加载数据 查询和插入数据 2.1 创建，显示，修改，和删除表2.1.1 创建表以下例子创建表page_view： 123456CREATE TABLE page_view(viewTime INT, userid BIGINT, page_url STRING, referrer_url STRING, ip STRING COMMENT 'IP Address of the User')COMMENT 'This is the page view table'PARTITIONED BY(dt STRING, country STRING)STORED AS SEQUENCEFILE; 在这个例子中，表的列被指定相应的类型。备注（Comments)可以基于列级别，也可以是表级别。另外，使用PARTITIONED关键词定义的分区列与数据列是不同的，分区列实际上不存储数据。当使用这种方式创建表的时候，我们假设数据文件的内容，字段之间以ASCII 001（ctrl-A)分隔，行之间以换行分隔。 如果数据不是以上述格式组织的，我们也可以指定分隔符，如下： 12345678CREATE TABLE page_view(viewTime INT, userid BIGINT, page_url STRING, referrer_url STRING, ip STRING COMMENT 'IP Address of the User')COMMENT 'This is the page view table'PARTITIONED BY(dt STRING, country STRING)ROW FORMAT DELIMITED FIELDS TERMINATED BY '1'STORED AS SEQUENCEFILE; 目前，行分隔符不能改变，因为它不是由Hive决定，而是由Hadoop分隔符。 对表的指定列进行分桶，是一个好的方法，它可以有效地对数据集进行抽样查询。如果没有分桶，则会进行随机抽样，由于在查询的时候，需要扫描所有数据，因此，效率不高。以下例子描述了，在表page_view的userid列上进行分桶的例子： 1234567891011CREATE TABLE page_view(viewTime INT, userid BIGINT, page_url STRING, referrer_url STRING, ip STRING COMMENT 'IP Address of the User')COMMENT 'This is the page view table'PARTITIONED BY(dt STRING, country STRING)CLUSTERED BY(userid) SORTED BY(viewTime) INTO 32 BUCKETSROW FORMAT DELIMITED FIELDS TERMINATED BY '1' COLLECTION ITEMS TERMINATED BY '2' MAP KEYS TERMINATED BY '3'STORED AS SEQUENCEFILE; 以上例子，通过一个userid的哈希函数，表被分成32个桶。在每个桶中的数据，是以viewTime升序进行存储。这样组织数据允许用户有效地在这n个桶上进行抽样。合适的排序使得内部操作充分利用熟悉的数据结构来进行更加有效的查询。 123456789101112CREATE TABLE page_view(viewTime INT, userid BIGINT, page_url STRING, referrer_url STRING, friends ARRAY&lt;BIGINT&gt;, properties MAP&lt;STRING, STRING&gt;, ip STRING COMMENT 'IP Address of the User')COMMENT 'This is the page view table'PARTITIONED BY(dt STRING, country STRING)CLUSTERED BY(userid) SORTED BY(viewTime) INTO 32 BUCKETSROW FORMAT DELIMITED FIELDS TERMINATED BY '1' COLLECTION ITEMS TERMINATED BY '2' MAP KEYS TERMINATED BY '3'STORED AS SEQUENCEFILE; 在这个例子，CLUSTERED BY指定列进行分桶，以及创建多少个桶。行格式分隔符指定在hive表中，行如何存储。在这种分隔符情况下，指定了字段是如何结束，集合项（数组和map）如何结束，以及map的key是如何结束的。STORED AS SEQUENCEFILE表示这个数据是以二进制格式进行存储数据在hdfs上。对于以上例子的ROW FORMAT的值和STORED AS表示系统默认值。 表名和列名不区分大小写。 2.1.2 浏览表和分区1SHOW TABLES; 列出数据库里的所有的表，也可以这么浏览： 1SHOW TABLES 'page.*'; 这样将会列出以page开头的表，模式遵循Java正则表达式语法。 1SHOW PARTITIONS page_view; 列出表的分区。如果表没有分区，则抛出错误。 1DESCRIBE page_view; 列出表的列和列的类型。 1DESCRIBE EXTENDED page_view; 列出表的列和表的其他属性。这会打印很多信息，且输出的风格不是很友好，通常用于调试。 1DESCRIBE EXTENDED page_view PARTITION (ds='2016-08-08'); 列出列和分区的所有属性。这也会打印出许多信息，通常也是用于调试。 2.1.3 修改表对已有的表进行重命名。如果表的新名字存在，则报错： 1ALTER TABLE old_table_name RENAME TO new_table_name; 对已有表的列名进行重命名。要确保使用相同的列类型，且要包含对每个已存在列的一个入口(也就是说，就算不修改其他列的列名，也要把此列另上，否则，此列会丢失）。 1ALTER TABLE old_table_name REPLACE COLUMNS (col1 TYPE, ...); 对已有表增加列： 1ALTER TABLE tab1 ADD COLUMNS (c1 INT COMMENT 'a new int column', c2 STRING DEFAULT 'def val'); 注意：模式的改变（例如增加列），保留了表的老分区，以免它是一个分区表。所有对这些列或老分区的查询都会隐式地返回一个null值或这些列指定的默认值。 2.1.4 删除表和分区删除表是相当，表的删除会删除已经建立在表上的任意索引。相关命令是： 1DROP TABLE pv_users; 要删除分区。修改表删除分区： 1ALTER TABLE pv_users DROP PARTITION (ds='2016-08-08') 注意：此表或分区的任意数据都将被删除，而且可能无法恢复。 2.2 加载数据要加载数据到Hive表有许多种方式。用户可以创建一个“外部表”来指向一个特定的HDFS路径。用这种方法，用户可以使用HDFSput或copy命令，复制一个文件到指定的位置，并且附上相应的行格式信息创建一个表指定这个位置。一旦完成，用户就可以转换数据和插入他们到任意其他的Hive表中。例如，如果文件&#x2F;tmp&#x2F;pv_2016-06-08.txt包含逗号分隔的页面访问记录。这需要以合适的分区加载到表page_view，以下命令可以完成这个目标： 123456789101112131415CREATE EXTERNAL TABLE page_view_stg(viewTime INT, userid BIGINT, page_url STRING, referrer_url STRING, ip STRING COMMENT 'IP Address of the User', country STRING COMMENT 'country of origination')COMMENT 'This is the staging page view table'ROW FORMAT DELIMITED FIELDS TERMINATED BY '44' LINES TERMINATED BY '12'STORED AS TEXTFILELOCATION '/user/data/staging/page_view';hadoop dfs -put /tmp/pv_2016-06-08.txt /user/data/staging/page_viewFROM page_view_stg pvsINSERT OVERWRITE TABLE page_view PARTITION(dt='2016-06-08', country='US')SELECT pvs.viewTime, pvs.userid, pvs.page_url, pvs.referrer_url, null, null, pvs.ipWHERE pvs.country = 'US'; 其中，‘44’是逗号的ASCII码，‘12’是换页符（NP from feed,new page）。null是作为目标表中的数组和map类型插入，如果指定了合适的行格式，这些值也可以来自外部表。 如果在HDFS上有一些历史数据，用户想增加一些元数据，以便于可以使用Hive来查询和操纵这些数据，这个方法是很有用的。 另外，系统也支持直接从本地文件系统上加载数据到Hive表。表的格式与输入文件的格式需要相同。如果文件&#x2F;tmp&#x2F;pv_2016-06-08包含了US数据，然后我们不需要像前面例子那样的任何筛选，这种情况的加载可以使用以下语法完成： 1LOAD DATA LOCAL INPATH /tmp/pv_2016-06-08_us.txt INTO TABLE page_view PARTITION(date='2016-06-08', country='US') 路径参数可以是一个目录（这种情况下，目录下的所有文件将被加载），一个文件，或一个通配符（这种情况下，所有匹配的文件会上传）。如果参数是目录，它不能包含子目录。同样，通配符只匹配文件名。 在输入文件&#x2F;tmp&#x2F;pv_2016-06-08.txt非常大的情况下，用户可以采用并行加载数据的方式（使用Hive的外部工具）。只要文件在HDFS上－以下语法可以用于加载数据到Hive表： 1LOAD DATA INPATH '/user/data/pv_2016-06-08_us.txt' INTO TABLE page_view PARTITION(date='2016-06-08', country='US') 对于这个例子，我们假设数组和map在文件中的值为null。 更多关于加载数据到表的信息，请参考 Hive Data Manipulation Language,创建外部表的另外一个例子请参考 External Tables。 2.3 查询和插入数据 Simple Query Partition Based Query Joins Aggregations Multi Table&#x2F;File Inserts Dynamic-Partition Insert Inserting into Local Files Sampling Union All Array Operations Map (Associative Arrays) Operations Custom Map&#x2F;Reduce Scripts Co-Groups Hive查询操作在文档Select,插入操作在文档insert data into Hive Tables from queries和writing data into the filesystem from queries。 2.3.1 简单的查询对于所有的活跃用户，可以使用以下查询格式： 1234INSERT OVERWRITE TABLE user_activeSELECT user.*FROM userWHERE user.active = 1; 注意：不像SQL，我们老是插入结果到表中。随后我们会描述，用户如何检查这些结果，甚至把结果导出到一个本地文件。你也可以在Beeline或HiveCLI执行以下查询： 123SELECT user.*FROM userWHERE user.active = 1; 这在内部将会重写到一些临时文件，并在Hive客户端显示。 2.3.2 基于查询的分区在一个查询中，要使用什么分区，是由系统根据where在分区列上条件自动的决定。例如，为了获取所有2008年3月份，从域名xyz.com过来的page_views，可以这么写查询： 12345INSERT OVERWRITE TABLE xyz_com_page_viewsSELECT page_views.*FROM page_viewsWHERE page_views.date &gt;= '2008-03-01' AND page_views.date &lt;= '2008-03-31' AND page_views.referrer_url like '%xyz.com'; 注意：在这里使用的page_views.date是用PARTITIONED BY(date DATATIME, country STRING)定义的.如果你的分区命名不一样，那么不要指望.date能够做你想做的事情，即无法获得分区的优势。 2.3.3 连接表的连接可以使用以下命令： 1234INSERT OVERWRITE TABLE pv_usersSELECT pv.*, u.gender, u.ageFROM user u JOIN page_view pv ON (pv.userid = u.id)WHERE pv.date = '2008-03-03'; 想实现外连接，用户可以使用LEFT OUTER,RIGHT OUTER或FULL OUTER关键词来指示不同的外连接（左保留，右保留或两端都保留）。例如，想对上面的查询做一个FULL OUTER，相应的语法可以像下面这样： 1234INSERT OVERWRITE TABLE pv_usersSELECT pv.*, u.gender, u.ageFROM user u FULL OUTER JOIN page_view pv ON (pv.userid = u.id)WHERE pv.date = '2008-03-03'; 为了检查key在另外一个表中是否存在，用户可以使用LEFT SEMI JOIN,正如以下例子一样： 1234INSERT OVERWRITE TABLE pv_usersSELECT u.*FROM user u LEFT SEMI JOIN page_view pv ON (pv.userid = u.id)WHERE pv.date = '2008-03-03'; 为了连接多个表，可以使用以下语法： 1234INSERT OVERWRITE TABLE pv_friendsSELECT pv.*, u.gender, u.age, f.friendsFROM page_view pv JOIN user u ON (pv.userid = u.id) JOIN friend_list f ON (u.id = f.uid)WHERE pv.date = '2008-03-03'; 注意：Hive只支持equi-joins。所以，把最大的表放在join的最右边，可以得到最好的性能。 2.3.4 聚合统计用户每个性别的人数，可以使用以下查询： 1234INSERT OVERWRITE TABLE pv_gender_sumSELECT pv_users.gender, count (DISTINCT pv_users.userid)FROM pv_usersGROUP BY pv_users.gender; 可以同时做多个聚合，然而，两个聚合函数不能同时用DISTINCT作用于不同的列，以下情况是可以的（DISTINCT作用于相同列）： 1234INSERT OVERWRITE TABLE pv_gender_aggSELECT pv_users.gender, count(DISTINCT pv_users.userid), count(*), sum(DISTINCT pv_users.userid)FROM pv_usersGROUP BY pv_users.gender; 然而，以下情况（DISTINCT作用于不同的列）是不允许的： 1234INSERT OVERWRITE TABLE pv_gender_aggSELECT pv_users.gender, count(DISTINCT pv_users.userid), count(DISTINCT pv_users.ip)FROM pv_usersGROUP BY pv_users.gender; 2.3.5 多表&#x2F;文件插入聚合或简单查询的输出可以插入到多个表中，或者甚至是HDFS文件（能够使用HDFS工具进行操纵）。例如，如果沿用前面的“性别分类”，例子如下： 12345678FROM pv_usersINSERT OVERWRITE TABLE pv_gender_sum SELECT pv_users.gender, count_distinct(pv_users.userid) GROUP BY pv_users.genderINSERT OVERWRITE DIRECTORY '/user/data/tmp/pv_age_sum' SELECT pv_users.age, count_distinct(pv_users.userid) GROUP BY pv_users.age; 第一个插入语句将结果插入到Hive表中，而第二个插入语句是将结果写到HDFS文件。 2.3.6 动态分区插入在前面的例子中，我们知道，在插入语句中，只能有一个分区。如果我们想加载到多个分区，我们必须像以下描述来使用多条插入语句： 1234567FROM page_view_stg pvsINSERT OVERWRITE TABLE page_view PARTITION(dt='2008-06-08', country='US') SELECT pvs.viewTime, pvs.userid, pvs.page_url, pvs.referrer_url, null, null, pvs.ip WHERE pvs.country = 'US'INSERT OVERWRITE TABLE page_view PARTITION(dt='2008-06-08', country='CA') SELECT pvs.viewTime, pvs.userid, pvs.page_url, pvs.referrer_url, null, null, pvs.ip WHERE pvs.country = 'CA'INSERT OVERWRITE TABLE page_view PARTITION(dt='2008-06-08', country='UK') SELECT pvs.viewTime, pvs.userid, pvs.page_url, pvs.referrer_url, null, null, pvs.ip WHERE pvs.country = 'UK'; 为了加载数据到全部的country分区到指定的日期。我们必须在输入数据中为每个country增加一条插入语句。这是非常不方便的，因为我们需要提前创建且知道已存在哪些country分区列表。如果哪天这些country列表变了，我们必须修改我们的插入语句，也应该创建相应的分区。这也是非常低效的，因为每个插入语句可能都是转换成一个MapReduce作业。 动态分区插入（Dynamic-partition insert)(或multi-partition插入)就是为了解决以上问题而设计的，它通过动态地决定在扫描数据的时候，哪些分区应该创建和填充。这个新的特征是在版本0.6.0加入的。在动态分区插入中，输入列被评估，这行应该插入到哪个分区。如果分区没有创建，它将自动创建这个分区。使用这个特征，我们仅仅需要插入语桀犬吠尧来创建和填充所有需要的分区。另外，因为只有一个插入语句，相应的也只有一个MapReduce作业。相比多个插入语句的情况，这将显著地提高性能且降低Hadoop集群负载。 以下是使用一个插入语句，加载数据到所有country分区的例子： 123FROM page_view_stg pvsINSERT OVERWRITE TABLE page_view PARTITION(dt='2008-06-08', country) SELECT pvs.viewTime, pvs.userid, pvs.page_url, pvs.referrer_url, null, null, pvs.ip, pvs.country 与多条插入语句相比，动态分区插入有一些语法上的不同： country出现在PARTITION后面，但是没有具体的值。这种情况，country就是一个动态分区列。另一方面，dt有一个值，这意味着它是一个静态的分区列。如果一个列是动态分区列，它的值将会使用输入列的值。目前，我们仅仅允许在分区条件的最后一列放置动态分区列，因为分区列的顺序，指示了它的层级次序（意味着dt是根分区，country是子分区）。我们不能这样指定分区（dt,country&#x3D;’US’)，因为这表示，我们需要更新所有的日期的分区且它的country子分区是‘US’。 一个额外的pvs.country列被加入在查询语句中。这对动态分区列来说，相当于输入列。注意：对于静态分区列，我们不需要添加一个输入列，因为在PARTITION语句中，它的值已经知道。注意：动态分区列的值（不是名字）查出来是有序的，且是放在select语句的最后。 动态分区插入的语义： 对于动态分区列，当已经此分区时，（例如，country&#x3D;’CA’已存在dt根分区下面）如果动态分区插入与输入数据中相同的值（’CA’），它将会被重写（overwritten)。 2.3.7 插入到本地文件在某些场合，我们需要把输出写到一个本地文件，以便于能用excel表格打开。这可以使用以下命令： 123INSERT OVERWRITE LOCAL DIRECTORY &apos;/tmp/pv_gender_sum&apos;SELECT pv_gender_sum.*FROM pv_gender_sum; 2.3.8 抽样抽样语句允许用户对数据抽样查询，而不是全表查询。当前，抽样是对那些在CREATE TABLE语句的CLUSTERED BY修饰的列上。以下例子，我们从表pv_gender_sum表中的32个桶中，选择第3个桶。 123INSERT OVERWRITE TABLE pv_gender_sum_sampleSELECT pv_gender_sum.*FROM pv_gender_sum TABLESAMPLE(BUCKET 3 OUT OF 32); 通常，TABLESAMPLE的语法像这样： 1TABLESAMPLE(BUCKET x OUT OF y) 这个y必须是桶的数量的因子或倍数，桶的数量是在创建表的时候指定的。抽样所选的桶由桶大小，y和x共同决定。如果y和桶大小相等，则抽样所选的桶是x对y的求模结果。 1TABLESAMPLE(BUCKET 3 OUT OF 16) 这将抽样第3个和第19个桶。桶的编号从0开始。 tablesample语句的另一方面： 1TABLESAMPLE(BUCKET 3 OUT OF 64 ON userid) 这将抽取第3个桶的一半。 2.3.9 union all这个语言也支持union all，如果假设我们有两个不同的表，分别用来记录用户发布的视频和用户发布的评论，以下例子是一个union all 的结果与用户表再连接的查询： 12345678910111213INSERT OVERWRITE TABLE actions_usersSELECT u.id, actions.dateFROM ( SELECT av.uid AS uid FROM action_video av WHERE av.date = '2008-06-03' UNION ALL SELECT ac.uid AS uid FROM action_comment ac WHERE ac.date = '2008-06-03' ) actions JOIN users u ON(u.id = actions.uid); 2.3.10 数组操作表的数组列可以这样： 1CREATE TABLE array_table (int_array_column ARRAY&lt;INT&gt;); 假设pv.friends 是类型ARRAY（也就是一个整型数组），用户可以通过索引号获取数组中特定的元素，如下： 12SELECT pv.friends[2]FROM page_views pv; 这个查询得到的是pv.friends里的第三个元素。 用户也可以使用函数size来获取数组的长度，如下： 12SELECT pv.userid, size(pv.friends)FROM page_view pv; 2.3.11 Map（关联数组）操作Map提供了类似于关联数组的集合。这样的结构不仅可以由程序创建。我们也将很快可以继承这个。假设pv.properties是类型map&lt;String,String&gt;，如下： 123INSERT OVERWRITE page_views_mapSELECT pv.userid, pv.properties['page type']FROM page_views pv; 这将查询表page_views的‘page_type‘属性。 与数组相似，也可以使用函数size来获取map的大小： 12SELECT size(pv.properties)FROM page_view pv; 2.3.12 定制Map&#x2F;Reduce脚本通过使用Hive语言原生支持的特征，用户可以插入他们自己定制的mapper和reducer在数据流中。例如，要运行一个定制的mapper脚本script-map_script和reducer脚本script-reduce_script)，用户可以执行以下命令，使用TRANSFORM来嵌入mapper和reducer脚本。 注意：在执行用户脚本之前，表的列会转换成字符串，且由TAB分隔，用户脚本的标准输出将会被作为以TAB分隔的字符串列。用户脚本可以输出调试信息到标准错误输出，这个信息也将显示hadoop的详细任务页面上。 1234567891011FROM ( FROM pv_users MAP pv_users.userid, pv_users.date USING 'map_script' AS dt, uid CLUSTER BY dt) map_output INSERT OVERWRITE TABLE pv_users_reduced REDUCE map_output.dt, map_output.uid USING 'reduce_script' AS date, count; map脚本样本（weekday_mapper.py) 12345678import sysimport datetimefor line in sys.stdin: line = line.strip() userid, unixtime = line.split('\\t') weekday = datetime.datetime.fromtimestamp(float(unixtime)).isoweekday() print ','.join([userid, str(weekday)]) 当然，对于那些常见的select转换，MAP和REDUCE都是“语法糖”。内部查询也可以写成这样： 1SELECT TRANSFORM(pv_users.userid, pv_users.date) USING 'map_script' AS dt, uid CLUSTER BY dt FROM pv_users; 2.3.13 Co-Groups在使用map&#x2F;reduce的群体中，cogroup是相当常见的操作，它是将来自多个表的数据发送到一个定制的reducer，使得行由表的指定列的值进行分组。在Hive的查询语言中，可以使用以下方式，通过使用union all和cluster by来实现此功能。假设我们想对来自表actions_video和action_comment的行对uid列进行分组，且需要发送他们到reducer_script定制的reducer，可以使用以下语法： 123456789101112131415FROM ( FROM ( FROM action_video av SELECT av.uid AS uid, av.id AS id, av.date AS date UNION ALL FROM action_comment ac SELECT ac.uid AS uid, ac.id AS id, ac.date AS date ) union_actions SELECT union_actions.uid, union_actions.id, union_actions.date CLUSTER BY union_actions.uid) map INSERT OVERWRITE TABLE actions_reduced SELECT TRANSFORM(map.uid, map.id, map.date) USING 'reduce_script' AS (uid, id, reduced_val);","tags":[{"name":"hive","slug":"hive","permalink":"http://aeyoo.net/tags/hive/"}]},{"title":"spark程序设计优化","date":"2018-11-01T00:29:07.000Z","path":"2018/11/01/spark程序优化/","text":"本文介绍一下spark使用过程中的一些优化方法。内容完全转载自美团的技术文章《Spark性能优化指南——基础篇》，酌情删减了一部分内容。建议查看原文，感觉原文的界面好看一些。 Spark的性能调优实际上是由很多部分组成的，不是调节几个参数就可以立竿见影提升作业性能的。需要根据不同的业务场景以及数据情况，对Spark作业进行综合性的分析，然后进行多个方面的调节和优化，才能获得最佳性能。 spark性能优化主要分为四个部分： 开发调优 资源调优 数据倾斜调优 shuffle调优 开发调优和资源调优是所有Spark作业都需要注意和遵循的一些基本原则，是高性能Spark作业的基础；数据倾斜调优，主要讲解了一套完整的用来解决Spark作业数据倾斜的解决方案；shuffle调优，面向的是对Spark的原理有较深层次掌握和研究的同学，主要讲解了如何对Spark作业的shuffle运行过程以及细节进行调优。 以下主要讲解开发调优以及资源调优。 开发调优调优概述Spark性能优化的第一步，就是要在开发Spark作业的过程中注意和应用一些性能优化的基本原则。开发调优，就是要让大家了解以下一些Spark基本开发原则，包括：RDD lineage设计、算子的合理使用、特殊操作的优化等。 原则一：避免创建重复的RDD通常来说，我们在开发一个Spark作业时，首先是基于某个数据源（比如Hive表或HDFS文件）创建一个初始的RDD；接着对这个RDD执行某个算子操作，然后得到下一个RDD；以此类推，循环往复，直到计算出最终我们需要的结果。在这个过程中，多个RDD会通过不同的算子操作（比如map、reduce等）串起来，这个“RDD串”，就是RDD lineage，也就是“RDD的血缘关系链”。 我们在开发过程中要注意：对于同一份数据，只应该创建一个RDD，不能创建多个RDD来代表同一份数据。 一些Spark初学者在刚开始开发Spark作业时，或者是有经验的工程师在开发RDD lineage极其冗长的Spark作业时，可能会忘了自己之前对于某一份数据已经创建过一个RDD了，从而导致对于同一份数据，创建了多个RDD。这就意味着，我们的Spark作业会进行多次重复计算来创建多个代表相同数据的RDD，进而增加了作业的性能开销。 1234567891011121314151617// 需要对名为“hello.txt”的HDFS文件进行一次map操作，再进行一次reduce操作。也就是说，需要对一份数据执行两次算子操作。// 错误的做法：对于同一份数据执行多次算子操作时，创建多个RDD。// 这里执行了两次textFile方法，针对同一个HDFS文件，创建了两个RDD出来，然后分别对每个RDD都执行了一个算子操作。// 这种情况下，Spark需要从HDFS上两次加载hello.txt文件的内容，并创建两个单独的RDD；第二次加载HDFS文件以及创建RDD的性能开销，很明显是白白浪费掉的。val rdd1 = sc.textFile(\"hdfs://192.168.0.1:9000/hello.txt\")rdd1.map(...)val rdd2 = sc.textFile(\"hdfs://192.168.0.1:9000/hello.txt\")rdd2.reduce(...)// 正确的用法：对于一份数据执行多次算子操作时，只使用一个RDD。// 这种写法很明显比上一种写法要好多了，因为我们对于同一份数据只创建了一个RDD，然后对这一个RDD执行了多次算子操作。// 但是要注意到这里为止优化还没有结束，由于rdd1被执行了两次算子操作，第二次执行reduce操作的时候，还会再次从源头处重新计算一次rdd1的数据，因此还是会有重复计算的性能开销。// 要彻底解决这个问题，必须结合“原则三：对多次使用的RDD进行持久化”，才能保证一个RDD被多次使用时只被计算一次。val rdd1 = sc.textFile(\"hdfs://192.168.0.1:9000/hello.txt\")rdd1.map(...)rdd1.reduce(...) 原则二：尽可能复用同一个RDD除了要避免在开发过程中对一份完全相同的数据创建多个RDD之外，在对不同的数据执行算子操作时还要尽可能地复用一个RDD。比如说，有一个RDD的数据格式是key-value类型的，另一个是单value类型的，这两个RDD的value数据是完全一样的。那么此时我们可以只使用key-value类型的那个RDD，因为其中已经包含了另一个的数据。对于类似这种多个RDD的数据有重叠或者包含的情况，我们应该尽量复用一个RDD，这样可以尽可能地减少RDD的数量，从而尽可能减少算子执行的次数。 1234567891011121314151617181920212223242526// 错误的做法。// 有一个&lt;Long, String&gt;格式的RDD，即rdd1。// 接着由于业务需要，对rdd1执行了一个map操作，创建了一个rdd2，而rdd2中的数据仅仅是rdd1中的value值而已，也就是说，rdd2是rdd1的子集。JavaPairRDD&lt;Long, String&gt; rdd1 = ...JavaRDD&lt;String&gt; rdd2 = rdd1.map(...)// 分别对rdd1和rdd2执行了不同的算子操作。rdd1.reduceByKey(...)rdd2.map(...)// 正确的做法。// 上面这个case中，其实rdd1和rdd2的区别无非就是数据格式不同而已，rdd2的数据完全就是rdd1的子集而已，却创建了两个rdd，并对两个rdd都执行了一次算子操作。// 此时会因为对rdd1执行map算子来创建rdd2，而多执行一次算子操作，进而增加性能开销。// 其实在这种情况下完全可以复用同一个RDD。// 我们可以使用rdd1，既做reduceByKey操作，也做map操作。// 在进行第二个map操作时，只使用每个数据的tuple._2，也就是rdd1中的value值，即可。JavaPairRDD&lt;Long, String&gt; rdd1 = ...rdd1.reduceByKey(...)rdd1.map(tuple._2...)// 第二种方式相较于第一种方式而言，很明显减少了一次rdd2的计算开销。// 但是到这里为止，优化还没有结束，对rdd1我们还是执行了两次算子操作，rdd1实际上还是会被计算两次。// 因此还需要配合“原则三：对多次使用的RDD进行持久化”进行使用，才能保证一个RDD被多次使用时只被计算一次。 原则三：对多次使用的RDD进行持久化当你在Spark代码中多次对一个RDD做了算子操作后，恭喜，你已经实现Spark作业第一步的优化了，也就是尽可能复用RDD。此时就该在这个基础之上，进行第二步优化了，也就是要保证对一个RDD执行多次算子操作时，这个RDD本身仅仅被计算一次。 Spark中对于一个RDD执行多次算子的默认原理是这样的：每次你对一个RDD执行一个算子操作时，都会重新从源头处计算一遍，计算出那个RDD来，然后再对这个RDD执行你的算子操作。这种方式的性能是很差的。 因此对于这种情况，我们的建议是：对多次使用的RDD进行持久化。此时Spark就会根据你的持久化策略，将RDD中的数据保存到内存或者磁盘中。以后每次对这个RDD进行算子操作时，都会直接从内存或磁盘中提取持久化的RDD数据，然后执行算子，而不会从源头处重新计算一遍这个RDD，再执行算子操作。 123456789101112131415161718对多次使用的RDD进行持久化的代码示例// 如果要对一个RDD进行持久化，只要对这个RDD调用cache()和persist()即可。// 正确的做法。// cache()方法表示：使用非序列化的方式将RDD中的数据全部尝试持久化到内存中。// 此时再对rdd1执行两次算子操作时，只有在第一次执行map算子时，才会将这个rdd1从源头处计算一次。// 第二次执行reduce算子时，就会直接从内存中提取数据进行计算，不会重复计算一个rdd。val rdd1 = sc.textFile(\"hdfs://192.168.0.1:9000/hello.txt\").cache()rdd1.map(...)rdd1.reduce(...)// persist()方法表示：手动选择持久化级别，并使用指定的方式进行持久化。// 比如说，StorageLevel.MEMORY_AND_DISK_SER表示，内存充足时优先持久化到内存中，内存不充足时持久化到磁盘文件中。// 而且其中的_SER后缀表示，使用序列化的方式来保存RDD数据，此时RDD中的每个partition都会序列化成一个大的字节数组，然后再持久化到内存或磁盘中。// 序列化的方式可以减少持久化的数据对内存/磁盘的占用量，进而避免内存被持久化数据占用过多，从而发生频繁GC。val rdd1 = sc.textFile(\"hdfs://192.168.0.1:9000/hello.txt\").persist(StorageLevel.MEMORY_AND_DISK_SER)rdd1.map(...)rdd1.reduce(...) 对于persist()方法而言，我们可以根据不同的业务场景选择不同的持久化级别。 Spark的持久化级别 如何选择一种最合适的持久化策略 默认情况下，性能最高的当然是MEMORY_ONLY，但前提是你的内存必须足够足够大，可以绰绰有余地存放下整个RDD的所有数据。因为不进行序列化与反序列化操作，就避免了这部分的性能开销；对这个RDD的后续算子操作，都是基于纯内存中的数据的操作，不需要从磁盘文件中读取数据，性能也很高；而且不需要复制一份数据副本，并远程传送到其他节点上。但是这里必须要注意的是，在实际的生产环境中，恐怕能够直接用这种策略的场景还是有限的，如果RDD中数据比较多时（比如几十亿），直接用这种持久化级别，会导致JVM的OOM内存溢出异常。 如果使用MEMORY_ONLY级别时发生了内存溢出，那么建议尝试使用MEMORY_ONLY_SER级别。该级别会将RDD数据序列化后再保存在内存中，此时每个partition仅仅是一个字节数组而已，大大减少了对象数量，并降低了内存占用。这种级别比MEMORY_ONLY多出来的性能开销，主要就是序列化与反序列化的开销。但是后续算子可以基于纯内存进行操作，因此性能总体还是比较高的。此外，可能发生的问题同上，如果RDD中的数据量过多的话，还是可能会导致OOM内存溢出的异常。 如果纯内存的级别都无法使用，那么建议使用MEMORY_AND_DISK_SER策略，而不是MEMORY_AND_DISK策略。因为既然到了这一步，就说明RDD的数据量很大，内存无法完全放下。序列化后的数据比较少，可以节省内存和磁盘的空间开销。同时该策略会优先尽量尝试将数据缓存在内存中，内存缓存不下才会写入磁盘。 通常不建议使用DISK_ONLY和后缀为_2的级别：因为完全基于磁盘文件进行数据的读写，会导致性能急剧降低，有时还不如重新计算一次所有RDD。后缀为_2的级别，必须将所有数据都复制一份副本，并发送到其他节点上，数据复制以及网络传输会导致较大的性能开销，除非是要求作业的高可用性，否则不建议使用。 原则四：尽量避免使用shuffle类算子如果有可能的话，要尽量避免使用shuffle类算子。因为Spark作业运行过程中，最消耗性能的地方就是shuffle过程。shuffle过程，简单来说，就是将分布在集群中多个节点上的同一个key，拉取到同一个节点上，进行聚合或join等操作。比如reduceByKey、join等算子，都会触发shuffle操作。 shuffle过程中，各个节点上的相同key都会先写入本地磁盘文件中，然后其他节点需要通过网络传输拉取各个节点上的磁盘文件中的相同key。而且相同key都拉取到同一个节点进行聚合操作时，还有可能会因为一个节点上处理的key过多，导致内存不够存放，进而溢写到磁盘文件中。因此在shuffle过程中，可能会发生大量的磁盘文件读写的IO操作，以及数据的网络传输操作。磁盘IO和网络数据传输也是shuffle性能较差的主要原因。 因此在我们的开发过程中，能避免则尽可能避免使用reduceByKey、join、distinct、repartition等会进行shuffle的算子，尽量使用map类的非shuffle算子。这样的话，没有shuffle操作或者仅有较少shuffle操作的Spark作业，可以大大减少性能开销。 1234567891011121314151617Broadcast与map进行join代码示例// 传统的join操作会导致shuffle操作。// 因为两个RDD中，相同的key都需要通过网络拉取到一个节点上，由一个task进行join操作。val rdd3 = rdd1.join(rdd2)// Broadcast+map的join操作，不会导致shuffle操作。// 使用Broadcast将一个数据量较小的RDD作为广播变量。val rdd2Data = rdd2.collect()val rdd2DataBroadcast = sc.broadcast(rdd2Data)// 在rdd1.map算子中，可以从rdd2DataBroadcast中，获取rdd2的所有数据。// 然后进行遍历，如果发现rdd2中某条数据的key与rdd1的当前数据的key是相同的，那么就判定可以进行join。// 此时就可以根据自己需要的方式，将rdd1当前数据与rdd2中可以连接的数据，拼接在一起（String或Tuple）。val rdd3 = rdd1.map(rdd2DataBroadcast...)// 注意，以上操作，建议仅仅在rdd2的数据量比较少（比如几百M，或者一两G）的情况下使用。// 因为每个Executor的内存中，都会驻留一份rdd2的全量数据。 原则五：使用map-side预聚合的shuffle操作如果因为业务需要，一定要使用shuffle操作，无法用map类的算子来替代，那么尽量使用可以map-side预聚合的算子。 所谓的map-side预聚合，说的是在每个节点本地对相同的key进行一次聚合操作，类似于MapReduce中的本地combiner。map-side预聚合之后，每个节点本地就只会有一条相同的key，因为多条相同的key都被聚合起来了。其他节点在拉取所有节点上的相同key时，就会大大减少需要拉取的数据数量，从而也就减少了磁盘IO以及网络传输开销。通常来说，在可能的情况下，建议使用reduceByKey或者aggregateByKey算子来替代掉groupByKey算子。因为reduceByKey和aggregateByKey算子都会使用用户自定义的函数对每个节点本地的相同key进行预聚合。而groupByKey算子是不会进行预聚合的，全量的数据会在集群的各个节点之间分发和传输，性能相对来说比较差。 比如如下两幅图，就是典型的例子，分别基于reduceByKey和groupByKey进行单词计数。其中第一张图是groupByKey的原理图，可以看到，没有进行任何本地聚合时，所有数据都会在集群节点之间传输；第二张图是reduceByKey的原理图，可以看到，每个节点本地的相同key数据，都进行了预聚合，然后才传输到其他节点上进行全局聚合。 groupByKey实现wordcount原理 reduceByKey实现wordcount原理 原则六：使用高性能的算子除了shuffle相关的算子有优化原则之外，其他的算子也都有着相应的优化原则。 使用reduceByKey&#x2F;aggregateByKey替代groupByKey详情见“原则五：使用map-side预聚合的shuffle操作”。 使用mapPartitions替代普通mapmapPartitions类的算子，一次函数调用会处理一个partition所有的数据，而不是一次函数调用处理一条，性能相对来说会高一些。但是有的时候，使用mapPartitions会出现OOM（内存溢出）的问题。因为单次函数调用就要处理掉一个partition所有的数据，如果内存不够，垃圾回收时是无法回收掉太多对象的，很可能出现OOM异常。所以使用这类操作时要慎重！ 使用foreachPartitions替代foreach原理类似于“使用mapPartitions替代map”，也是一次函数调用处理一个partition的所有数据，而不是一次函数调用处理一条数据。在实践中发现，foreachPartitions类的算子，对性能的提升还是很有帮助的。比如在foreach函数中，将RDD中所有数据写MySQL，那么如果是普通的foreach算子，就会一条数据一条数据地写，每次函数调用可能就会创建一个数据库连接，此时就势必会频繁地创建和销毁数据库连接，性能是非常低下；但是如果用foreachPartitions算子一次性处理一个partition的数据，那么对于每个partition，只要创建一个数据库连接即可，然后执行批量插入操作，此时性能是比较高的。实践中发现，对于1万条左右的数据量写MySQL，性能可以提升30%以上。 使用filter之后进行coalesce操作通常对一个RDD执行filter算子过滤掉RDD中较多数据后（比如30%以上的数据），建议使用coalesce算子，手动减少RDD的partition数量，将RDD中的数据压缩到更少的partition中去。因为filter之后，RDD的每个partition中都会有很多数据被过滤掉，此时如果照常进行后续的计算，其实每个task处理的partition中的数据量并不是很多，有一点资源浪费，而且此时处理的task越多，可能速度反而越慢。因此用coalesce减少partition数量，将RDD中的数据压缩到更少的partition之后，只要使用更少的task即可处理完所有的partition。在某些场景下，对于性能的提升会有一定的帮助。 使用repartitionAndSortWithinPartitions替代repartition与sort类操作repartitionAndSortWithinPartitions是Spark官网推荐的一个算子，官方建议，如果需要在repartition重分区之后，还要进行排序，建议直接使用repartitionAndSortWithinPartitions算子。因为该算子可以一边进行重分区的shuffle操作，一边进行排序。shuffle与sort两个操作同时进行，比先shuffle再sort来说，性能可能是要高的。 原则七：广播大变量有时在开发过程中，会遇到需要在算子函数中使用外部变量的场景（尤其是大变量，比如100M以上的大集合），那么此时就应该使用Spark的广播（Broadcast）功能来提升性能。 在算子函数中使用到外部变量时，默认情况下，Spark会将该变量复制多个副本，通过网络传输到task中，此时每个task都有一个变量副本。如果变量本身比较大的话（比如100M，甚至1G），那么大量的变量副本在网络中传输的性能开销，以及在各个节点的Executor中占用过多内存导致的频繁GC，都会极大地影响性能。 因此对于上述情况，如果使用的外部变量比较大，建议使用Spark的广播功能，对该变量进行广播。广播后的变量，会保证每个Executor的内存中，只驻留一份变量副本，而Executor中的task执行时共享该Executor中的那份变量副本。这样的话，可以大大减少变量副本的数量，从而减少网络传输的性能开销，并减少对Executor内存的占用开销，降低GC的频率。 12345678910111213广播大变量的代码示例// 以下代码在算子函数中，使用了外部的变量。// 此时没有做任何特殊操作，每个task都会有一份list1的副本。val list1 = ...rdd1.map(list1...)// 以下代码将list1封装成了Broadcast类型的广播变量。// 在算子函数中，使用广播变量时，首先会判断当前task所在Executor内存中，是否有变量副本。// 如果有则直接使用；如果没有则从Driver或者其他Executor节点上远程拉取一份放到本地Executor内存中。// 每个Executor内存中，就只会驻留一份广播变量副本。val list1 = ...val list1Broadcast = sc.broadcast(list1)rdd1.map(list1Broadcast...) 原则八：使用Kryo优化序列化性能在Spark中，主要有三个地方涉及到了序列化： 在算子函数中使用到外部变量时，该变量会被序列化后进行网络传输（见“原则七：广播大变量”中的讲解）。 自定义的类型作为RDD的泛型类型时（比如JavaRDD，Student是自定义类型），所有自定义类型对象，都会进行序列化。因此这种情况下，也要求自定义的类必须实现Serializable接口。 使用可序列化的持久化策略时（比如MEMORY_ONLY_SER），Spark会将RDD中的每个partition都序列化成一个大的字节数组。 对于这三种出现序列化的地方，我们都可以通过使用Kryo序列化类库，来优化序列化和反序列化的性能。Spark默认使用的是Java的序列化机制，也就是ObjectOutputStream&#x2F;ObjectInputStream API来进行序列化和反序列化。但是Spark同时支持使用Kryo序列化库，Kryo序列化类库的性能比Java序列化类库的性能要高很多。官方介绍，Kryo序列化机制比Java序列化机制，性能高10倍左右。Spark之所以默认没有使用Kryo作为序列化类库，是因为Kryo要求最好要注册所有需要进行序列化的自定义类型，因此对于开发者来说，这种方式比较麻烦。 以下是使用Kryo的代码示例，我们只要设置序列化类，再注册要序列化的自定义类型即可（比如算子函数中使用到的外部变量类型、作为RDD泛型类型的自定义类型等）： 123456// 创建SparkConf对象。val conf = new SparkConf().setMaster(...).setAppName(...)// 设置序列化器为KryoSerializer。conf.set(&quot;spark.serializer&quot;, &quot;org.apache.spark.serializer.KryoSerializer&quot;)// 注册要序列化的自定义类型。conf.registerKryoClasses(Array(classOf[MyClass1], classOf[MyClass2])) 原则九：优化数据结构Java中，有三种类型比较耗费内存： 对象，每个Java对象都有对象头、引用等额外的信息，因此比较占用内存空间。 字符串，每个字符串内部都有一个字符数组以及长度等额外信息。 集合类型，比如HashMap、LinkedList等，因为集合类型内部通常会使用一些内部类来封装集合元素，比如Map.Entry。 因此Spark官方建议，在Spark编码实现中，特别是对于算子函数中的代码，尽量不要使用上述三种数据结构，尽量使用字符串替代对象，使用原始类型（比如Int、Long）替代字符串，使用数组替代集合类型，这样尽可能地减少内存占用，从而降低GC频率，提升性能。 但是在笔者的编码实践中发现，要做到该原则其实并不容易。因为我们同时要考虑到代码的可维护性，如果一个代码中，完全没有任何对象抽象，全部是字符串拼接的方式，那么对于后续的代码维护和修改，无疑是一场巨大的灾难。同理，如果所有操作都基于数组实现，而不使用HashMap、LinkedList等集合类型，那么对于我们的编码难度以及代码可维护性，也是一个极大的挑战。因此笔者建议，在可能以及合适的情况下，使用占用内存较少的数据结构，但是前提是要保证代码的可维护性。 资源调优调优概述在开发完Spark作业之后，就该为作业配置合适的资源了。Spark的资源参数，基本都可以在spark-submit命令中作为参数设置。很多Spark初学者，通常不知道该设置哪些必要的参数，以及如何设置这些参数，最后就只能胡乱设置，甚至压根儿不设置。资源参数设置的不合理，可能会导致没有充分利用集群资源，作业运行会极其缓慢；或者设置的资源过大，队列没有足够的资源来提供，进而导致各种异常。总之，无论是哪种情况，都会导致Spark作业的运行效率低下，甚至根本无法运行。因此我们必须对Spark作业的资源使用原理有一个清晰的认识，并知道在Spark作业运行过程中，有哪些资源参数是可以设置的，以及如何设置合适的参数值。 Spark作业基本运行原理 详细原理见上图。我们使用spark-submit提交一个Spark作业之后，这个作业就会启动一个对应的Driver进程。根据你使用的部署模式（deploy-mode）不同，Driver进程可能在本地启动，也可能在集群中某个工作节点上启动。Driver进程本身会根据我们设置的参数，占有一定数量的内存和CPU core。而Driver进程要做的第一件事情，就是向集群管理器（可以是Spark Standalone集群，也可以是其他的资源管理集群，美团•大众点评使用的是YARN作为资源管理集群）申请运行Spark作业需要使用的资源，这里的资源指的就是Executor进程。YARN集群管理器会根据我们为Spark作业设置的资源参数，在各个工作节点上，启动一定数量的Executor进程，每个Executor进程都占有一定数量的内存和CPU core。 在申请到了作业执行所需的资源之后，Driver进程就会开始调度和执行我们编写的作业代码了。Driver进程会将我们编写的Spark作业代码分拆为多个stage，每个stage执行一部分代码片段，并为每个stage创建一批task，然后将这些task分配到各个Executor进程中执行。task是最小的计算单元，负责执行一模一样的计算逻辑（也就是我们自己编写的某个代码片段），只是每个task处理的数据不同而已。一个stage的所有task都执行完毕之后，会在各个节点本地的磁盘文件中写入计算中间结果，然后Driver就会调度运行下一个stage。下一个stage的task的输入数据就是上一个stage输出的中间结果。如此循环往复，直到将我们自己编写的代码逻辑全部执行完，并且计算完所有的数据，得到我们想要的结果为止。 Spark是根据shuffle类算子来进行stage的划分。如果我们的代码中执行了某个shuffle类算子（比如reduceByKey、join等），那么就会在该算子处，划分出一个stage界限来。可以大致理解为，shuffle算子执行之前的代码会被划分为一个stage，shuffle算子执行以及之后的代码会被划分为下一个stage。因此一个stage刚开始执行的时候，它的每个task可能都会从上一个stage的task所在的节点，去通过网络传输拉取需要自己处理的所有key，然后对拉取到的所有相同的key使用我们自己编写的算子函数执行聚合操作（比如reduceByKey()算子接收的函数）。这个过程就是shuffle。 当我们在代码中执行了cache&#x2F;persist等持久化操作时，根据我们选择的持久化级别的不同，每个task计算出来的数据也会保存到Executor进程的内存或者所在节点的磁盘文件中。 因此Executor的内存主要分为三块：第一块是让task执行我们自己编写的代码时使用，默认是占Executor总内存的20%；第二块是让task通过shuffle过程拉取了上一个stage的task的输出后，进行聚合等操作时使用，默认也是占Executor总内存的20%；第三块是让RDD持久化时使用，默认占Executor总内存的60%。 task的执行速度是跟每个Executor进程的CPU core数量有直接关系的。一个CPU core同一时间只能执行一个线程。而每个Executor进程上分配到的多个task，都是以每个task一条线程的方式，多线程并发运行的。如果CPU core数量比较充足，而且分配到的task数量比较合理，那么通常来说，可以比较快速和高效地执行完这些task线程。 以上就是Spark作业的基本运行原理的说明，大家可以结合上图来理解。理解作业基本原理，是我们进行资源参数调优的基本前提。 资源参数调优了解完了Spark作业运行的基本原理之后，对资源相关的参数就容易理解了。所谓的Spark资源参数调优，其实主要就是对Spark运行过程中各个使用资源的地方，通过调节各种参数，来优化资源使用的效率，从而提升Spark作业的执行性能。以下参数就是Spark中主要的资源参数，每个参数都对应着作业运行原理中的某个部分，我们同时也给出了一个调优的参考值。 num-executors 参数说明：该参数用于设置Spark作业总共要用多少个Executor进程来执行。Driver在向YARN集群管理器申请资源时，YARN集群管理器会尽可能按照你的设置来在集群的各个工作节点上，启动相应数量的Executor进程。这个参数非常之重要，如果不设置的话，默认只会给你启动少量的Executor进程，此时你的Spark作业的运行速度是非常慢的。 参数调优建议：每个Spark作业的运行一般设置50~100个左右的Executor进程比较合适，设置太少或太多的Executor进程都不好。设置的太少，无法充分利用集群资源；设置的太多的话，大部分队列可能无法给予充分的资源。 executor-memory 参数说明：该参数用于设置每个Executor进程的内存。Executor内存的大小，很多时候直接决定了Spark作业的性能，而且跟常见的JVM OOM异常，也有直接的关联。 参数调优建议：每个Executor进程的内存设置4G8G较为合适。但是这只是一个参考值，具体的设置还是得根据不同部门的资源队列来定。可以看看自己团队的资源队列的最大内存限制是多少，num-executors乘以executor-memory，是不能超过队列的最大内存量的。此外，如果你是跟团队里其他人共享这个资源队列，那么申请的内存量最好不要超过资源队列最大总内存的1&#x2F;31&#x2F;2，避免你自己的Spark作业占用了队列所有的资源，导致别的同学的作业无法运行。 executor-cores 参数说明：该参数用于设置每个Executor进程的CPU core数量。这个参数决定了每个Executor进程并行执行task线程的能力。因为每个CPU core同一时间只能执行一个task线程，因此每个Executor进程的CPU core数量越多，越能够快速地执行完分配给自己的所有task线程。 参数调优建议：Executor的CPU core数量设置为24个较为合适。同样得根据不同部门的资源队列来定，可以看看自己的资源队列的最大CPU core限制是多少，再依据设置的Executor数量，来决定每个Executor进程可以分配到几个CPU core。同样建议，如果是跟他人共享这个队列，那么num-executors * executor-cores不要超过队列总CPU core的1&#x2F;31&#x2F;2左右比较合适，也是避免影响其他同学的作业运行。 driver-memory 参数说明：该参数用于设置Driver进程的内存。 参数调优建议：Driver的内存通常来说不设置，或者设置1G左右应该就够了。唯一需要注意的一点是，如果需要使用collect算子将RDD的数据全部拉取到Driver上进行处理，那么必须确保Driver的内存足够大，否则会出现OOM内存溢出的问题。 spark.default.parallelism 参数说明：该参数用于设置每个stage的默认task数量。这个参数极为重要，如果不设置可能会直接影响你的Spark作业性能。 参数调优建议：Spark作业的默认task数量为5001000个较为合适。很多同学常犯的一个错误就是不去设置这个参数，那么此时就会导致Spark自己根据底层HDFS的block数量来设置task的数量，默认是一个HDFS block对应一个task。通常来说，Spark默认设置的数量是偏少的（比如就几十个task），如果task数量偏少的话，就会导致你前面设置好的Executor的参数都前功尽弃。试想一下，无论你的Executor进程有多少个，内存和CPU有多大，但是task只有1个或者10个，那么90%的Executor进程可能根本就没有task执行，也就是白白浪费了资源！因此Spark官网建议的设置原则是，设置该参数为num-executors * executor-cores的23倍较为合适，比如Executor的总CPU core数量为300个，那么设置1000个task是可以的，此时可以充分地利用Spark集群的资源。 spark.storage.memoryFraction 参数说明：该参数用于设置RDD持久化数据在Executor内存中能占的比例，默认是0.6。也就是说，默认Executor 60%的内存，可以用来保存持久化的RDD数据。根据你选择的不同的持久化策略，如果内存不够时，可能数据就不会持久化，或者数据会写入磁盘。 参数调优建议：如果Spark作业中，有较多的RDD持久化操作，该参数的值可以适当提高一些，保证持久化的数据能够容纳在内存中。避免内存不够缓存所有的数据，导致数据只能写入磁盘中，降低了性能。但是如果Spark作业中的shuffle类操作比较多，而持久化操作比较少，那么这个参数的值适当降低一些比较合适。此外，如果发现作业由于频繁的gc导致运行缓慢（通过spark web ui可以观察到作业的gc耗时），意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。 spark.shuffle.memoryFraction 参数说明：该参数用于设置shuffle过程中一个task拉取到上个stage的task的输出后，进行聚合操作时能够使用的Executor内存的比例，默认是0.2。也就是说，Executor默认只有20%的内存用来进行该操作。shuffle操作在进行聚合时，如果发现使用的内存超出了这个20%的限制，那么多余的数据就会溢写到磁盘文件中去，此时就会极大地降低性能。 参数调优建议：如果Spark作业中的RDD持久化操作较少，shuffle操作较多时，建议降低持久化操作的内存占比，提高shuffle操作的内存占比比例，避免shuffle过程中数据过多时内存不够用，必须溢写到磁盘上，降低了性能。此外，如果发现作业由于频繁的gc导致运行缓慢，意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。 资源参数的调优，没有一个固定的值，需要同学们根据自己的实际情况（包括Spark作业中的shuffle操作数量、RDD持久化操作数量以及spark web ui中显示的作业gc情况），同时参考本篇文章中给出的原理以及调优建议，合理地设置上述参数。 资源参数参考示例以下是一份spark-submit命令的示例，大家可以参考一下，并根据自己的实际情况进行调节： 123456789./bin/spark-submit \\ --master yarn-cluster \\ --num-executors 100 \\ --executor-memory 6G \\ --executor-cores 4 \\ --driver-memory 1G \\ --conf spark.default.parallelism=1000 \\ --conf spark.storage.memoryFraction=0.5 \\ --conf spark.shuffle.memoryFraction=0.3 \\ 写在最后的话根据实践经验来看，大部分Spark作业经过本次基础篇所讲解的开发调优与资源调优之后，一般都能以较高的性能运行了，足以满足我们的需求。但是在不同的生产环境和项目背景下，可能会遇到其他更加棘手的问题（比如各种数据倾斜），也可能会遇到更高的性能要求。为了应对这些挑战，需要使用更高级的技巧来处理这类问题。在后续的《Spark性能优化指南——高级篇》中，我们会详细讲解数据倾斜调优以及Shuffle调优。","tags":[{"name":"spark","slug":"spark","permalink":"http://aeyoo.net/tags/spark/"}]},{"title":"朴素贝叶斯与拉普拉斯平滑简介","date":"2018-10-31T15:26:38.000Z","path":"2018/10/31/朴素贝叶斯与拉普拉斯平滑简介/","text":"今天我们从极大似然估计说起，然后阐述一下朴素贝叶斯分类算法和贝叶斯估计，最后介绍M估计和拉普拉斯平滑方法，其主要解决了零概率问题。 1 极大似然法极大似然法是一种根据样本估计模型参数的方法，通过观测样本构造似然函数，然后令似然函数的极值为0进而确定模型参数。 假设我们有一枚硬币，抛出后正面朝上的概率为p(0&lt;p&lt;1)。现在我们抛出了49个正面(H)，31个反面(T)。我们来求其似然函数的最大值： $$f(\\theta)&#x3D;f_D(H&#x3D;49,T&#x3D;80-49|p)&#x3D;\\left(\\frac{80}{49}\\right)p^{49}(1-p)^{31} \\tag{1.1}$$ 我们对方程两边同时取微分，并使其为零。 $$\\begin{aligned}0 &amp;&#x3D; \\frac{d}{dp}\\left(\\left(\\frac{80}{49}\\right)p^{49}(1-p)^{31}\\right) \\\\&amp;&#x3D; 49p^{48}(1-p)^{31}-31p^{49}(1-p)^{30} \\\\&amp;&#x3D; p^{48}(1-p)^{30}[49(1-p)-31p] \\\\\\end{aligned} \\tag{1.2}$$ 其解为p&#x3D;0,p&#x3D;1，以及p&#x3D;49&#x2F;80。使可能性最大的解显然是p&#x3D;49&#x2F;80，p&#x3D;0和p&#x3D;1这两个解会使可能性为零）。因此我们说最大似然估计值为49&#x2F;80。 这个结果很容易一般化。只需要用一个字母t代替49用以表达伯努利试验中的被观察数据（即样本）的“成功”次数，用另一个字母n代表伯努利试验的次数即可。使用完全同样的方法即可以得到最大似然估计值: $$\\hat{p}&#x3D;\\frac{t}{n} \\tag{1.3}$$ 对于任何成功次数为t，试验总数为n的伯努利试验。以上就是用极大似然法求解离散分布，连续参数空间的情况。 2 朴素贝叶斯朴素贝叶斯是基于贝叶斯定理与特征条件独立假设的分类方法。对于给定的训练数据集，首先基于特征条件独立假设 学习输入&#x2F;输出的联合概率分布；然后基于此模型，对于给定的输入x，利用贝叶斯定理求出后验概率最大的输出y。 先验概率在贝叶斯统计中，某一不确定量p的先验概率分布是在考虑”观测数据”前，能表达p不确定性的概率分布。 后验概率 （知道“果”，推测“因”的概率）在贝叶斯统计中，一个随机事件的后验概率是在考虑相关证据 ( 观测数据 ) 后所得到的条件概率。换句话说，后验概率分布是一个随机变量基于试验得到的概率分布。 2.1 联合概率分布在概率论中, 对两个随机变量X和Y，其联合分布是同时对于X和Y的概率分布。 对离散随机变量而言，联合分布概率质量函数为$P(X &#x3D; x , and , Y &#x3D; y)$，即 $$P(X&#x3D;x , and , Y&#x3D;y)&#x3D;P(Y&#x3D;y|X&#x3D;x)P(X&#x3D;x)&#x3D;p(X&#x3D;x|Y&#x3D;y)P(Y&#x3D;y) \\tag{2.1}$$ 因为是概率分布函数，所以必须有 $$\\sum_{x}{\\sum_{y}{f_{X,Y}(x,y)dy dx}}&#x3D;1 \\tag{2.2} $$ 2.2 朴素贝叶斯的推导给定训练集 $T&#x3D;\\{(x_1,y_1),(x_2,y_2),..,(x_N,y_N)\\}$，其由 $P(X,Y)$ 独立同分布产生。朴素贝叶斯法通过训练数据集学习联合概率分布$P(X,Y)$。具体地，学习以下先验分布和条件概率分布。先验分布$P(Y&#x3D;c_k),k&#x3D;1,2,…,K$,条件概率分布 $$P(X&#x3D;x|Y&#x3D;c_k)&#x3D;P(x^{(1)}&#x3D;X^{(1)},…,x^{(n)}|Y&#x3D;c_k),k&#x3D;1,2,…,K$$ 最后学习到联合概率分布$P(X,Y)$。 但是条件概率分布$P(X&#x3D;x|Y&#x3D;c_k)$有指数量级的参数。其估计是不可行的。假设$x^i$的取值有$S_j$个，Y的取值有$K$个，那么参数个数为$K\\prod_{j&#x3D;1}^n{S_j}$。 朴素贝叶斯对条件概率分布做了独立性的假设,假设分类的特征在类确定的条件下都是相互独立的。由于这是一个较强的假设，“朴素”因此得名，但是朴素贝叶斯依然有出色的性能。由条件独立性假设可以得到 $$\\begin {aligned}P(X&#x3D;x|Y&#x3D;c_k)&amp;&#x3D;P(X^{(1)}&#x3D;x^{(1)}, .. , X^{(n)}&#x3D;x^{(n)}|Y&#x3D;c_k) \\\\&amp;&#x3D;\\prod_{j&#x3D;1}^n{P(X^{(j)}&#x3D;x^{(j)}|Y&#x3D;c_k)} \\\\\\end {aligned} \\tag{2.3}$$ 朴素贝叶斯实际上学习到了生成数据的机制，所以属于生成模型。 朴素贝叶斯分类时，对给定的输入x，通过后验概率分布$P(Y&#x3D;c_k|X&#x3D;x)$，将后验概率最大的类作为x的类输出。后验概率的计算根据贝叶斯定理进行： $$P(Y&#x3D;c_k|X&#x3D;x)&#x3D;\\frac{P(X&#x3D;x|Y&#x3D;c_k)P(Y&#x3D;c_k)}{\\sum_{i}^K{P(X&#x3D;x|Y&#x3D;c_i)P(Y&#x3D;c_i)}} \\tag{2.4}$$ 将$(2.3)$代入$(2.4)$有 $$P(Y&#x3D;c_k|X&#x3D;x)&#x3D; \\frac{P(Y&#x3D;c_k) \\prod_{j&#x3D;1}^n P(X^{(j)}&#x3D;x^{(j)}|Y&#x3D;c_k)} { \\sum_{i}^K{P(Y&#x3D;c_i) \\prod_{j&#x3D;1}^n{P(X^{(j)}&#x3D;x^{(j)}|Y&#x3D;c_i)}}} ,, k&#x3D;1,2,..,K \\tag{2.5}$$ 这就是朴素贝叶斯分类的基本公式。于是，朴素贝叶斯分类器可表示为 $$y&#x3D;f(x)&#x3D;\\mathop{\\arg\\max}\\limits_{c_k}\\frac{P(Y&#x3D;c_k)\\prod_{j&#x3D;1}^n{P(X^{(j)}&#x3D;x^{(j)}|Y&#x3D;c_k)}}{\\sum_{i}^K{P(Y&#x3D;c_i)\\prod_{j&#x3D;1}^n{P(X^{(j)}&#x3D;x^{(j)}|Y&#x3D;c_i)}}} \\tag{2.6}$$ 在$(2.6)$中，分母对所有$C_k$都是相同的，所以可以进一步简化为 $$y&#x3D;\\mathop{\\arg\\max}\\limits_{c_k} \\space P(Y&#x3D;c_k) \\prod_{j&#x3D;1}^n{P(X^{(j)}&#x3D;x^{(j)}|Y&#x3D;c_k)} \\tag{2.7}$$ 2.3 朴素贝叶斯算法的参数估计在朴素贝叶斯中，学习意味着估计$P(Y&#x3D;c_k)$和$P(X^{(j)}&#x3D;x^{(j)}|Y&#x3D;c_k)$，可以使用极大似然法估计相应的概率(思想即伯努利试验的极大似然估计的泛化，详见第一部分)，先验概率$P(y&#x3D;c_k)$ 的极大似然估计是 $$P(Y&#x3D;c_k)&#x3D;\\frac{\\sum_{i&#x3D;1}^N{I(y_i&#x3D;c_k)}} {N}, k&#x3D;1,2,…,K \\tag{2.8}$$ 对于条件概率，设第j个特征$x^{(j)}$可能取值的集合为${a_{j1}, a_{j2},.., a_{jS_j}}$，则条件概率 $P(X^{(j)}&#x3D;a_{(jl)}|Y&#x3D;c_k)$ 的极大似然估计是 $$P(X^{(j)}&#x3D;a_{jl}|Y&#x3D;c_k)&#x3D;\\frac{\\sum_{i&#x3D;1}^N{I(x_i^{(j)}&#x3D;a_{jl},y_i&#x3D;c_k)}} {\\sum_{i&#x3D;1}^N{I(y_i&#x3D;c_k)}} \\tag{2.9} $$ $$j&#x3D;1,2,…,n; , l&#x3D;1,2,…, S_i; , k&#x3D;1,2,.., K $$ $(2.9)$中，$x_i^{(j)}$是第i个样本的第j个特征，$a_{jl}$是第j个特征可能取的第$l$个值，$I$为指示函数。 2.4 朴素贝叶斯算法的形式化描述输入：训练数据,训练数据$T&#x3D;\\{(x_1,y_1),(x_2,y_2),..,(x_N,y_N)\\}$，其中$x_i&#x3D;(x_i^{(1)}, x_i^{(2)}, …, x_i^{(n)} ) ^T$，$x_i^{(j)}$是第i个样本的第j个特征，$x_i^{(j)} \\in \\{ a_{j1}, a_{j2}, … , a_{jSj}\\}$, $a_{jl}$是第$j$个特征可能取得第$l$个值，$j&#x3D;1,2,..,n,, l&#x3D;1,2,…,S_j, y_i \\in \\{c_1,c_2,..,c_K\\}$；实例$x$。 输出： 实例$x$的分类。 (1) 计算先验概率及条件概率 先验概率 $$P(Y&#x3D;c_k)&#x3D;\\frac{\\sum_{i&#x3D;1}^N{I(y_i&#x3D;c_k)}}{N}, k&#x3D;1,2,…,K \\tag{2.10}$$ 条件概率 $$P(X^{(j)}&#x3D;a_{jl}|Y&#x3D;c_k)&#x3D;\\frac{\\sum_{i&#x3D;1}^N{I(x_i^{(j)}&#x3D;a_{jl},y_i&#x3D;c_k)}}{\\sum_{i&#x3D;1}^N{I(y_i&#x3D;c_k)}} \\tag{2.11}$$ $$j&#x3D;1,2,…,n; l&#x3D;1,2,..,S; k&#x3D;1,2,…,K$$ (2) 对于给定的实例$x&#x3D;(x^{(1)},x^{(2)},,…,x^{(n)})$，计算后验概率(该步骤通过贝叶斯公式得到) $$P(Y&#x3D;c_k|X&#x3D;x)&#x3D;P(Y&#x3D;c_k)\\prod_{j&#x3D;1}^n{P(X^{(j)}&#x3D;x^{(j)}|Y&#x3D;c_k)}, k&#x3D;1,2,…,K \\tag{2.11} $$ (3) 确定实例x的类 $$y&#x3D;\\mathop{\\arg\\max}\\limits_{c_k} \\space P(Y&#x3D;c_k) \\prod_{j&#x3D;1}^n{P(X^{(j)}&#x3D;x^{(j)}|Y&#x3D;c_k)} \\tag{2.12}$$ 用极大似然估计可能会出现所要估计的概率值为0的情况，这会影响到后验概率的计算结果，使分类产生误差。解决这一问题的方法是采用贝叶斯估计。具体地，条件概率的贝叶斯估计是 $$P_{\\lambda}{(X^{(j)}&#x3D;a_{jl}|Y&#x3D;c_k)}&#x3D;\\frac{\\sum_{i&#x3D;1}^N{I(X_i^{(j)} &#x3D; a_{jl},y_i&#x3D;c_k)+\\lambda}}{\\sum_{i&#x3D;1}^N{I(y_i&#x3D;c_k)+S_i \\lambda}} \\tag{2.13} $$ 其中$\\lambda\\geq 0$。等价于在随机变量各个取值的频数上赋予一个正数$\\lambda&gt;0$。当$\\lambda&#x3D;0$时就是极大似然估计。常取$\\lambda&#x3D;1$，这时就是拉普拉斯平滑。显然，对任何$l&#x3D;1,2,…,S_j,k&#x3D;1,2,…,K$,有 $$P_{\\lambda}(X^{(j)}&#x3D;a_{jl}|Y&#x3D;c_k)&gt;0 \\tag{2.14} $$ $$\\sum_{l&#x3D;1}^{S_j}{P(X^{(j)}&#x3D;a_{jl}|Y&#x3D;c_k)&#x3D;1} \\tag{2.15} $$ 这说明式$(2.13)$确是一种概率分布。同样，先验概率的贝叶斯估计是 $$P_{\\lambda}(Y&#x3D;c_k)&#x3D;\\frac{\\sum_{i&#x3D;1}^N{I(y_i&#x3D;c_k)+\\lambda}}{N+k\\lambda} \\tag{2.16} $$ 3 M估计和拉普拉斯平滑对于多分类问题，一般可以通过观测数据来估计类别$c_k$出现的概率 ( 极大似然法 )，即$P(Y&#x3D;c_k)&#x3D;\\frac{n_c}{n}$。其中，$n_k$为类别$c_k$的样本数量，$n$为总样本数量。当$n_c$很大的时候，$\\frac{n_c}{n}$是对类别$c_k$出现的真实概率$P_{real}(Y&#x3D;c_k)$的良好估计。但是当$n_c$比较小的时候，$\\frac{n_c}{n}$会产生有偏估计。当$n_c &#x3D; 0$的时候，$\\frac{n_c}{n}&#x3D;0$会对$P_{real}(Y&#x3D;c_k)$产生一个有偏的过低概率估计。由贝叶斯公式可得$P(Y&#x3D;c_k|X&#x3D;x)&#x3D;0$，则类别$c_k$永远不会被分类到。 为了避免此问题，m估计出现了: $$P(Y&#x3D;c_k)&#x3D;\\frac{n_c+mp}{n+m} \\tag{3.1}$$ 其中$n_c$为该类别$c_k$的样本数量，$n$为总样本数量，$p$为$P(Y&#x3D;c_k)$的先验估计，m为等效样本大小的常量。 4 关于CTR中拉普拉斯平滑分母值的设定在CTR(点击率)预估中，拉普拉斯平滑是必要的。 $$ctr&#x3D;\\frac{click}{expos} \\tag{4.1}$$ $click$是点击次数，$expos$是曝光量次数。 加了拉普拉斯平滑之后， $$ctr&#x3D;\\frac{click+\\lambda}{expos+k\\lambda}, ,, \\lambda&#x3D;1 \\tag{4.2}$$ $k$为类别个数，在商品推荐中$k$为item的个数。对于商品a，如果没有曝光 ( $expos&#x3D;0$ ) 的话，此时点击 ( $expos$ ) 也为0。这样的话就是$ctr_a&#x3D;\\frac{1}{k}$，也就是将点击 item a 的先验概率赋值给$ctr_a$。换句话说，对于总数为k的商品，在没有任何观测数据的情况下，点击其中一个的概率是$p_{prior}&#x3D;\\frac{1}{k}$。这和LDA主题模型也有共通之处。 5 参考 最大似然估计 统计学习方法[李航] 联合分布 Cmd Markdown 公式指导手册 https://blog.csdn.net/sinat_37789134/article/details/68948546 拉普拉斯平滑处理 Laplace Smoothing 先验分布、后验分布、似然估计这几个概念是什么意思，它们之间的关系是什么？ 贝叶斯定理 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} });","tags":[{"name":"朴素贝叶斯","slug":"朴素贝叶斯","permalink":"http://aeyoo.net/tags/朴素贝叶斯/"},{"name":"拉普拉斯平滑","slug":"拉普拉斯平滑","permalink":"http://aeyoo.net/tags/拉普拉斯平滑/"},{"name":"M估计","slug":"M估计","permalink":"http://aeyoo.net/tags/M估计/"},{"name":"极大似然法","slug":"极大似然法","permalink":"http://aeyoo.net/tags/极大似然法/"}]},{"title":"白话Attenction机制","date":"2018-10-30T14:04:46.000Z","path":"2018/10/30/详解Attenction机制/","text":"attention机制最初是在 rnn 中引入的用于解决机器翻译问题，此前机器翻译问题通过使用 RNN 解决，先基于输入编码一个隐语义向量，然后通过解码器基于该隐语义向量进行解码。但是这样存在一个问题，就是解码严重依赖于同一个隐语义向量。仔细思考下这样是不合理的。因为对于不同的输出 $y_i$，其和输入$X&#x3D;\\lbrace x_1, x_2,.., x_n \\rbrace$有着不同的相关性，例如将“我爱你”翻译成“I love you”，显然输入“我“，”爱“，”你”对输出 $I$的贡献是不同的。attention就是为了解决这个问题，总结就是为了解决信息传递过程中的信息量不同的情况。 关于注意力机制，看这篇文章就可以了《深度学习中的注意力机制》； 上文中的示例模型是Seq2Seq，可以看这篇文章从Encoder到Decoder实现Seq2Seq模型。 下面聊几个问题。 1 attention是怎么加的？ MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} });","tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://aeyoo.net/tags/深度学习/"},{"name":"Attenction","slug":"Attenction","permalink":"http://aeyoo.net/tags/Attenction/"}]},{"title":"如何优雅地爬取明星头像","date":"2018-10-30T00:25:04.000Z","path":"2018/10/30/如何优雅地爬取明星头像/","text":"最近需要修正一些明星头像照片集合中的bad case，手动替换的过程中发现 http://www.manmankan.com 这个网址不错，所以打算先爬取该网站的明星头像照片对我的素材进行替换，然后再修正bad case。这样兴许可以减小工作量。 因为该网站采用了明星信息动态加载的方式，所以直接爬虫是爬不到的。解决该问题的方式有两种： selenium+phantomjs。 Selenium是一个开源的自动化测试工具，可以用于测试web应用程序。PhantomJS是一个没有界面的浏览器。使用Python+Selenium+PhantomJS可以很方便的爬取动态加载的网页。其中PhantomJS 用来渲染解析JS，Selenium 用来驱动PhantomJS 并与 Python 的对接，Python 进行后期的数据处理。但是目前PhantomJS似乎停止维护了。关于这种方式，python获取完整网页内容（即包括js动态加载的）：selenium+phantomjs 有介绍。 分析js请求。我比较倾向于这个方式。一般动态加载的网页都是通过js向服务器端发送请求获取数据的，这样的话我们就可以截获请求，然后模拟请求进行访问了，相比之下，这种效率更高。 第二种方式如何截获请求呢？ 首先，使用开发版Firefox打开相关界面，使用查看器查看相关内容元素。如图所示： 在相关元素旁边有两个比较可疑的东西，loadSearch()函数和 http://hit.manmankan.com/dy2013/search.asp?rnd=0.5952100315643931&amp;keywords=刘亦菲&amp;t=3&amp;fl=0 。都有search关键词，嗯，暂且记下。 然后从查看器切换到网络板块，并在网页上输入刘亦菲进行搜索，观察发生了哪些网络传输行为。这时会有好多传输信息显示，既然我们刚刚发现了search关键词，那么我们可以输入search关键词，看看剩下些什么。 这两个东西貌似很熟悉，第二个网址和之前发现的网址很像啊，输入浏览器看看是啥。 这正是咱们需要的结果嘛。我们可以用Python访问这个网址，就会得到相关网页，然后进行正则提取就好了。 然后再看看两个网址有啥区别，貌似关键词不同，应该是中文网址进行了URL编码。那么我们只需要在Python中对中文名字进行相应编码即可。 123http://hit.manmankan.com/dy2013/search.asp?rnd=0.5952100315643931&amp;keywords=刘亦菲&amp;t=3&amp;fl=0http://hit.manmankan.com/dy2013/search.asp?rnd=0.5952100315643931&amp;keywords=%C1%F5%D2%E0%B7%C6&amp;t=3&amp;fl=0 那么我们再看看search.js文件，看看能不能找到loadSearch()函数，毕竟看名字二者存在很大关联。果不其然，发现如下代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556function loadSearch() &#123; var key = QueryString(\"KeyWords\"); if (key == undefined || key == null || key == \"\") &#123; $('#lilist').html(\"&lt;span&gt;请输入要查询的关键字&lt;/span&gt;\"); return; &#125; if(key.indexOf(\"script\")&gt;0) &#123; return; &#125; key = decodeURIComponent(key); key=stripscript(key); var fid = QueryString(\"fl\"); if (fid == undefined || fid == null || fid == \"\") &#123; fid=0; &#125; searchlist(key,fid);&#125;function searchlist(keywords,fid) &#123; keywords = Trim(keywords); //alert(keywords); $('#lilist').html(\"&lt;span&gt;正在搜索中....&lt;/span&gt;\"); $('#keyword').val(keywords); $('#kw').html(keywords); if (keywords == undefined || keywords == \"\") &#123; $('#lilist').html(\"&lt;span&gt;请输入要查询的关键字&lt;/span&gt;\"); return; &#125; var ReturnScript,ReturnValue; if (keywords != undefined &amp;&amp; keywords != \"\") &#123; ReturnScript=document.createElement('script'); ReturnScript.src=\"http://hit.manmankan.com/dy2013/search.asp?rnd=\"+Math.random()+\"&amp;keywords=\"+decodeURIComponent(keywords)+\"&amp;t=3&amp;fl=\"+fid; document.body.appendChild(ReturnScript); &#125; &#125;//查询结果显示function SearchResult(innerHTMLValue)&#123; var retv=innerHTMLValue; if(retv==\"\") &#123; $('#lilist').html(\"&lt;span&gt;没有找到您搜索的明星！！！&lt;/span&gt;\"); &#125; else &#123; $(\"#lilist\").html(\"\"); $(\"#lilist\").html(retv); &#125;&#125; 来吧，我们可以编码了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798#coding:utf8import osimport urllib2import refrom urllib import quoteimport sysreload(sys)sys.setdefaultencoding('utf8')def getPage(url): # 如果你处于公司内网的话，可以使用代理，方法如下： # The proxy address and port: # proxy_info = &#123;'host': 'your_proxy_site', 'port': your_proxy_site&#125; # We create a handler for the proxy # proxy_support = urllib2.ProxyHandler(&#123;\"http\": \"http://%(host)s:%(port)d\" % proxy_info&#125;) # We create an opener which uses this handler: # opener = urllib2.build_opener(proxy_support) # Then we install this opener as the default opener for urllib2: # urllib2.install_opener(opener) header = &#123;\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:62.0) Gecko/20100101 Firefox/62.0\"&#125; request = urllib2.Request(url=url, headers=header) # 模拟浏览器进行访问 response = urllib2.urlopen(request) text = response.read() return textdef getHtml(url): page = getPage(url) html = unicode(page,'GBK').encode(\"utf8\") return htmldef getImg(html, reg): imgre = re.compile(reg) imglist = re.findall(imgre, html) return imglistdef loadImg(url, path): page = getPage(url) data = page f1 = open(path, \"wb\") f1.write(data) f1.close()def load_picname(path): files = os.listdir(unicode(path, \"utf8\")) # 得到文件夹下的所有文件名称 pic_name=[] for f in files: pic_name.append(f.split(\".\")[0]) return pic_nameif __name__==\"__main__\": #配置 begin imgpath = \"imgs\" # 图片保存路径 picname_path=r\"D:\\\\wsp\\\\明星头像\\\\dzb\" # 获取所有图片名 #配置 end if not os.path.exists('.\\\\' + imgpath): os.mkdir('.\\\\' + imgpath) names=load_picname(picname_path) reg = r'src=\"([^\"]*jpg)\" alt=\"(.*?)\"/&gt;' url = \"http://hit.manmankan.com/dy2013/search.asp?keywords=%s&amp;t=3&amp;fl=0\" # names=[\"赵君\",\"胡歌\",\"裕美 \"] # s=\"赵君\" # s=s.decode(\"utf8\").encode(\"gbk\") # print(quote(s)) #s=unicode(s,'utf8').encode(\"gbk\") count=0 exist_pic_count=0 for name in names: print(count) count+=1 name=name.decode(\"utf8\").encode(\"gbk\") turl = (url) % name html = getHtml(turl) d = getImg(html, reg) print(html) if len(d)&gt;0: print(\"exist_pic_count: \"+str(exist_pic_count)) exist_pic_count+=1 # loadList(filed,d) pic_name=d[0][1].strip().decode(\"utf8\").encode(\"gbk\") loadImg(d[0][0].strip(),(imgpath + \"/%s.jpg\") %pic_name)","tags":[{"name":"爬虫","slug":"爬虫","permalink":"http://aeyoo.net/tags/爬虫/"}]},{"title":"hive常用语法","date":"2018-10-29T09:15:22.000Z","path":"2018/10/29/hive常用语法/","text":"最近要用hive做一些基础分析，所以整理一下平时遇到的一些语法。另外，将专门整理一个hive的基础教程。 1 在SQL中，count(字段)或者count(1)不统计null值；count(*)统计null值。 2 IF(expr1,expr2,expr3)在SQL中是一个函数，expr1是一个表达式，如果返回true，则返回expr2，否则返回expr3。经常这样使用: 123selectcount(IF (field1=1 and field is not NULL,1, NULL )) as new_field1from tableA 3 LEFT JOIN 关键字会从左表 (Persons) 那里返回所有的行，即使在右表 (Orders) 中没有匹配的行。 4 regexp_extract(string subject, string pattern, int index) 返回值: string 说明: 将字符串subject按照pattern正则表达式的规则拆分，返回index指定的字符。 第一参数: 要处理的字符串 第二参数: 需要匹配的正则表达式 第三个参数: 0，是返回与之匹配的整个字符串，包含正则表达式部分 1，返回拆分后的第 1 个子串 2，返回拆分后的第 2 个子串 … 参考 Hive Operators and User-Defined Functions Hive内置函数","tags":[{"name":"hive","slug":"hive","permalink":"http://aeyoo.net/tags/hive/"}]},{"title":"mac重装任意版本的系统","date":"2018-10-28T15:41:57.000Z","path":"2018/10/28/mac重装系统/","text":"OSX真的做的越来越差劲了，最近升级到最新系统，感觉很难用。所以打算回退到之前用过的最好用的版本，macOS Sierra 10.12.6。之所以说这个系统好用是因为，这个系统比较稳定，而且能找到很多可用工具，且支持Notes软件的手写笔记（使用 apple pencil）同步到mac Notes阅读。接下来介绍如何重装系统，以安装macOS Seirra为例。 重装系统的方法大体有两种： 互联网恢复 U盘重装 个人推荐第二种，第一种方式比较简单，但是容易出问题，我遇到的情况是只能安装mac随附版本系统。按照官网的说法，可以安装该mac上曾经安装过的最新系统，但是我折腾了半天没做到。所以这里只介绍第二种方式，如果想了解第一种方式见官网链接：如何通过 macOS 恢复功能重新安装 macOS。 U盘重装U盘重装也就是官网说的可引导安装器。 1 下载 macOS在浏览器输入如下网址，即可以跳转到app store对应的macOS下载页面。 macOS Mojave [1] https://itunes.apple.com/cn/app/macos-mojave/id1398502828?mt=12 macOS High Sierra [2] https://itunes.apple.com/cn/app/macos-high-sierra/id1246284741?mt=12 macOS Sierra [3] https://itunes.apple.com/cn/app/macos-sierra/id1127487414?ls=1&amp;mt=12 OS X El Capitan [4] https://itunes.apple.com/cn/app/os-x-el-capitan/id1147835434?mt=12 更老版本在此不进行列举，以上网址在官网均可以找到。 下载之后，在应用程序中会出现 Install macOS Seirra。 2 格式化U盘下载安装器后，请连接U盘，确保该U盘至少有12G可用储存空间。并且将U盘格式化为 Mac OS 扩展格式。 插上U盘之后，格式化 Mac OS 扩展格式 步骤如下： 在 Mac 上的“磁盘工具”应用 中，选取“显示”&gt;“显示所有设备”。 如果想要抹掉某个磁盘，请 推出该磁盘的每个宗卷（在边栏上选择宗卷，然后点按“推出”按钮 ）。[如果格式化U盘失败，很可能是因为没有推出宗卷] 在边栏中选择磁盘或宗卷，然后点按“抹掉”按钮 。 点按“格式”弹出式菜单，然后选取宗卷格式。[5] Mac OS 扩展（日志式）：使用 Mac 格式（日志式 HFS Plus）来保护分层文件系统的完整性。 Mac OS 扩展（日志式，加密）：使用 Mac 格式，要求密码，并加密分区。 Mac OS 扩展（区分大小写，日志式）：使用 Mac 格式并区分文件夹名称的大小写。例如，名称为“Home”和“HOME”的文件夹是两个不同的文件夹。 MS-DOS (FAT)：用于 Windows 宗卷且大小为 32 GB 或不足 32 GB。 ExFAT：用于 Windows 宗卷且大小超过 32 GB。 输入磁盘或宗卷的名称。 如果选取了 Mac OS 扩展（日志式，加密），若要防止已抹掉的文件被恢复，请点按“安全性选项”，使用滑块来选取覆盖已抹掉数据的次数，然后点按“好”。 覆盖数据三次即符合美国能源部关于安全抹掉磁性介质的标准。覆盖数据七次即符合美国国防部的 5220-22-M 标准。 点按“抹掉”，然后点按“完成”。[5] 3 将系统刻录到U盘中打开Terminal(终端)，键入或粘贴以下命令之一。这些命令假设安装器（Install macOS Seirra，即通过第一步下载的系统镜像），仍位于您的“应用程序”文件夹中，并且 MyVolume 是U盘的名称。如果不是这个名称，请将MyVolume替换为你的U盘名称。 [6] Mojave： 1sudo /Applications/Install\\ macOS\\ Mojave.app/Contents/Resources/createinstallmedia --volume /Volumes/MyVolume High Sierra： 1sudo /Applications/Install\\ macOS\\ High\\ Sierra.app/Contents/Resources/createinstallmedia --volume /Volumes/MyVolume Sierra： 1sudo /Applications/Install\\ macOS\\ Sierra.app/Contents/Resources/createinstallmedia --volume /Volumes/MyVolume --applicationpath /Applications/Install\\ macOS\\ Sierra.app El Capitan： 1sudo /Applications/Install\\ OS\\ X\\ El\\ Capitan.app/Contents/Resources/createinstallmedia --volume /Volumes/MyVolume --applicationpath /Applications/Install\\ OS\\ X\\ El\\ Capitan.app 键入相应的命令后，请按下 Return 键。 出现提示时，请键入您的管理员密码，然后再次按下 Return 键。在您键入密码时，“终端”不会显示任何字符。 出现提示时，请键入 Y 以确认您要抹掉宗卷，然后按下 Return 键。创建可引导安装器过程中，“终端”将显示进度。 当“终端”显示这个操作已完成时，该宗卷的名称将与您下载的安装器名称相同，例如“Install macOS Seirra”。您现在可以退出“终端”并弹出宗卷。 [6] 4 设置U盘为启动磁盘系统设置 — 启动磁盘 — 设置U盘（Install macOS Seirra）为启动磁盘 5 重启系统，进行自动安装重启系统后，会自动进行系统的安装，期间还会自动重启系统一次。然后就可以设置系统了。 6 关于系统账户登录的说明装好系统之后，在进行系统设置-登录apple账户时， 可以立即登录自己的apple账户作为mac用户，mac用户和apple账户一致。 也可以略过这一步，新建一个账户作为mac用户，然后apple store等软件再登录自己的apple账户，mac用户和apple账户不一致。 参考 如何升级到 macOS Mojave 如何升级到 macOS High Sierra 如何升级到 macOS Sierra 如何升级到 OS X El Capitan 在 Mac 上使用“磁盘工具”抹掉宗卷 如何创建可引导的 macOS 安装器","tags":[{"name":"重装系统","slug":"重装系统","permalink":"http://aeyoo.net/tags/重装系统/"}]},{"title":"关于数据例行化的几点思考","date":"2018-10-22T08:45:11.000Z","path":"2018/10/22/关于数据例行化的几点思考/","text":"今天总结一下工作中遇到的一些关于数据例行化的问题，并给出几点思考。 如果你从事机器学习的工业应用，那么你有可能遇到过数据数据例行化的问题。假设你遇到了如下场景： 你是一个机器学习攻城狮，每隔15分钟从源数据服务器获取数据，对数据进行业务处理。那么有一个问题，如何保证你wget到的数据是完整的呢？ 这个问题比较简单，只需要源数据服务器每次生成数据之后，生成一个md5的校验文件，当你把数据拉取下来之后，进行md5校验即可。 然后有一天，你看到业务告警，经过排查，你发现原来自己wget到的数据和源数据服务器上的数据不一致。这是怎么回事呢？ 经过分析相应日志，你发现原因是这样的：你每隔15分钟获取数据，在某一个时刻点，网络出现了延迟或者机器性能问题，导致原来可以在15:07时刻就可以wget到的数据，现在15:16还没有完全wget下来，然后源数据服务器又开始产生新的数据覆盖了上一份数据。 你思考了一会，发现有如下方案。1，使用锁机制。即每次从源服务器读取数据的时候，首先给要读取的数据加锁，当读取完之后解锁。这可以通过增删一个文件实现，即lock_filename.txt。没错，这是一种比较简单的方式，但是只适用于源数据和你的业务机制在相同机器上。 2，可以在源数据每生成一份数据的时候，加一个时间戳。例如，源数据产生的时间是15:00，然后对文件名加一个时间戳，即filename_201810221500.txt。当你在15：15获取数据的时候，date命令获取15分钟前的时间戳，拼接文件名，进行数据获取。 由于本人遇到的场景是同机数据获取，所以就这种情况继续进行分析。 本人通过shell脚本进行数据获取，shell脚本中调用了Python脚本。在每个时刻00，15，30，45分钟调用shell脚本。有一天线上业务告警，这是怎么回事呢？ 经过排查，发现获取的数据少了。通过打印日志，发现在每个小时00分钟调用的shell脚本需要在22分钟才结束，而其它三个时刻的脚本调用均未发生延时情况。经过分析，发现是因为shell脚本中的Python脚本发生了延时调用。 Python脚本延时调用和数据变少有什么关系呢？shell脚本源代码如下： 1234&gt; #shell脚本&gt; check_fileMD5()&gt; python f.py #Python调用延迟执行 (1)&gt; 12345&gt; # f.py&gt; lock_file()&gt; getData()&gt; unlock_file()&gt; (1)Python脚本发生了延迟调用，但是此时已经对文件md5进行了校验。所以，当下一个时刻点15分钟的时候新数据会覆盖了旧数据，此时00分钟调用了shell卡在了Python脚本调用这里，但是已经无法再次调用check_fileMD5()检查源数据的完整性，所以导致了读写冲突，数据变少了。 至于Python脚本为什么会延时调用呢？这是因为在0-15分钟有别的Python脚本占用了Python解释器，导致Python脚本无法及时获取Python解释器。","tags":[{"name":"例行化","slug":"例行化","permalink":"http://aeyoo.net/tags/例行化/"}]},{"title":"poj1753_FlipGame_状态压缩_BFS_位运算","date":"2018-10-18T12:09:39.000Z","path":"2018/10/18/poj1753-Flip-Game-状态压缩-BFS-位运算/","text":"今天看了poj1753，想了半天没有思路，就去看了一下题解《POJ 1753 Flip Game（状态压缩+BFS）解题报告》。这个题如果没之前没遇到过类型题的话，很难想到方法。先上题。 题目描述 如图，题目描述如下：给定4*4的一个棋盘，并给定某一状态的黑白棋子状态和翻转规则，问最少经过多少步可以翻转到全黑或者全白？ 翻转规则如下：若选定一个坐标 (i,j) 的棋子进行翻转，那么该棋子邻边（上下左右）的棋子也一并会翻转（也就是共5个棋子进行了翻转）。黑色变白色，白色变黑色。 思路主要讲一下解题思路，至于状态压缩的细节，以及如何进行位运算，作者blue的题解报告《POJ 1753 Flip Game（状态压缩+BFS）解题报告》已经介绍地很详细了，就不再重复造轮子了。 之所以一开始没有想到解题方法，是因为根本没有往bfs方向上想，因为如果进行状态遍历的话，时间复杂度是 $O(n^n)&#x3D;O(16^{16})$，感觉会爆。不过看网上的题解说这个复杂度不大，囧,一看我就是小白。 首先将初始状态加入队列q; … (1) 若q不为空；则(3) …(2) 从队列中取出元素，依次翻转16个位置的棋子。如果翻转位置i的棋子之后，达到最终状态，则结束算法，返回步数。否则将该状态加入队列q，并翻转位置i+1,判断是否达到最终状态，直至遍历完16个位置。返回(2) …(3) 我咋感觉描述地这么晦涩。。。直接附上原作者代码吧。。明晚再ac替换代码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586#include &lt;cstdio&gt;#include &lt;queue&gt;using namespace std;const int size = 4;const int dir_num = 4;struct info &#123; int value; // 状态值 int step; // 步数&#125;;int dir[dir_num][2] = &#123; &#123;-1, 0&#125;, &#123;0, 1&#125;, &#123;1, 0&#125;, &#123;0, -1&#125;, &#125;;int pos[size*size]; // 16 种翻转状态bool vis[1&lt;&lt;(size*size)]; //标记某状态是否已出现过// 判断某个位置是否在棋盘内bool Judge(int x, int y) &#123; if(x&gt;=0 &amp;&amp; x&lt;size &amp;&amp; y&gt;=0 &amp;&amp; y&lt;size) return true; else return false;&#125;// 预处理 16 种翻转状态void Initialize() &#123; for(int i=0; i&lt;size; ++i) &#123; for(int j=0; j&lt;size; ++j) &#123; // i*size + j 即编号 int value = 1 &lt;&lt; (i*size + j); for(int k=0; k&lt;dir_num; ++k) &#123; int next_x = i+dir[k][0]; int next_y = j+dir[k][1]; if(Judge(next_x, next_y)) // 加上 1&lt;&lt;(编号) 即可将此位置设置为1 value += 1 &lt;&lt; (next_x*size + next_y); &#125; pos[i*size+j] = value; &#125; &#125;&#125;int BFS(int value) &#123; queue&lt;info&gt; q; info s = &#123;value, 0&#125;; q.push(s); vis[s.value] = true; while(!q.empty()) &#123; info f = q.front(); q.pop(); // 盘面全黑 (0) 或全白 (2^16-1) 时结束，返回步数 if(f.value==0 || f.value==(1&lt;&lt;(size*size))-1) return f.step; // 搜索全部 16 个位置 for(int i=0; i&lt;size*size; ++i) &#123; // 通过异或运算得到翻转后的状态 info next = &#123;f.value^pos[i], f.step+1&#125;; if(!vis[next.value]) &#123; q.push(next); vis[next.value] = true; &#125; &#125; &#125; return -1; // 无法到达目标状态，返回 -1&#125;int main(int argc, char const *argv[]) &#123; Initialize(); char str[5]; int value = 0; for(int i=0; i&lt;size; ++i) &#123; scanf(\"%s\", str); // 计算起始状态的值 for(int j=0; j&lt;size; ++j) &#123; if(str[j] == 'w') value += 1 &lt;&lt; (i*size + j); &#125; &#125; int ans = BFS(value); if(ans &gt;= 0) printf(\"%d\\n\", ans); else printf(\"Impossible\\n\"); return 0;&#125; MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} });","tags":[{"name":"状态压缩","slug":"状态压缩","permalink":"http://aeyoo.net/tags/状态压缩/"},{"name":"BFS","slug":"BFS","permalink":"http://aeyoo.net/tags/BFS/"},{"name":"位运算","slug":"位运算","permalink":"http://aeyoo.net/tags/位运算/"}]},{"title":"word2vec思想概述","date":"2018-10-17T14:55:12.000Z","path":"2018/10/17/word2vec思想概述/","text":"今天了解了一下word2vec这个工具，之前用过但是没怎么细究，今天回顾整理一下。 关于word2vec的介绍，我觉得这篇文章《理解Word2Vec之Skip-Gram模型》讲的不错，主要介绍了word2vec的大概思想，以及实现的tricks。这篇文章后面附有代码，本人是先看代码，没看懂的才看文章，感觉豁然开朗。 此外，网上还有一篇《word2vec中的数学》，从理论角度阐述了word2vec背后的数学原理。这篇文章的作者的博客在这里。 简单地说，word2vec就是给定一个语料库，通过特定的神经网络模型+滑动窗口的思想去学习得到代表每个单词的向量。 word2vec是Tomáš Mikolov和其同事一起做的工作，涉及两篇论文。 Efficient Estimation of Word Representations in Vector Space.pdf，这篇论文提出了word2vec模型 Distributed Representations of Words and Phrases and their Compositionality.pdf，这篇论文提出了针对word2vec的两种优化方式，层次softmax和负采样（nce loss的简化版）。需要注意的是负采样和nce是不同的，负采样是nce的简化版，参见《(35 封私信 &#x2F; 70 条消息) nce loss 与 sampled softmax loss 到底有什么区别？怎么选择？ - 知乎》。 参考 Noise Contrastive Estimation 前世今生——从 NCE 到 InfoNCE - 知乎 理解 Word2Vec 之 Skip-Gram 模型 - 知乎 nlp&#x2F;word2vec_中的数学原理详解.pdf at master · renpengcheng-github&#x2F;nlp https://github.com/NELSONZHAO/zhihu/blob/master/skip_gram/Skip-Gram-English-Corpus.ipynb word2vec 中的数学原理详解 - peghoty - 博客园 (35 封私信 &#x2F; 67 条消息) 求通俗易懂解释下nce loss？ - 知乎 https://www.tensorflow.org/api_docs/python/tf/nn/nce_loss python - Understanding tf.nn.nce_loss() in tensorflow - Stack Overflow 论文｜万物皆可Vector之Word2vec：2个模型、2个优化及实战使用 - 知乎 (35 封私信 &#x2F; 70 条消息) nce loss 与 sampled softmax loss 到底有什么区别？怎么选择？ - 知乎","tags":[{"name":"NLP","slug":"NLP","permalink":"http://aeyoo.net/tags/NLP/"},{"name":"word2vec","slug":"word2vec","permalink":"http://aeyoo.net/tags/word2vec/"}]},{"title":"L2范数浅谈","date":"2018-10-15T13:25:04.000Z","path":"2018/10/15/L2范数浅谈/","text":"机器学习的求解本质上是一个优化问题的求解，其方式一般通过构造损失函数，对损失函数进行求解，进而确定模型参数的过程。为了防止模型过拟合，或者使得模型更稳定，经常使用正则化技术。今天介绍一下正则化技术中的L2范数。 许多正则化技术通过对损失函数（也叫目标函数）J 添加一个参数范数惩罚 $\\Omega(\\theta)$ 限制模型的学习能力。假设正则化后的目标函数为 J ： $$ J(\\theta, X, ,y) &#x3D; J(\\theta; X, y) + \\alpha(\\Omega) \\tag{1.1}$$ 其中，$\\theta\\in[0, \\infty]$ 是衡量范数惩罚项 $\\Omega$ 对目标函数 $J(\\theta, X, ,y)$ 相对贡献的超参数。$\\theta$ 为0表示没有正则化，$\\theta$ 越大，对目标函数的惩罚越大。 此处需要注意的是，则神经网络中，参数包含每一层仿射变换的权重和偏置，通常我们只对权重正则化而非偏置，原因是精确拟合偏置所需的数据量比拟合权重少得多。每个权重会指定两个变量如何相互作用，而每个偏置控制一个单变量【尚待考究】，这意味着我们不对其进行正则化也不会导致太大的方差。另外，正则化偏置参数可能会导致模型明显的欠拟合。 L2正则化L2正则化（也叫岭回归 或吉洪诺夫正则），即 $\\Omega(\\theta)&#x3D;\\frac{1}{2}||w||^2_2$ ，通过对目标函数添加L2范数，使得权重更加接近原点。在这里，我们通过研究正则化后的目标函数的梯度，洞察一些权重衰减的正则化表现。为了简便，假设没有偏置，因为 $\\theta$ 就是$w$。目标函数如下： $$J(\\theta; X, y) &#x3D; \\frac{\\theta}{2}w^Tw + J(w; X, y) \\tag{1.2}$$ 与之对应的梯度为 $$\\nabla_wJ(w; X, y) &#x3D; \\alpha w + \\nabla_wJ(w; J, y) \\tag{1.3}$$ 使用单步梯度下降更新权重， $$w\\leftarrow w - \\epsilon(\\alpha w + \\nabla_wJ(w; X, y)) \\tag{1.4}$$ 稍微整理一下： $$w\\leftarrow(1-\\epsilon\\alpha)w-\\epsilon\\nabla_wJ(w; X,y) \\tag{1.5}$$ 可以看到，加入正则化之后学习规则的变化，即在每次更新梯度之前先收缩权重向量（将权重向量乘以一个常数因子）。 进一步分析，令 $w^*$ 为 未正则化 的目标函数取得最小误差的权重向量，即$w^*&#x3D;argmin_wJ(w)$。我们在$w^*$的邻域做二次近似（二阶泰勒展开），如果目标函数确实是二次的，则该近似可以看作是完美的。近似的 $\\hat{J}(\\theta)$ 如下： $$ \\hat{J}(\\theta) &#x3D; J(w^*)+\\frac{1}{2}(w-w^*)^TH(w-w^*) \\tag{1.6} $$ 其中，H是J在$w^*$处关于w的Hessian矩阵。因为$w^*$被定义为最优，即梯度消失为0，所以该二次项中没有一阶项。同样地，因为$w^*$是J的一个最优点，可以得到H是半正定的结论。 当 $\\hat{J}$ 取得最小时，其梯度 $$\\nabla_w\\hat{J}(w)&#x3D;H(w-w^*) \\tag{1.7}$$ 为0。 上文研究的是未正则化的情况。为了研究正则化带来的影响，我们在$(1.7)$中添加正则化项的梯度。设最小化正则化后的损失函数为 $\\hat{J}$，使用变量 $\\tilde{w}$ 表示此时的最优点： $$ \\alpha\\tilde{w} + H(\\tilde{w} - w^*) &#x3D;0 \\tag{1.8}$$ $$(H + \\alpha I)\\tilde{w} &#x3D; Hw^* \\tag{1.9}$$ $$ \\tilde{w} &#x3D; (H + \\alpha I)^{-1}Hw^* \\tag{1.10}$$ 当 $\\alpha$ 趋近于0时，正则化的解 $\\tilde{w}$ 会趋近于 $w^*$。当 $\\alpha$ 增加时，因为 $H$ 是实对称的，所以可以将其分解为一个对角矩阵 A 和一组特征向量的标准正交基 Q，并有 $ H&#x3D;QAQ^T$，将其带入$(1.10)$，有： $$\\tilde{w} &#x3D; (QAQ^T + \\alpha I)^{-1}QAQ^Tw^* \\tag{1.11}$$ $$\\tilde{w} &#x3D; [(Q(A + \\alpha I)Q^T]^{-1}QAQ^T w^* \\tag{1.12}$$ $$\\tilde{w} &#x3D; (Q(A + \\alpha I)^{-1}AQ^T w^* \\tag{1.13}$$ 注：对角矩阵的逆为矩阵各元素变为倒数之后的矩阵。 可以看到正则化项的效果是沿着由 H 的特征向量所定义的轴缩放 $w^*$。具体来说，就是根据 $\\frac{\\lambda _i}{\\lambda _i+\\alpha}$ 因子缩放与H第i个特征对齐的 $w^*$ 的分量。 沿着H特征值较大的方向（如$\\lambda \\gg \\alpha$）正则化的影响较小。而 $\\lambda \\ll \\alpha$ 的分量将会收缩到几乎为0。 通过对 $(1.13)$ 的分析，我们可以知道只有在显著减少目标函数的方向上的参数会保留相对完好。在无助于目标函数减小的方向(H矩阵较小的特征值)上改变参数不会显著增加梯度。这种不重要方向对应的分量会在训练过程中因正则化而衰减掉。 以上讨论了正则化对通用的二次代价函数的影响。接下来以线性回归为例进行阐述。 线性回归的代价函数是平方误差之和： $$(Xw-y)^T(Xw-y) \\tag{1.14}$$ 解析解为： $$w&#x3D;(X^TX)^{-1}X^Ty \\tag{1.15}$$ 添加 L2 正则化项之后，目标函数变为： $$(Xw-y)^T(Xw-y)+\\frac{1}{2}\\alpha w^Tw \\tag{1.16}$$ 解析解为： $$w&#x3D;(X^TX+\\alpha I)^{-1}X^Ty \\tag{1.17}$$ 式(1.15)中的矩阵 $X^TX$ 与协方差矩阵 $\\frac{1}{m}X^TX$成正比。L2正则项将这个矩阵替换为$X^TX+\\alpha I$，与之不同的是**对角线加了$\\alpha$**。这个矩阵的对角线对应了每个输入特征的方差。我们可以看到，L2正则化能让学习算法感知具有较高方差的输入特征$x_i$，并且其特征的权重将会收缩。模型的抗扰动能力也比较强。 参考文献： 花书：深度学习 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} });","tags":[{"name":"L2范数，范数","slug":"L2范数，范数","permalink":"http://aeyoo.net/tags/L2范数，范数/"}]},{"title":"Linux性能管理命令","date":"2018-10-15T13:25:04.000Z","path":"2018/10/15/Linux性能管理命令/","text":"本文整理一下Linux常用的性能管理命令，仅保留了个人工作中会用到的内容。内容均来源于网络，详见参考文献。 df 命令df命令用于显示磁盘分区上的可使用的磁盘空间。默认显示单位为KB。可以利用该命令来获取硬盘被占用了多少空间，目前还剩下多少空间等信息。 参数： -a 全部文件系统列表 -h 方便阅读方式显示 -k或–kilobytes：指定区块大小为1024字节； -m或–megabytes：指定区块大小为1048576字节； –block-size&#x3D;&lt;区块大小&gt;：以指定的区块大小来显示区块数目； -H或–si：与-h参数相同，但在计算时是以1000 Bytes为换算单位而非1024 Bytes； -i 显示inode信息 –sync：在取得磁盘使用信息前，先执行sync指令； –no-sync：在取得磁盘使用信息前，不要执行sync指令，此为预设值； -P或–portability：使用POSIX的输出格式； -T或–print-type：显示文件系统的类型； –help：显示帮助； –version：显示版本信息。 如果你使用df命令的话，你应该会看到文件系统 tmpfs，它是类Unix系统上暂存档存储空间的常见名称，通常以挂载文件系统方式实现，并将数据存储在易失性存储器而非永久存储设备中。和RAM disk的概念近似，但后者会呈现出具有完整文件系统的虚拟磁盘[4]。 所有在tmpfs上存储的数据在理论上都是暂时借放的，那也表示说，文件不会创建在硬盘上面。一旦重启，所有在tmpfs里面的数据都会消失不见。理论上，存储器使用量会随着tmpfs的使用而时有增长或消减。目前有许多Unix的发行版都有激活tmpfs，默认是把它以共享存储器的方式用在系统的&#x2F;tmp目录底下。这个特征在 Unix 上面会表现像是[4]： 12Filesystem Size Used Avail Use% Mounted ontmpfs 256M 688K 256M 1% /tmp du 命令du命令用来查看文件和目录的大小。 参数 -a或-all 显示目录中个别文件的大小。 -b或-bytes 显示目录或文件大小时，以byte为单位。 -c或–total 除了显示个别目录或文件的大小外，同时也显示所有目录或文件的总和。 -k或–kilobytes 以KB(1024bytes)为单位输出。 -m或–megabytes 以MB为单位输出。 -s或–summarize 仅显示总计，只列出最后加总的值。 -h或–human-readable 以K，M，G为单位，提高信息的可读性。 -L&lt;符号链接&gt;或–dereference&lt;符号链接&gt; 显示选项中所指定符号链接的源文件大小。 -S或–separate-dirs 显示个别目录的大小时，并不含其子目录的大小。 -H或–si 与-h参数相同，但是K，M，G是以1000为换算单位。[10] sync 命令sync命令用于强制被改变的内容立刻写入磁盘，更新超块信息。 在Linux&#x2F;Unix系统中，在文件或数据处理过程中一般先放到内存缓冲区中，等到适当的时候再写入磁盘，以提高系统的运行效率。sync命令则可用来强制将内存缓冲区中的数据立即写入磁盘中。用户通常不需执行sync命令，系统会自动执行update或bdflush操作，将缓冲区的数据写 入磁盘。只有在update或bdflush无法执行或用户需要非正常关机时，才需手动执行sync命令[2]。 top 命令top命令用来显示Linux进程的资源实时占用情况，可以用该命令查看Linux的内存使用情况，但是查出来的内存一般比较高，这和Linux的内存分配机制有关。 在Linux中，有两个缓存内存 buffers和cached，在Linux系统下的buffer指的是磁盘写缓存，而cache则指的是磁盘读缓存。 而这两块是为了提高系统效率而分配的内存，在内存富余的时候，操作系统将空闲内存利用起来，而有内存需求时，系统会释放这部分的内存供应用程序使用[6]。 这样，真正应用程序可用的内存就是free+buffer+cache，上面的例子就是：52068k + 112620k + 1831700k &#x3D; 1996388k 而已用内存则是used-buffer-cache，上面的例子为：4034428k - 112620k - 1831700k &#x3D; 2090108k 还可以使用free -m 查看某一时刻的内存使用情况。 free 命令free命令可以显示当前系统未使用的和已使用的内存数目，还可以显示被内核使用的内存缓冲区[9]。 参数 -b：以Byte为单位显示内存使用情况； -k：以KB为单位显示内存使用情况； -m：以MB为单位显示内存使用情况； -o：不显示缓冲区调节列； -s&lt;间隔秒数&gt;：持续观察内存使用状况； -t：显示内存总和列； -V：显示版本信息。 按进程的CPU使用率排序。运行top命令后，键入大写P。 按进程的内存使用率排序。运行top命令后，键入大写M。 实例： 12345free -m total used free shared buffers cachedMem: 2016 1973 42 0 163 1497-/+ buffers/cache: 312 1703Swap: 4094 0 4094 第一部分Mem行解释： total：内存总数； used：已经使用的内存数； free：空闲的内存数； shared：当前已经废弃不用； buffers Buffer：缓存内存数； cached Page：缓存内存数。 关系：total &#x3D; used + free 第二部分(-&#x2F;+ buffers&#x2F;cache)解释: (-buffers&#x2F;cache) used内存数：第一部分Mem行中的 used – buffers – cached (+buffers&#x2F;cache) free内存数: 第一部分Mem行中的 free + buffers + cached 可见-buffers&#x2F;cache反映的是被程序实实在在吃掉的内存，而+buffers&#x2F;cache反映的是可以挪用的内存总数。 第三部分是指交换分区[9]。 linux下查看最消耗CPU、内存的进程1 CPU占用最多的前10个进程： 1ps auxw|head -1;ps auxw|sort -rn -k3|head -10 2 内存消耗最多的前10个进程 1ps auxw|head -1;ps auxw|sort -rn -k4|head -10 3 虚拟内存使用最多的前10个进程 [5] 1ps auxw|head -1;ps auxw|sort -rn -k5|head -10p jps jps是jdk提供的一个查看当前java进程的小工具，全称是 Java Virtual Machine Process Status Tool。 q：仅输出VM标识符，不输出类名，JAR文件名，main方法的参数 m：输出main方法的参数 l：输出主类的完整包名，或者jar文件的完整路径 v：输出jvm参数 V：输出通过flags文件传递给JVM的参数 使用示例： 1jps -m | grep &quot;para_name&quot; | wc -l linux下查找文件和目录在指定目录下递归查找包含“abc”的文件： 1grep -Ri ~/bin -e &quot;abc&quot; grep命令参数： R - 表示递归搜索指定的目录 i - 表示忽略大小写区别 e - 指定要用作搜索模式的短语 d - 指定分隔符 f - 设置要打印的字段 查找目录： 1find /（查找目录） -name &apos;查找关键字&apos; -type d 查找文件： 1find /（查找目录） -name &apos;查找关键字&apos; -print 参考 http://man.linuxde.net/df http://man.linuxde.net/sync 每天一个linux命令（33）：df 命令 https://zh.wikipedia.org/wiki/Tmpfs linux下查看最消耗CPU、内存的进程 Linux查看物理内存占用率 linux下使用free命令查看实际内存占用（可用内存） 记一次Linux系统内存占用较高得排查 http://man.linuxde.net/free 每天一个linux命令（34）：du 命令 5个命令行工具，可在Linux中快速查找文件 linux 查找目录或文件","tags":[{"name":"linux性能管理","slug":"linux性能管理","permalink":"http://aeyoo.net/tags/linux性能管理/"}]},{"title":"poj1664_放苹果_dp","date":"2018-10-14T06:10:59.000Z","path":"2018/10/14/poj1664-放苹果-dp/","text":"把M个同样的苹果放在N个同样的盘子里，允许有的盘子空着不放，问共有多少种不同的分法？（用K表示）5，1，1和1，5，1 是同一种分法。 Input 第一行是测试数据的数目t（0 &lt;&#x3D; t &lt;&#x3D; 20）。以下每行均包含二个整数M和N，以空格分开。1&lt;&#x3D;M，N&lt;&#x3D;10。 Output 对输入的每组数据M和N，用一行输出相应的K。 Sample Input 17 3 Sample Output 8 题解该题是典型的dp问题。需要找到子问题。dp[m][n] 表示把m个苹果放到n个盘子里的方案个数，有两种情况。 if m &lt; n ; dp[m][n] &#x3D; dp[m][m]; 因为苹果和盘子是相同的，所以将m个苹果放到n个盘子和放到m个盘子的方案数是一样的。 if m &gt;&#x3D; n ; dp[m][n] &#x3D; dp[m][n-1]+dp[m-n][n] 表示，m个苹果放到n个盘子里有两种情况： 一个盘子为空，m个苹果放到n-1个盘子； 将n个苹果分别放到n个盘子，然后m-n个苹果放到n个盘子里。 注意 dp[0][n] &#x3D; dp[1][n] &#x3D; dp[m][1] &#x3D; dp[m][0] &#x3D; 1 从 i&#x3D;2, j&#x3D;2 开始遍历，可以避免将 dp[0][n] 和 dp[m][0] 的值设置为 0 ，因为设置为 dp[0][n] 是不正确的。eg, dp[2][2] &#x3D; dp[0][2] + dp[2][1]，此处，dp[0][2] 表示将 2 个苹果分别放到 2 个盘子，每个盘子一个。如此，dp[0][2] &#x3D; 1 。 代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243#include&lt;iostream&gt;using namespace std;int dp[12][12];int main()&#123; int t,m,n; while(cin&gt;&gt;t) &#123; for(int k=0;k&lt;t;k++) &#123; dp[1][1]=1; cin&gt;&gt;m&gt;&gt;n; for(int i=0;i&lt;=m;i++) dp[i][0]=1; for(int j=0;j&lt;=n;j++) dp[0][j]=1; for(int i=0;i&lt;=m;i++) dp[i][1]=1; for(int j=0;j&lt;=n;j++) dp[1][j]=1; for(int i=2;i&lt;=m;i++) //此处从i=2,j=2开始遍历比较合理 &#123; for(int j=2;j&lt;=n;j++) &#123; if(i&lt;j) &#123; dp[i][j]=dp[i][i]; &#125;else &#123; dp[i][j]=dp[i][j-1]+dp[i-j][j]; &#125; &#125; &#125; cout&lt;&lt;dp[m][n]&lt;&lt;endl; &#125; &#125; return 0;&#125;","tags":[{"name":"dp","slug":"dp","permalink":"http://aeyoo.net/tags/dp/"}]},{"title":"记录一下接下来要做的","date":"2018-10-13T16:37:20.000Z","path":"2018/10/14/记录一下接下来要做的/","text":"有一些需要做的，先记录一下。 poj刷题200道 线性回归，牛顿法，拟牛顿法的实现 矩阵分解 L1，L2范数以及L1范数为何有有效稀疏解 FM kmp，字符串比较，深搜总结 FTRL,FOBOS,LDA模型 推荐系统基础 马尔可夫链 LDA主题模型 机器学习计算理论 概率论和组合数学 哈希，以及平均比较次数 预计2019.1.20刷完 附题目： 水题：1000 1003 1006 1005 1007 1008 1012 2388 2027 2262 2046 1046 2000 1028 2017 2479 1503 1298 1068 1552 2105 3094 1517 1658 2159 2109 3673 3030 3062 1080 2390 2301 1519 2656 1657 1579 1504 2636 1922 2350 2013 3980 2521 2602 2578 2509 1477 1543 2840 3100 2389 1844 2593 2141 1565 1035 3438 3589 2551 暴力：2909 1656 思考题：1050 1013 1019 1083 2965 2665 1032 麻烦题：1001 2136 3299 模拟题：1207 1017 1218 数据结构： STL：1002 2503 2081 2418 1256 1833 线段树：3468 3264 2299 2528 2823 2104 2777 树状数组：2352 2828 2155 3321 3067 1195 并查集：1182 2524 1611 1703 2492 1308 2236 1988 哈希：3349 1200 优先队列：3253 栈：1363 字典树：2513 3630 深搜：1011 1753 1979 2488 1321 2386 2255 2362 2676 1562 广搜：3278 1077 1915 3126 1426 2243 2251 贪心：1328 1042 动态规划：1088 1664 1163 1159 1014 1458 2533 3624 1936 1742 3176 1276 1160 1018 1157 1141 2411 1185 1065 1837 1015 二分法：3273 数学：1316 2739 2140 1338 1401 1423 3070 1045 1953 3233 1663 数论：1061 3006 1811 博弈：1067 图论： 最小生成树：1258 2485 2253 2421 1251 1679 1789 2728 最短路：1125 3259 1062 2387 1201 3159 1860 2240 3268 2449 网络流：1273 1459 3469 1274 1149 强连通分量：2186 二分匹配：3041 1469 最小费用流：2195 其他：1094 1330 字符串： KMP：3461 2752 后缀数组：2774 1743 几何：1118凸包：1113 2187","tags":[{"name":"计划","slug":"计划","permalink":"http://aeyoo.net/tags/计划/"}]},{"title":"poj1011_sticks","date":"2018-10-13T13:58:15.000Z","path":"2018/10/13/poj1011-sticks/","text":"最近计划好好刷一下poj上的题，打印了一下要刷的题集。决定先从深搜开始。第一道题是sticks，之前写过是参考网上的。今天又写了一边，权当回顾。 题目：给定n个等长木棒，将其随机断开得到m个短木棒(m&gt;n)。现给定m个短木棒的长度，求原始木棒的最短长度len。 poj1011题目链接 这是一道dfs题目，比较经典。 主要思路 就是首先将所有的木棒按照长度做一个递减排序。令len的范围是 [ 短木棒的最长长度, 短木棒的长度和 ]。给定一个len值，进行dfs遍历。临界条件 是已组成的木棒数目 &#x3D; 原始木棒的个数n。 注意 对于dfs题目，考虑使用全局变量和结构体进行数据的存储，比较方便。 对于循环输出，记得记得清空全局变量。 github默认讲tab解析为8个空格。所以为了美观，尽量将所用编辑器的tab设置为4个空格，或者禁用tab字符 (eg dev c++)。 个人代码如下。文末附原作者代码，注释比较详细。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667#include&lt;iostream&gt;#include&lt;algorithm&gt;using namespace std;struct Stick&#123; int len; bool vis;&#125;;Stick sticks[67]; int sum=0,n=0,total=0,k=0;bool cmp(Stick a,Stick b)&#123; return a.len&gt;b.len;&#125;bool dfs(int num,int len,int pos)&#123; if(num==total) return true; for(int i=pos+1;i&lt;n;i++) &#123; if(sticks[i].vis) continue; if(len+sticks[i].len==k) &#123; sticks[i].vis=true; if(dfs(num+1,0,-1)) return true; sticks[i].vis=false; return false; &#125;else if(len+sticks[i].len&lt;k) &#123; sticks[i].vis=true; if(dfs(num,len+sticks[i].len,i)) return true; sticks[i].vis=false; if(len==0) return false; while(i+1&lt;n &amp;&amp; sticks[i].len==sticks[i+1].len) i++; &#125; &#125; return false;&#125; int main()&#123; while(cin&gt;&gt;n &amp;&amp; n) &#123; sum=0; for(int i=0;i&lt;n;i++) &#123; cin&gt;&gt;sticks[i].len; sticks[i].vis=false; sum+=sticks[i].len; &#125; sort(sticks,sticks+n,cmp); for(k=sticks[0].len;k&lt;=sum;k++) &#123; if(sum%k!=0) continue; total=sum/k; if(dfs(1,0,-1)) //第一个参数是1的原因是如果当前n-1个木棒可以拼接成功的话，那么第n个木棒一定可以拼接成功。 &#123; cout&lt;&lt;k&lt;&lt;endl; break; &#125; &#125; &#125; return 0;&#125; 因原作者代码注释比较详细，此处就不详细介绍了，直接放代码。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879#include &lt;iostream&gt;#include &lt;algorithm&gt;using namespace std;//total能组成的木棒的组数,l:组成的木棒的长度int total,l;//num:输入的整数，sum：总长度int num,sum;typedef struct&#123; int length;//木棒的长度 bool mark;//木棒是否被使用过&#125;Sticks;Sticks sticks[70];bool cmp(Sticks a,Sticks b)&#123; return a.length&gt;b.length;&#125;//s 已组成的木棒数目,len已经组成的长度，pos搜索的木棒的下标的位置int dfs(int s,int len,int pos)&#123; if(s==total)return 1; for(int i=pos+1;i&lt;num;i++) &#123; //如果这个木棒已经用过，则继续下一根 if(sticks[i].mark)continue; if(len+sticks[i].length == l) &#123; sticks[i].mark = true; if(dfs(s+1,0,-1))return true; sticks[i].mark = false; return false; &#125;else if(sticks[i].length+len&lt;l)&#123; sticks[i].mark = true; if(dfs(s,len+sticks[i].length,i)) return true; sticks[i].mark = false; //剪枝：如果当前搜索时，前边的长度为0，而第一根没有成功的使用， //说明第一根始终要被废弃，所以这种组合必定不会成功 //此处的剪枝必须有，因为这里的剪枝会节省很多的无用搜索， //我试了一下，此处剪枝省去就会超时的。。。。 if(len==0)return false; //剪枝：如果当前和上一次搜到的木棒是一样长的则没必要再搜一次了 while(sticks[i].length==sticks[i+1].length)i++; &#125; &#125; return false;&#125;int main()&#123; while(cin&gt;&gt;num&amp;&amp;num!=0) &#123; sum = 0;//标记为0 for(int i = 0; i &lt; num; i++) &#123; cin&gt;&gt;sticks[i].length; sum += sticks[i].length; sticks[i].mark = false; &#125; //将木棒按照长度从长到短的顺序排序 sort(sticks,sticks+num,cmp); //从木棒的最长的那根开始搜索，因为最小的组合也会大于等于最长的那根 for(l = sticks[0].length; l &lt;= sum; l++) &#123; //剪枝一：如果不能被整除说明不能组成整数根木棒，搜下一个 if(sum%l!=0)continue; total = sum / l;//得到木棒总数目 if(dfs(1,0,-1)) &#123; cout&lt;&lt;l&lt;&lt;endl; break; &#125; &#125; &#125; return 0;&#125;","tags":[{"name":"dfs","slug":"dfs","permalink":"http://aeyoo.net/tags/dfs/"},{"name":"递归","slug":"递归","permalink":"http://aeyoo.net/tags/递归/"}]},{"title":"hexo主题添加数学公式 & 修改主题css配置","date":"2018-10-12T13:37:29.000Z","path":"2018/10/12/hexo主题添加数学公式/","text":"添加数学公式对于BlueLake主题，网上大多数添加数学公式的方法没有作用。亲测在需要添加数学公式的文章末尾加入以下代码，即起作用。 首先安装相应库。 1npm install hexo-math --save 然后在文章末尾添加如下代码。 123456789&lt;script type=\"text/x-mathjax-config\"&gt;MathJax.Hub.Config(&#123;tex2jax: &#123;inlineMath: [['$','$'], ['\\\\(','\\\\)']]&#125;&#125;);&lt;/script&gt;&lt;script type=\"text/javascript\" src=\"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\"&gt;&lt;/script&gt; 例如 $$A_1 &#x3D; 5 $$ $$\\frac{a}{b}$$ $$x&#x3D;\\frac{-b\\pm\\sqrt{b^2-4ac}}{2a}$$ $$\\frac{\\partial u}{\\partial t}&#x3D; h^2 \\left( \\frac{\\partial^2 u}{\\partial x^2} +\\frac{\\partial^2 u}{\\partial y^2} +\\frac{\\partial^2 u}{\\partial z^2}\\right)$$ 行内公式展示 $c &#x3D; b + c$ MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} }); 修改主题css配置配置文件是 xxx&#x2F;blog&#x2F;themes&#x2F;BlueLake&#x2F;source&#x2F;css&#x2F;style.styl，修改对应配置即可。如博客字体类型，大小等。详见《Hexo博客之改字体》。 参考 如何在Hexo博客中插入数学公式 [首选参考] hexo中插入数学公式","tags":[{"name":"hexo","slug":"hexo","permalink":"http://aeyoo.net/tags/hexo/"}]},{"title":"矩阵分解在推荐中的应用","date":"2018-07-13T07:20:29.000Z","path":"2018/07/13/矩阵分解在推荐中的应用/","text":"在推荐系统中，一个比较核心的问题是，如何根据User和Item组成的评分矩阵（如果一个user对一个item没有历史行为，则该值未知），对矩阵中的未知评分做出预测。矩阵分解便是用来解决该问题的。 1. SVD奇异值分解传统的SVD用于推荐存在一个很大的问题，SVG要求矩阵是稠密的（矩阵中所有位置的值都是已知的），所以不能直接用于我们求解未知评分。 传统SVD采用的方法是对评分矩阵中的缺失值进行简单的补全，比如用全局平均值或者用用户物品平均值补全，得到补全后的矩阵。接着可以用SVD分解并降维 **[最后如何得到未知评分的预测？]**。 2. FunkSVDFunkSVD是在传统SVD面临计算效率问题时提出来的，既然将一个矩阵做SVD分解成3个矩阵很耗时，同时还面临稀疏的问题，那么我们能不能避开稀疏问题，同时只分解成两个矩阵呢？可以的，使用FunkSVD。 FunkSVD将矩阵M(m*n)分解为P(m*k)和Q(k*n)。使用线性回归的思想，我们的目标是让用户的评分和用矩阵乘积得到的评分残差尽可能的小，也就是说，可以用均方差作为损失函数，来寻找最终的P和Q。","tags":[{"name":"MF","slug":"MF","permalink":"http://aeyoo.net/tags/MF/"},{"name":"RMF","slug":"RMF","permalink":"http://aeyoo.net/tags/RMF/"}]},{"title":"scrapy爬取博客园文章","date":"2018-04-15T06:28:38.000Z","path":"2018/04/15/scrapy爬取博客园文章/","text":"本文介绍如何使用scrapy爬取博客园的文章。 具体过程： 创建一个Scrapy项目 定义提取的Item 编写爬取网站的 spider 并提取 Item 编写 Item Pipeline 来存储提取到的Item(即数据) 创建项目在开始爬取之前，您必须创建一个新的Scrapy项目。 进入您打算存储代码的目录中，运行下列命令: 1scrapy startproject tutorial 该命令将会创建包含下列内容的 tutorial 目录: 12345678910tutorial/ scrapy.cfg tutorial/ __init__.py items.py pipelines.py settings.py spiders/ __init__.py ... 这些文件分别是: scrapy.cfg: 项目的配置文件 tutorial&#x2F;: 该项目的python模块。之后您将在此加入代码。 tutorial&#x2F;items.py: 项目中的item文件. tutorial&#x2F;pipelines.py: 项目中的pipelines文件. tutorial&#x2F;settings.py: 项目的设置文件. tutorial&#x2F;spiders&#x2F;: 放置spider代码的目录. 定义ItemItem 是保存爬取到的数据的容器；其使用方法和python字典类似， 并且提供了额外保护机制来避免拼写错误导致的未定义字段错误。 类似在ORM中做的一样，您可以通过创建一个 scrapy.Item 类， 并且定义类型为 scrapy.Field 的类属性来定义一个Item。 (如果不了解ORM, 不用担心，您会发现这个步骤非常简单) 首先根据需要从dmoz.org获取到的数据对item进行建模。 我们需要从dmoz中获取名字，url，以及网站的描述。 对此，在item中定义相应的字段。编辑 tutorial 目录中的 items.py 文件: 12345678910import scrapyclass TutorialItem(scrapy.Item): title=scrapy.Field() publishDate=scrapy.Field() url=scrapy.Field() content=scrapy.Field() keywords=scrapy.Field() scrapyDate=scrapy.Field() pass 编写第一个爬虫(Spider)Spider是用户编写用于从单个网站(或者一些网站)爬取数据的类。 其包含了一个用于下载的初始URL，如何跟进网页中的链接以及如何分析页面中的内容， 提取生成 item 的方法。 为了创建一个Spider，您必须继承 scrapy.Spider 类， 且定义以下三个属性: name: 用于区别Spider。 该名字必须是唯一的，您不可以为不同的Spider设定相同的名字。 start_urls: 包含了Spider在启动时进行爬取的url列表。 因此，第一个被获取到的页面将是其中之一。 后续的URL则从初始的URL获取到的数据中提取。 parse() 是spider的一个方法。 被调用时，每个初始URL完成下载后生成的 Response 对象将会作为唯一的参数传递给该函数。 该方法负责解析返回的数据(response data)，提取数据(生成item)以及生成需要进一步处理的URL的 Request 对象。 以下为我们的第一个Spider代码，保存在 tutorial&#x2F;spiders 目录下的__init__.py 文件中: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121# -*- coding: utf-8 -*-import scrapyfrom tutorial.items import TutorialItemimport timefrom scrapy.spiders import CrawlSpiderimport reimport requestsfrom lxml import etreeimport sysreload(sys)sys.setdefaultencoding('utf-8')class spider(CrawlSpider): name = \"cnblogsSpider\" # 设置爬虫名称 allowed_domains = [\"cnblogs.com\"] # 设置允许的域名 # start_urls = [ # \"http://www.cnblogs.com/lidabo/p/7746915.html\", # 设置开始爬取页面 # ] start_urls = [ \"http://www.cnblogs.com/AllBloggers.aspx\", # 设置开始爬取页面 ] def parse(self, response): sel=response.selector userUrls=sel.xpath('//td/a[1]/@href').extract() for userUrl in userUrls: yield scrapy.Request(userUrl, callback=self.parse_cagetory) print '1' def parse_cagetory(self,response): sel=response.selector scr = sel.xpath('//script/text()').extract()[0] pat = \"currentBlogApp =.+'\" st = re.findall(pat, scr)[0] currentBlogApp = st.replace(\"currentBlogApp = '\", \"\").replace(\"'\", \"\") url='http://www.cnblogs.com/'+currentBlogApp+'/mvc/blog/sidecolumn.aspx?blogApp='+currentBlogApp r = requests.get(url) sel = etree.HTML(r.content) categoryUrls=sel.xpath('//div[@id=\"sidebar_categories\"]//a/@href') #no extract() print '-------' print len(categoryUrls) for categoryUrl in categoryUrls: print 'categoryUrl'+categoryUrl yield scrapy.Request(categoryUrl,callback=self.parse_itemList) def parse_itemList(self,response): sel=response.selector print '++++++' postTitleUrls=sel.xpath('//div[@class=\"entrylistPosttitle\"]/a/@href').extract() for titleUrl in postTitleUrls: print 'titleUrl'+titleUrl yield scrapy.Request(titleUrl,callback=self.parse_item) def parse_item(self, response): sel = response.selector item = TutorialItem() print '??????????' scr = sel.xpath('//script/text()').extract()[0] pat = \"currentBlogApp =.+'\" st = re.findall(pat, scr)[0] currentBlogApp = st.replace(\"currentBlogApp = '\", \"\").replace(\"'\", \"\") scr = sel.xpath('//script/text()').extract()[1] pat = 'cb_blogId=.+,cb_entryId' st = re.findall(pat, scr)[0] cb_blogId = st.replace('cb_blogId=', '').replace(',cb_entryId', '') scr = sel.xpath('//script/text()').extract()[1] pat = 'cb_entryId=.+,cb_blogApp' st = re.findall(pat, scr)[0] cb_entryId = st.replace('cb_entryId=', '').replace(',cb_blogApp', '') requestDataDict=&#123;&#125; pat = 'cb_blogId.+,cb_entryCreatedDate' js = sel.xpath('//div[@id=\"topics\"]/script/text()').extract_first() strs=re.findall(pat, js)[0] tmpList=strs.split(',')[0:4] for s in tmpList: emeList=s.split('=') requestDataDict[emeList[0]]=emeList[1] title=sel.xpath('//a[@id=\"cb_post_title_url\"]/text()').extract_first() # item[\"title\"] = (title is not None and [title.decode(\"utf-8\")] or [\"\"])[0] item[\"title\"] = title publishDate = sel.xpath('//span[@id=\"post-date\"]/text()').extract_first() item[\"publishDate\"] = (publishDate is not None and [publishDate.encode(\"utf-8\")] or [\"\"])[0] url=response.url item[\"url\"]=url plist=sel.xpath('//div[@id=\"cnblogs_post_body\"]//text()').extract() content='' for s in plist: p = (s is not None and [s.decode(\"utf-8\")] or [\"\"])[0] content=content+' '+p item[\"content\"]=content r = requests.get( 'http://www.cnblogs.com/mvc/blog/CategoriesTags.aspx?blogApp='+currentBlogApp+'&amp;blogId='+cb_blogId+'&amp;postId='+cb_entryId) s = r.json().get('Categories') pat = '&gt;.*?&lt;/a&gt;' lis = re.findall(pat, s) keywords = lis[0].replace('&gt;', '').replace('&lt;/a', '') for i in xrange(len(lis)-1): tmpword=lis[i+1].replace('&gt;', '').replace('&lt;/a', '') keywords=keywords+' '+tmpword item[\"keywords\"]=keywords scrapyDate=time.strftime('%Y-%m-%d %H:%M',time.localtime(time.time())) item[\"scrapyDate\"]=(scrapyDate is not None and [scrapyDate.encode(\"utf-8\")] or [\"\"])[0] yield item # self.file.close() 爬取进入项目的根目录，在命令行&#x2F;终端下（假设你用的是pycharm或者mac）执行下列命令启动spider: 1scrapy crawl cnblogsSpider #cnblogsSpider是爬虫的名字 保存数据在pipelines.py文件中编写以下代码： 1234567891011121314151617import jsonclass TutorialPipeline(object): def __init__(self): self.file = open(\"item.json\", \"w+\") def process_item(self, item, spider): record = json.dumps(dict(item), ensure_ascii=False)+\"\\n\" #此处如果有中文的话，要加上ensure_ascii=False参数，否则可能出现乱码 self.file.write(record) return item def open_spider(self, spider): pass def close_spider(self, spider): self.file.close() 参考 Scrapy入门教程","tags":[{"name":"爬虫","slug":"爬虫","permalink":"http://aeyoo.net/tags/爬虫/"}]},{"title":"svm多类别分类","date":"2018-04-11T15:54:11.000Z","path":"2018/04/11/svm多类别分类/","text":"svm本身只适用于二分类问题，但是通过sklearn也可以做多分类问题。在确定超参数的过程中，通常使用网格搜索。 多类别分类问题，有两种构建分类器的策略：One-vs-All及One-vs-One。 多类别分类策略One-Vs-The-Rest策略这个策略同时也称为One-vs-all策略，即通过构造K个判别式（K为类别的个数），第i个判别式将样本归为第i个类别或非第i个类别。这种分类方法虽然比较耗时间，但是能够通过每个类别对应的判别式获得关于该类别的直观理解（如文本分类中每个话题可以通过只属于该类别的高频特征词区分）。 One-Vs-One策略One-Vs-One策略即是两两类别之间建立一个判别式，这样，总共需要K(K−1)&#x2F;2个判别式，最后通过投票的方式确定样本所属类别。 网格搜索主要使用GridSearchCV。 Demo12345678910111213141516171819202122232425262728293031323334353637383940#coding:utf-8from sklearn.metrics import classification_reportfrom sklearn import preprocessingfrom sklearn.cross_validation import train_test_splitfrom sklearn.model_selection import GridSearchCVfrom sklearn.multiclass import OneVsOneClassifierfrom sklearn.multiclass import OneVsRestClassifierimport pandas as pddata_path='./winequality-red.csv'data=pd.read_csv(data_path,delimiter=';')# 属性有11个data_src=data.iloc[:,:11]data_tar=data.iloc[:,11:]X_train, X_test, Y_train, Y_test=train_test_split(data_src,data_tar,test_size=0.20,random_state=33)ss = StandardScaler() X_train = ss.fit_transform(X_train) X_test = ss.transform(X_test)# 网格搜索grid = GridSearchCV(SVC(), param_grid=&#123;\"C\":[0.1,0.5,1,5,10], \"gamma\": [1,0,5,0.1,0.05, 0.01]&#125;, cv=4)grid.fit(X, y)print(\"The best parameters are %s with a score of %0.2f\" % (grid.best_params_, grid.best_score_))# rbf需要双引号csvm = svm.SVC(C=0.5, kernel=\"rbf\", degree=3, gamma=1, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200)# 多类别分类#Y_predict=OneVsRestClassifier(csvm).fit(X_train,Y_train).predict(X_test)Y_predict=OneVsOneClassifier(csvm).fit(X_train,Y_train).predict(X_test)print classification_report(Y_test, Y_predict) reference http://yphuang.github.io/blog/2016/04/22/Multiclass-and-Multilabel-algorithms-Implementation-in-sklearn/","tags":[{"name":"svm多类别分类","slug":"svm多类别分类","permalink":"http://aeyoo.net/tags/svm多类别分类/"},{"name":"网格搜索","slug":"网格搜索","permalink":"http://aeyoo.net/tags/网格搜索/"}]},{"title":"二分搜索","date":"2018-04-11T03:52:47.000Z","path":"2018/04/11/二分搜索/","text":"二分搜索的变形题 poj1064 有n个绳子，它们的长度分别是Li,如果从它们中切割出K条长度相同的绳子的话，这K条绳子每条最长能有多长？保留到小数点后2位。 1&lt;&#x3D;N&lt;&#x3D;100001&lt;&#x3D;K&lt;&#x3D;100001&lt;&#x3D;Li&lt;&#x3D;100000 AC 123456789101112131415161718192021222324252627282930313233#include&lt;iostream&gt;#include &lt;math.h&gt;using namespace std;double L[10000+5];bool f(double x,int n,int k)&#123; int num=0; for(int i=0;i&lt;n;i++) &#123; num+=(int)(L[i]/x); &#125; return num&gt;=k;&#125;int main()&#123; int n,k; double l=0,r=100000; //r的取值是限制条件的右边界。 书中说INF，含义为下确界，并无实际数值意义 cin&gt;&gt;n&gt;&gt;k; for(int i=0;i&lt;n;i++) &#123; cin&gt;&gt;L[i]; &#125; for(int i=0;i&lt;100;i++) &#123; double mid=(l+r)/2; if(f(mid,n,k)) l=mid; else r=mid; &#125; printf(\"%.2f\\n\",floor(r*100)/100); //floor(x)返回的是小于或等于x的最大整数 return 0;&#125;","tags":[{"name":"二分搜索","slug":"二分搜索","permalink":"http://aeyoo.net/tags/二分搜索/"}]},{"title":"关于同一台电脑构建两个github博客的说明","date":"2018-04-11T02:14:39.000Z","path":"2018/04/11/关于同一台电脑构建两个github博客的说明/","text":"之前在mac上构建了一个github blog，将其删除之后 构建第二个github blog的时候，部署一直报错，remote: Permission to A/A.github.io.git denied to B. 关于问题的解决已经有两个文章讲的很好了。 http://ourcoders.com/thread/show/5538/ https://www.jianshu.com/p/77b0340a02f3 大概就是mac终端使用git会缓存密码, 可以尝试下通过钥匙串程序管理. 在钥匙串程序右上角的搜索区搜索github, 结果中种类为互联网密码的条目即为所需, 删除它重新试试git. 这篇文章 翻译了git 关于 credentials 的介绍,里面详细说明了git 是如何寻找用户输入过的用户名和密码的,可以看一下明白 git 记录密码的原理。如果你不想看这篇文章，那么大概理解几个概念就好： git 去找系统是否缓存了用户的密码有三种策略：去缓存中找，去磁盘中找，去钥匙串中找。 &#x2F;Users&#x2F;xxx&#x2F;.gitconfig 文件中(这个文件如果没设置过git 的全局配置可能会不存在)，配置了git 到底选择哪个策略去找用户名和密码。 通过编辑 .gitconfig 文件，credential.helper &#x3D; store&#x2F;cache&#x2F;osxkeychain 来修改 git 缓存策略。 建议阅读原文。","tags":[{"name":"hexo","slug":"hexo","permalink":"http://aeyoo.net/tags/hexo/"},{"name":"github blog","slug":"github-blog","permalink":"http://aeyoo.net/tags/github-blog/"}]},{"title":"sklearn操作示例数据Demo","date":"2018-04-11T01:27:02.000Z","path":"2018/04/11/sklearn操作示例数据Demo/","text":"本文使用sklearn对digits进行分类。因为维度低，所以使用SVM可以得到不错的准确率。 1234567891011121314151617181920212223242526272829303132333435import sys from sklearn.datasets import load_digits # 加载手写数字识别数据 import pylab as pl from sklearn.cross_validation import train_test_split # 训练测试数据分割 from sklearn.preprocessing import StandardScaler # 标准化工具 from sklearn.svm import LinearSVC from sklearn.metrics import classification_report # 预测结果分析工具 reload(sys) sys.setdefaultencoding('utf-8') digits = load_digits() # 数据纬度，1797幅图，8*8 print digits.data.shape # 分割数据 X_train, X_test, Y_train, Y_test = train_test_split(digits.data, digits.target, test_size=0.20, random_state=33) ss = StandardScaler() # fit是实例方法，必须由实例调用 X_train = ss.fit_transform(X_train) X_test = ss.transform(X_test)# 支持向量机csvm = svm.SVC(gamma=0.020)csvm.fit(X_train, Y_train)Y_predict=csvm.predict(X_test)print classification_report(Y_test, Y_predict, target_names=digits.target_names.astype(str))# 随机森林from sklearn.ensemble import RandomForestClassifierclf = RandomForestClassifier(n_estimators=450)clf = clf.fit(X_train, Y_train)Y_predict=clf.predict(X_test)print classification_report(Y_test, Y_predict, target_names=digits.target_names.astype(str)) 结果SVM结果如下：随机森林结果如下：","tags":[{"name":"python","slug":"python","permalink":"http://aeyoo.net/tags/python/"},{"name":"sklearn","slug":"sklearn","permalink":"http://aeyoo.net/tags/sklearn/"}]},{"title":"蠢蠢欲动","date":"2017-11-05T16:12:32.000Z","path":"2017/11/06/蠢蠢欲动/","text":"每次看到一些近乎传奇的经历，都无法按耐自己的热情。这世界上有许多非常有天赋的人，都在不断努力，这也是自己不断努力的动力。专注力和平和的心境很重要。 嗯,, 好好干吧。其实也没啥好说的。 附上一张byvoid的阿里星面试经历，自勉。","tags":[{"name":"tiuve","slug":"tiuve","permalink":"http://aeyoo.net/tags/tiuve/"}]},{"title":"tensorflow基础语法","date":"2017-08-02T11:57:16.000Z","path":"2017/08/02/tensorflow基础语法/","text":"本文通过代码记录一些 tensorflow 的基础语法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#coding:utf8import tensorflow as tfa = tf.constant([1,2],name=\"a1\")b = tf.constant([3,4],name=\"b1\")res = a + bwith tf.Session() as sess: c = sess.run(res) print(res.get_shape()) # 获取张量的形状 (2,) print(sess.run(a)) # [1 2] print(a) #Tensor(\"a1:0\", shape=(2,), dtype=int32) # tf.Variable的作用就是保存和更新神经网络中的参数 # 声明一个２*３的矩阵,均值为０,标准差为２. random_normal() 正太分布 weight_matrix = tf.Variable(tf.random_normal([2, 3], stddev=2)) w1 = tf.Variable([[1.0, 2.0, 3.0], [10.0, 20.0, 30.0]]) zeros = tf.Variable(tf.zeros([2, 3], tf.int32)) # 产生全0的数组 ones = tf.Variable(tf.ones([2,3],tf.int32)) # 产生全１的数组 array_define = tf.Variable(tf.constant([1, 2])) # 产生一个全部为给定数字的数据 constant = tf.Variable(tf.constant([1,2,3])) # 产生一个给定值的常量 bias = tf.Variable(tf.zeros([3])) w2 = tf.Variable(w1.initialized_value()) # 其它变量的值初始化新的变量 W3 = tf.Variable(w1.initialized_value() * 2.0) # 正态分布,但如果随机出来的值偏离平均值超过２个标准差，那么这个数将被重新随机 w4 = tf.Variable(tf.truncated_normal([2,3],stddev=1)) w5 = tf.Variable(tf.random_uniform([2,3],minval=0,maxval=2)) # 均匀分布 w6 = tf.Variable(tf.random_gamma([2,3],1)) # gamma分布 # 初始化所有变量 init_op = tf.global_variables_initializer() sess.run(init_op) # 打印变量 print(\"输出 2*3 权重矩阵\") print(sess.run(weight_matrix)) print(\"w1\") print(sess.run(w1)) print(\"zero\") print(sess.run(zeros)) print(\"ones\") print(sess.run(ones)) print(\"array_define\") print(sess.run(array_define)) print(\"constant\") print(sess.run(constant)) print(\"bias\") print(sess.run(bias)) print(sess.run(w4)) print(sess.run(w5)) print(sess.run(w6)) # 前向传播的实现 w1 = tf.Variable(tf.random_normal((2,3), stddev=1, seed=1)) w2 = tf.Variable(tf.random_normal((3,1), stddev=1, seed=1)) # 注意, 此处声明的ｘ是一个 1*2 的矩阵常量 x = tf.constant([[1.0,2.0]]) a = tf.matmul(x,w1) y = tf.matmul(a,w2) init_op = tf.global_variables_initializer() sess.run(init_op) print(\"y:\") print(sess.run(y)) # placeholder 占位符 x1 = tf.placeholder(tf.float32,shape=(3,2),name=\"input\") a = tf.matmul(x1,w1) y1 = tf.matmul(a,w2) print(\"y1\") print(sess.run(y1,feed_dict=&#123;x1:[[1,2],[2,3],[3,4]]&#125;))","tags":[{"name":"tensorflow","slug":"tensorflow","permalink":"http://aeyoo.net/tags/tensorflow/"}]},{"title":"snow","date":"2017-04-29T05:27:23.000Z","path":"2017/04/29/snow/","text":"连续做了一个月的噩梦，不知道是有所征兆，还是咋。 渐渐地变得懒散，找不到生活的意义，以及此刻的自己为了什么而去奋斗。 仿佛好久没有令自己开心的事了。 谨以 Approaching Nirvana 的《 you 》献给自己。 做自己。","tags":[{"name":"hole","slug":"hole","permalink":"http://aeyoo.net/tags/hole/"}]},{"title":"介绍几个ML工具","date":"2017-04-19T06:08:12.000Z","path":"2017/04/19/介绍几个ML工具/","text":"首先介绍数据流挖掘工具。MOA (MASSIVE ONLINE ANALYSIS)MOA is the most popular open source framework for data stream mining, with a very active growing community (blog). It includes a collection of machine learning algorithms (classification, regression, clustering, outlier detection, concept drift detection and recommender systems) and tools for evaluation. Related to the WEKA project, MOA is also written in Java, while scaling to more demanding problems. 链接：http://moa.cms.waikato.ac.nz/。 WEKAWeka is a collection of machine learning algorithms for data mining tasks. The algorithms can either be applied directly to a dataset or called from your own Java code. Weka contains tools for data pre-processing, classification, regression, clustering, association rules, and visualization. It is also well-suited for developing new machine learning schemes. 声明一下：WEKA是有可视化分析工具的。 链接：http://www.cs.waikato.ac.nz/ml/weka/。 如果想在项目中使用WEKA，需要下载Linux平台的weka，找到weka.jar即可。 接下来介绍一些常用的工具。scikit-learnScikit-learn (formerly scikits.learn) is a free software machine learning library for the Python programming language. Simple and efficient tools for data mining and data analysis Accessible to everybody, and reusable in various contexts Built on NumPy, SciPy, and matplotlib Open source, commercially usable - BSD license 链接：http://scikit-learn.org/stable/index.html。 NumPyNumPy is the fundamental package for scientific computing with Python. It contains among other things: a powerful N-dimensional array object sophisticated (broadcasting) functions tools for integrating C&#x2F;C++ and Fortran code useful linear algebra, Fourier transform, and random number capabilities Besides its obvious scientific uses, NumPy can also be used as an efficient multi-dimensional container of generic data. Arbitrary data-types can be defined. This allows NumPy to seamlessly and speedily integrate with a wide variety of databases. SciPySciPy is a series of Scientific Computing Tools for Python. It refers to several related but distinct entities: The SciPy Stack, a collection of open source software for scientific computing in Python, and particularly a specified set of core packages. The community of people who use and develop this stack. Several conferences dedicated to scientific computing in Python - SciPy, EuroSciPy and SciPy.in. The SciPy library, one component of the SciPy stack, providing many numerical routines.","tags":[{"name":"机器学习工具","slug":"机器学习工具","permalink":"http://aeyoo.net/tags/机器学习工具/"}]},{"title":"摄影","date":"2017-04-11T04:40:22.000Z","path":"2017/04/11/摄影/","text":"感光度、光圈和快门光圈 ： 大光圈小景深背景虚化，小光圈大景深背景清晰。快门决定了曝光时间长短。如果要拍摄夜景车灯流动效果，需要设置快门快门速度两秒或更慢；拍摄水滴凝固效果设置快门1&#x2F;500或者更快。有的时候按不下快门， 可能设置了自动对焦但是无法对焦准确。解决办法，离被摄物体远一点或者手动调焦。快门优先和光圈优先都是半自动的。 感光度 就是底片感应光线进行化学反应的速度。胶片机有不同感光度的胶片。通过提高感光度就可以加快快门打开关闭的时间进行拍摄了。安全快门概念。 一般地，白天光照充分的时候使用ISO100，晚上或者光照条件不好情况下，需要把感光度调高，如ISO400或更高，这样就可以使用更快的快门了。提高感光度可能会造成噪点。可以设置感光度为自动模式进行自动调节。 感光度、光圈和快门决定了一张照片的质量。 白平衡荧光灯模式（金碧辉煌） 相机的自动白平衡会自动把黄色改变为白色记录下来。为了得到一个接近真实的白色，相机会增加另外的颜色调节光线。AWB是自动白平衡， 曝光，白加黑减 拍摄雪景时候灰蒙蒙的。相机测光会自动把检测到的光线设置为中等色调的曝光组合，中等色调，是反反光率为18%的颜色。雪的表面存在强烈的发光，相机测光觉得光线太亮了，会自动调暗一些。反之相同。 想在光圈优先模式下拍出正常白色，需要设置曝光补偿为+2，纯正黑色为-3。 P模式 Program AE 程序自动拍摄模式 程序自动曝光模式，是相机根据现场的光照条件，计算出光圈和快门的曝光组合后，就可以按下快门了。如果使用P模式但没有进行参数调整的话，相当于全自动模式。一般情况下，可以拍摄出各种参数合理的照片。但是也可以根据自己需要，对光圈值和快门值进行调整。 如光圈设置4.0，快门速度1&#x2F;60，拍出的照片景深很浅，比较适合拍特写或人像；不适合风景。 如果拍风景需要远处山水清晰成像，需要手动调节，把光圈调至只11或16组合。 如果在光线不足情况下， 相机会自动调节光圈至最大值，快门速度也会相应变慢。如果调节光圈到最大值后快门速度过慢，可以提高感光度以获取更快的快门速度。 尼康D7100操作技巧如何进行对焦调节？有自动对焦（AF）和手动对焦。 自动对焦模式： ● AF-A 自动伺服AF ● AF-S 单次伺服AF ● AF-C 连续伺服AF自动对焦模式调节方式：按下AF模式按钮旋转主指令拨盘。AF区域模式调节方式：按下AF模式按钮旋转副指令拨盘。 如何进行曝光调节？P、S、A、M模式下可以设置曝光的方式（别的模式都是自动测光的）。测光方式有矩阵，中央重点（人像拍摄经典方式），点三种。设置曝光方式：（先按info按钮）按下format按钮并旋转主指令拨盘直到控制面板显示所需设定。设置曝光值：按下加减按钮旋转主指令拨盘。照相机关闭后，曝光值不会重设。 如何进行感光度（ISO）调节？P&#x2F;S&#x2F;A&#x2F;M模式是手动调节，别的都是自动调节。设置ISO值：按下ISO按钮（控制面板左边第四个），旋转主指令拨盘进行调节（取景器会显示ISO值）。 设置ISO自动&#x2F;手动：按下ISO按钮（控制面板左边第四个），旋转副指令拨盘进行调节。 若在拍摄菜单的ISO感光度设定 &gt; 自动ISO感光度控制中选择了开启，当使用用户所选值无法达到最佳曝光时，照相机将自动调整ISO感光度。按下info按钮可以查看ISO值。 较高感光度会产生噪点。使用拍摄菜单的高ISO降噪可以减少噪点。 ps液化工具怎么用和ps液化教程：瘦脸和放大眼睛。执行“滤镜——液化”，打开“液化”对话框，在左边有一竖排工具，共12个相关命令。 阴天如何调参数摄影清晰默认室外情况，室内如果光线好的话可以适当降低拍摄条件 先看环境，阴天，光线昏暗，单靠相机要想拍到清楚的照片，快门速度肯定要放慢，光圈要大，高ISO，保证光线充足。题主要求脸部清晰，所以光圈必须要小，看你多少人了，人少的话一般f5.6 -f8左右够了，人多的话就f11-f16。那么，问题来了，光圈小了，要保证进光量，必须放慢快门速度或者提高ISO。快门速度多慢呢，看环境光，具体多少说不准，但是不能太慢，总不能说10s吧，就算自己上架子，别人也不一定能站得住（好吧，我是开玩笑的）。高iso,这个可以 有，现在相机高感这么好，1600或者以上也是可以接受的，看你相机喽。高感带来噪点，可以接受的话请大胆使用 这种情况最好是有闪光灯（至少2个热靴灯，为什么至少两个，嗯……怕你一个不够用），配一把大的反光伞还是可以应付的。保证快门速度，景深，眼神光神马的都有了。如果你没有灯或者不会用 HTC U11相机拍摄教程在明亮的背景中拍摄人像时，使用 HDR（High Dynamic Range，高动态范围）可让您的拍摄对象更加清晰。 即使在高对比度光线条件下，HDR 也能为明亮部分和阴影带来丰富细节。 重要 ： 拍摄对象不动时，HDR 的效果最佳。相机会在不同的曝光度下拍摄多个镜头，并将它们组合成一张增强的照片。 HDRHTC的专业相机没有HDR，相机里面有。 当弱光下拍照出来噪点比较明显时，可以打开AutoHDR使噪点明显被改善，而且画质会更好。 如果用强制HDR，效果会更好，但是手机必须被拿稳至少1～2秒钟，否则会有模糊情况发生（并且强制HDR模式不适合拍摄动态场景，会出现拖影的）。 另外，由于专业模式不带HDR，除非自己擅长调配参数，否则对普通拍摄者来说，用AutoHDR拍照模式，在较弱光线下会省心省力。 使用专业模式拍屏幕或者灯光时，调感光度或者快门出现条纹是怎么回事？ 可见光都是一种电磁波，有不同的波长，跟频率，简单的来说，光不是一条直线，而是像海浪一样，有起有伏，呈s形。 了解了这一点之后，就还要知道频率，相当于你拿一条棍子，左右摇摆的速度。而屏幕光的频率一般是1&#x2F;60-1&#x2F;80s之间。 了解了这一点之后，只需要记得，如果你拍照时，快门超过了1&#x2F;60-1&#x2F;80s之后，就会出现你所说的条纹，因为屏幕光线其实是一直在闪烁并且呈s形，只不过闪烁的速度超过了人眼所见，所以看不出是闪烁，就相当于，一台风扇，如果开得足够快，你是看不到风扇叶片的。 所以，问题只跟快门有关，在调感光度值时会出现，其实是因为把快门设置为了自动，如果这时，把快门调到1&#x2F;60s，然后随便你怎么调感光度都不会再出现条纹。 U11拍夜景时十分容易过曝，怎么办？ 首先，我们要知道数码相机测光的原理，目前U11默认用的是平均测光，平均测光是什么呢？就是检测整个取景画面里的光线的强弱，那是怎么检测的呢？比如拍一个景里面，暗的区域居多，那么就得出这个场景亮度不够，便会自动进行补光。如果一个画面里亮的区域居多，那么就得出这个场景亮度过曝，需要减光。 明白了这一点之后，现在再来看为什么拍夜景时总会容易过曝，如果你拍的夜景里，以暗的区域居多（一般是天空跟没有灯光的地方），那这个时候系统就会识别出需要补光，所以就会出现很多人说的过曝了。 所以，在数码单反相机里，会有平均测光，点测光，中心测光，边缘测光，多点测光等，以应对不同的场景。 简单来说就是：别依赖所谓的自动模式，不存在一个测光模式搞定变化多端的所有场景。 下面说说如果过曝时怎么做。 第一个方法：上下滑动亮度控制条; 第二个方法：使用点测光模式. 在相机设置里，打开“点击自动曝光”的选项，然后回到拍照界面，这时只要点击过曝的地方就会自动调整亮度，如果这时觉得太暗了，再配以上下滑动亮度控制条进行微调，就可以得到一张正常的曝光，建议大家平时都开启HDR自动。 说明：本文内容基本总结自网上，之前整理的时候没想过发博客，所以无法在此处标注链接，请见谅。 摄影基础理论知识 4 &#x2F; 5 成像的重要参数 快门（分享自知乎网）","tags":[{"name":"摄影","slug":"摄影","permalink":"http://aeyoo.net/tags/摄影/"}]},{"title":"tf构建cnn对mnist数据集进行分类","date":"2017-04-11T01:49:05.000Z","path":"2017/04/11/tf构建cnn对mnist进行分类/","text":"使用tensorflow构建cnn对minist数据集进行分类。代码来自网络。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677#coding:utf-8from tensorflow.examples.tutorials.mnist import input_dataimport tensorflow as tfmnist = input_data.read_data_sets('mnist/', one_hot=True)sess = tf.InteractiveSession()x = tf.placeholder(\"float\", shape=[None,784])y_ = tf.placeholder(\"float\", shape=[None,10])#初始化权重def weight_variable(shape): initial = tf.truncated_normal(shape, stddev = 0.1) return tf.Variable(initial)#初始化偏置项def bias_variable(shape): initial = tf.constant(0.1, shape = shape ) return tf.Variable(initial)#卷积过程def conv2d(x,w): return tf.nn.conv2d(x,w, strides=[1,1,1,1],padding='SAME')#池化过程def max_pool_2x2(x): return tf.nn.max_pool(x,ksize=[1,2,2,1], strides=[1,2,2,1],padding='SAME')w_conv1 = weight_variable([5,5,1,32])b_conv1=bias_variable([32])#-1 表示图片数量不定x_image=tf.reshape(x,[-1,28,28,1])h_conv1=tf.nn.relu(conv2d(x_image,w_conv1)+b_conv1)h_pool1=max_pool_2x2(h_conv1)w_conv2=weight_variable([5,5,32,64])b_conv2=bias_variable([64])h_conv2=tf.nn.relu(conv2d(h_pool1,w_conv2)+b_conv2)h_pool2=max_pool_2x2(h_conv2)w_fc1=weight_variable([7*7*64,1024])b_fc1=bias_variable([1024])h_pool2_flat=tf.reshape(h_pool2,[-1,7*7*64])h_fc1=tf.nn.relu(tf.matmul(h_pool2_flat,w_fc1)+b_fc1)keep_prob=tf.placeholder(\"float\")h_fc1_drop=tf.nn.dropout(h_fc1,keep_prob)w_fc2=weight_variable([1024,10])b_fc2=bias_variable([10])y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop,w_fc2)+b_fc2)#计算交叉熵的代价函数cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))#使用优化算法使得代价函数最小化train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)#找出预测正确的标签correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))#得出通过正确个数除以总数得出准确率accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))sess.run(tf.initialize_all_variables())for i in range(20000): batch = mnist.train.next_batch(50) if i%100 == 0: train_accuracy = accuracy.eval(feed_dict=&#123; x:batch[0], y_: batch[1], keep_prob: 1.0&#125;) print \"step %d, training accuracy %g\"%(i, train_accuracy) train_step.run(feed_dict=&#123;x: batch[0], y_: batch[1], keep_prob: 0.5&#125;)print \"test accuracy %g\"%accuracy.eval(feed_dict=&#123; x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0&#125;)","tags":[{"name":"cnn","slug":"cnn","permalink":"http://aeyoo.net/tags/cnn/"}]},{"title":"一种概念漂移问题的解决算法","date":"2017-04-07T10:44:04.000Z","path":"2017/04/07/一种概念漂移问题的解决算法/","text":"今天研究了一下概念漂移问题并了解了一种解决算法，记录如下。 内容来自论文《 Learning with Drift Detection 》。 该论文展示了一种检测样本概率分布变化的方法。其背后的思想是控制在线学习模型的错误率。 当数据到达的时候，对数据进行学习。根据统计理论，当被分类数据的概率分布是确定的时候，学习错误率将逐渐减小；当概率分布是变化的时候，学习错误率将上升。该算法根据在线学习的错误率，定义了预警值和漂移值两个概念。如果在一个数据流环境中，学习的错误率上升到预警值Kw和漂移值Kd，那么一个新的上下文context便生成了。这是样本概率变化的一个信号。该算法仅从预警值开始学习一个新的模型。算法验证采用八个人工数据集和一个真实数据集；使用感知机，神经网络，决策树三种学习算法进行学习。实验表明，该算法拥有良好的性能，且性能独立于分类算法。 context： 通过确定概率分布生成的一个数据集合。 数据流可以看做是一个个context组成的。在context之间的概念变化可能是平缓的，也可能是急剧的。该算法通过监测这种变化，进而确定信息是否过时（无关信息），并重新学习当前context的相关信息。 在机器学习领域中，概念漂移问题一般通过时间窗口和加权样本（根据样本的年龄和实用价值进行赋权）来处理。应对概念漂移的方法可以分为两类： 定期调整学习者的方法，而不考虑变化是否真的发生; 首先检测概念变化的变化，接下来，学习器适应这些变化。 加权样本基于一种简单的观点，即样本的重要性随时间而逐渐降低。对于一个当前正在被使用的时间窗口，学习器只能根据窗口内的数据进行学习。如何确定时间窗口的大小是一个关键问题。小的窗口可以很快地适应样本的概念变化，但是在更多概率分布稳定的情况下会影响学习器的性能。大的窗口可以在概率分布稳定的情况下获得良好的学习性能，但是无法及时地反应概念变化。 所以通常地，一般通过监测样本的某些数据指标来确定是否发生了概念漂移，通过概念漂移的程度确定时间窗口的大小。按照惯例，如果概念漂移发生了则时间窗口减小，反之增大。一个相关的例子就是FLORA算法。FLORA2包含了一个基于规则的分类器的窗口调整的启发式思想。为了监测概念漂移，当前学习器的准确度和覆盖度被实时监测，并且窗口大小进行相应地调整。此外，还有通过准确率，召回率，时间精度等指标进行监测。启发式思想有一定的局限性：1. 反馈信息少；2. 相当多的参数需要被调整。另有人使用支持向量机进行窗口大小的研究。 漂移算法思想对于 错误 是一个服从伯努利实验的随机变量的样本。二项分布给出了随机变量的概率的一般形式，随机变量表示含有n个样例的样本中的错误数量。 12定义pi为观测到的错误率；定义si为观测到的标准偏差； si=sqrt(pi(1-pi)/i) //二项分布的标准差 对于足够多的样本，二项分布近似于具有相同均值和方差的正态分布。我们可以通过评估假设中的方法估计一个样本集合的真实错误率（基于某离散值假设h在样本S上观察到的样本错误率，估计它的真实错误率，内容较多此处不进行详述）。","tags":[{"name":"流数据","slug":"流数据","permalink":"http://aeyoo.net/tags/流数据/"},{"name":"概念漂移","slug":"概念漂移","permalink":"http://aeyoo.net/tags/概念漂移/"}]},{"title":"KMP算法","date":"2016-12-10T07:58:40.000Z","path":"2016/12/10/KMP算法/","text":"在字符串匹配算法里面有一种算法叫kmp算法。其实这种算法原理很简单，用模式串的前缀和后缀性质减少比较次数，从而达到提高效率的目的。不可否认的是，字符串匹配场景还是很常见的。假如在字符串 T &#x3D; {a,b,c,d,e,a,b,c,d,a,b,d} 中搜索字符串 P &#x3D; {a,b,c,d,a,b,d}，则字符串 P 成为模式串。 其实KMP算法建立在 3 条引理之上的。见算法导论（p591）。也可以参考知乎更好的理解和掌握 KMP 算法? 直接贴代码.. 1234567891011121314151617181920212223242526272829303132333435363738//Go语言版，用Go语言实现只是为了学习Go的语法，所以代码风格不太统一，例如切片的声明方式。func cateMaxLens(pat string) []int &#123; plen := len(pat) maxMatchLenArys := make([]int, plen) // 声明切片 maxlen := 0 // 当i=k时，计算i=0开始，和i=k开始，最常公共字符串 for i:=1; i&lt;plen; i++ &#123; for maxlen &gt; 0 &amp;&amp; pat[maxlen] != pat[i] &#123; maxlen = maxMatchLenArys[maxlen-1] &#125; if pat[i] == pat[maxlen] &#123; maxlen++ &#125; maxMatchLenArys[i] = maxlen &#125; return maxMatchLenArys&#125;func kmp(src string, pat string) []int &#123; var posArys []int maxMatchLenArys := cateMaxLens(pat) count := 0 for i:=0; i&lt; len(src); i++ &#123; for count&gt;0 &amp;&amp; pat[count] != src[i] &#123; count = maxMatchLenArys[count-1] // 为了确定在前缀和后缀含有公共子串的前提下，下次匹配时的起始位置 &#125; if pat[count] == src[i]&#123; count++ &#125; if count == len(pat) &#123; posArys = append(posArys, i-len(pat) + 1) count = maxMatchLenArys[count-1] &#125; &#125; return posArys // posArys记录匹配到的字符串的所有起始位置，例如src=\"ababa\",pat=\"abab\",则posArys[0,2]，如果没有匹配到，则posArys=[]&#125;","tags":[{"name":"kmp","slug":"kmp","permalink":"http://aeyoo.net/tags/kmp/"},{"name":"字符串匹配","slug":"字符串匹配","permalink":"http://aeyoo.net/tags/字符串匹配/"}]},{"title":"深度优先遍历","date":"2016-12-09T10:50:39.000Z","path":"2016/12/09/深度优先遍历/","text":"本文介绍了一下深度优先遍历（depth-first search，DFS）的框架。下面代码使用了 vector 式的邻接表，其中 G[u][i] 表示结点 u 的第 i 个子结点。每条边用（u，v）表示。 12345678910111213141516171819#include &lt;stdio.h&gt;int maxn=100;std::vector&lt;int&gt; G[maxn]; //图int vis[maxn];dfs(int u)&#123; vis[u]=1; PREVISIT(u); //访问结点u之前的操作 int i=0,v=-1; int d=G[u].size(); for(i=0;i&lt;d;++i) //枚举每条边 &#123; v=G[u][i]; if(!vis[v]) dfs(v); &#125; POSTVISIT(u); //访问结点u之后的操作&#125; 我们把相互可达的结点称为一个连通分量，则很容易用DFS在线性时间内求出任意无向图的连通分量。下面代码为每个结点计算出了该结点所属的连通分量编号。 1234567891011void find_cc()&#123; current_cc=0; memset(vis,0,sizeof(vis)); for(int u=0;u&lt;n;u++) //依次检查图中的每个结点 if(!vis[u]) &#123; current_cc++; //如果结点u没有被访问过，意味着它属于一个新的连通分量 dfs(u); //从结点u开始DFS可以访问到它所在的整个连通分量 &#125;&#125; 这里current_cc表示当前连通分量的编号。如果要记录每个结点的连通分量编号，需要在PREVISIT(u) 中赋值cc[u]&#x3D;current_cc。 如果我们只需要求连通分量，可以使用并查集，不需要保存图，只需按照某种顺序处理所有的边。 二分图的判定对于无向图 G&#x3D;(V,E)，如果可以把结点集分成不相交的两部分，即 X 和 Y&#x3D;V-X，使得每条边的其中一个端点在X中，另一个端点在Y中，则称 G 是二分图（bipartite graph）。 二分图的另一种说法是，可以把每个结点着以黑色和白色之一，是的每条边的两个端点颜色不同。不难发现，非连通的图是二分图当且仅当每个连通分量都是二分图，因此我们只需考虑无向连通图。 下面我们用 DFS 给任意无向图 G 进行黑白二着色。 1234567891011121314151617int color[maxn]; //调用函数之前color数组清零//判断结点u所在的连通分量是否为二分图bool bipartite(int u)&#123; for(int i=0;i&lt;G[u].size();i++) &#123; int v=G[u][i]; //枚举每条边 if(color[v]==color[u]) return false; if(!color[v]) &#123; color[v]=3-color[u]; if(!bipartite(v)) return false; &#125; &#125; return true;&#125; 摘自白书。","tags":[{"name":"dfs","slug":"dfs","permalink":"http://aeyoo.net/tags/dfs/"},{"name":"二分图","slug":"二分图","permalink":"http://aeyoo.net/tags/二分图/"},{"name":"连通分量","slug":"连通分量","permalink":"http://aeyoo.net/tags/连通分量/"}]},{"title":"二叉搜索树","date":"2016-12-08T08:01:55.000Z","path":"2016/12/08/二叉搜索树/","text":"今天写了一下二叉搜索树，暂时没写完，因为涉及到平衡化的问题，还要想想，特此记录。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162//BST.c#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;typedef struct TreeNode&#123; int m_nValue; TreeNode* p_left; TreeNode* p_right; TreeNode* parent;&#125;TreeNode,*PTreeNode;void insert(TreeNode** root,int value)&#123; TreeNode* pNode=(TreeNode*)malloc(sizeof(TreeNode)); //sizeof()的参数别写错了，没有* pNode-&gt;m_nValue=value; pNode-&gt;p_left=NULL; pNode-&gt;p_right=NULL; pNode-&gt;parent=NULL; if(*root == NULL) &#123; *root=pNode; return; &#125; if( (*root)-&gt;p_left == NULL &amp;&amp; value &lt; ((*root)-&gt;m_nValue )) &#123; pNode-&gt;parent = *root; (*root)-&gt;p_left = pNode; &#125;else if((*root)-&gt;p_right == NULL &amp;&amp; value &gt; ((*root)-&gt;m_nValue )) &#123; pNode-&gt;parent = *root; (*root)-&gt;p_right=pNode; &#125; if(value &lt; ((*root)-&gt;m_nValue )) insert(&amp;(*root)-&gt;p_left,value); else if(value &gt; ((*root)-&gt;m_nValue )) insert(&amp;(*root)-&gt;p_right,value);&#125;void printPreorder(TreeNode* root)&#123; if(root == NULL) return; printf(\"%d \",root-&gt;m_nValue); if(root-&gt;p_left != NULL) printPreorder(root-&gt;p_left); if(root-&gt;p_right != NULL) printPreorder(root-&gt;p_right);&#125;;int main()&#123; int a[]=&#123;2,3,4,5,6,7,8,9,1&#125;; int i=0; TreeNode* root = (TreeNode*) malloc(sizeof(TreeNode*)); root = NULL; for(i=0; i &lt; (sizeof(a)/sizeof(a[0]));++i) insert(&amp;root,a[i]); printPreorder(root); return 0;&#125;","tags":[]},{"title":"大数问题","date":"2016-12-07T08:28:30.000Z","path":"2016/12/07/大数问题/","text":"昨天瞌睡状态下写了一下大数相乘，各种低级bug，类型转换、参数写错、少写语句。。刚刚又写了一下。直接贴代码吧，写出来之后去poj2389跑了下过了。不过我发现，如果声明数组的时候size是变量（char c[clen]），在oj上会编译出错啊。但是sublime下没有这个问题。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748//BigDataMultifly.c#include &lt;stdio.h&gt;#include &lt;string.h&gt;int main()&#123; char a[42],b[42]; scanf(\"%s\",a); scanf(\"%s\",b); int alen=strlen(a), blen=strlen(b), clen=alen+blen; char c[84]; //此处本来用char c[alen+blen+1]，无奈OJ不通过本地测试通过。 memset(c,'0',sizeof(c)); int i=alen-1,j=blen-1,tmp=0,pre=0,k=0; for(i=alen-1;i&gt;=0;i--) &#123; for(j=blen-1;j&gt;=0;j--) &#123; k=0; tmp = (a[i]-'0')*(b[j]-'0'); while(1) &#123; if(c[i+j+1-k]-'0' + tmp &gt; 9) &#123; pre = (c[i+j+1-k]-'0' + tmp)/10; //向前进位 c[i+j+1-k] = ((c[i+j+1-k]-'0' + tmp) % 10)+'0'; k++; tmp=pre; &#125; else &#123; c[i+j+1-k] = (c[i+j+1-k]-'0' + tmp) +'0'; break; &#125; &#125; &#125; &#125; i=0; while(c[i]=='0') i++; for(;i&lt;clen;i++) printf(\"%c\", c[i]); return 0;&#125;","tags":[]},{"title":"链表的常见操作","date":"2016-12-05T08:39:11.000Z","path":"2016/12/05/链表的增加和删除操作/","text":"链表的常见操作，摘自《剑指offer》。 0 链表的增加和删除操作。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455//LinkedListstruct ListNode&#123; int m_nValue; ListNode* m_pNext;&#125;;void AddToTail(ListNode** pHead, int value)&#123; ListNode* pNew=new ListNode(); pNew-&gt;m_nValue=value; pNew-&gt;m_pNext=NULL; if(*pHead == NULL) *pHead=pNew; else &#123; ListNode* p= *pHead; while(p=m_pNext != NULL) &#123; p=p-&gt;m_pNext; &#125; p-&gt;m_pNext=pNew; &#125;&#125;void RemoveNode(ListNode** pHead, int value)&#123; if(pHead == NULL || *pHead == NULL) return; ListNode* pToDeleted=NULL; if((*pHead)-&gt;m_nValue == value) &#123; pToDeleted=*pHead; *pHead=(*pHead)-&gt;m_pNext; &#125;else &#123; ListNode* p=*pHead; while(p-&gt;m_pNext != NULL &amp;&amp; p-&gt;m_pNext-&gt;value!=NULL) p=p-&gt;m_pNext; if(p-&gt;m_pNext != NULL &amp;&amp; p-&gt;m_pNext-&gt;value == value) &#123; pToDeleted = p-&gt;m_pNext; p-&gt;m_pNext=-&gt;m_pNext-&gt;m_pNext; &#125; &#125; if(pToDeleted != NULL) &#123; delete pToDeleted; pToDeleted = NULL; &#125;&#125; 1 从尾到头打印列表1234567891011121314151617181920212223242526272829// 从尾到头打印链表 迭代void PrintListReversingly_Itetatively(ListNode* pHead)&#123; std::stack&lt;ListNode*&gt; nodes; ListNode* p=pHead; while(p!=NULL) &#123; nodes.push(p); p=p-&gt;m_pNext; &#125; while(!nodes.empty()) &#123; p=node.top(); printf(\"%d \\n\", p-&gt;m_nValue); nodes.pop(); &#125;&#125;// 从尾到头打印链表 递归void PrintListReversingly_Recursively(ListNode* pHead)&#123; if(pHead!=NULL) &#123; if(pHead-&gt;m_pNext!=NULL) PrintListReversingly_Recursively(pHead-&gt;m_pNext); printf(\"%d \\n\", pHead-&gt;m_nValue); &#125;&#125;","tags":[{"name":"链表","slug":"链表","permalink":"http://aeyoo.net/tags/链表/"}]},{"title":"poj1159","date":"2016-11-27T11:02:04.000Z","path":"2016/11/27/poj1159/","text":"题目：Palindrome. A palindrome is a symmetrical string, that is, a string read identically from left to right as well as from right to left. You are to write a program which, given a string, determines the minimal number of characters to be inserted into the string in order to obtain a palindrome. As an example, by inserting 2 characters, the string “Ab3bd” can be transformed into a palindrome (“dAb3bAd” or “Adb3bdA”). However, inserting fewer than 2 characters does not produce a palindrome. 实现代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;stdio.h&gt;#include &lt;string&gt;//记忆化DFSchar str[5000+1];short int dp[5000+1][5000+1];int minx(int a,int b) //注意别实现反了&#123; return a&lt;=b?a:b;&#125;int dfs(int left,int right)&#123; if(left&gt;=right) return 0; if(dp[left][right]!=-1) return dp[left][right]; else &#123; if(str[left]==str[right]) dp[left][right]=dfs(left+1,right-1); else dp[left][right]=minx(dfs(left+1,right),dfs(left,right-1))+1; return dp[left][right]; &#125;&#125;int main()&#123; int len; while(~scanf(\"%d\",&amp;len)) &#123; scanf(\"%s\",str); memset(dp,-1,sizeof(dp)); printf(\"%d\\n\", dfs(0,len-1)); &#125; return 0;&#125;","tags":[{"name":"回文字符串","slug":"回文字符串","permalink":"http://aeyoo.net/tags/回文字符串/"},{"name":"dp","slug":"dp","permalink":"http://aeyoo.net/tags/dp/"}]},{"title":"递归与分治","date":"2016-11-27T10:15:34.000Z","path":"2016/11/27/递归与分治/","text":"综述递归是一种思想，分治是一种算法。分治算法的思想是将一个较大的问题分解为若干个与原问题相似的小问题进行求解。分治算法可以用递归或者迭代的思想实现。分治法的一般步骤如下： 划分, 把问题分解为若干子问题 求解，递归求解子问题 合并，把子问题的解合并为原问题的解 经典问题可以采用分治法的问题有： 棋盘覆盖问题 在一个已排序数组中找到对应的元素 最大最小值问题 实现归并排序 快速幂 逆序对问题（可以借鉴归并排序求解） 分析1. 棋盘覆盖问题 划分 : 将 2n*2n 的棋盘划分为4个 2 n-12 n-1的小正方形； 求解 : 其中一个小正方形里面有一个黑格子，可以进行递归求解，另外三个小正方形没有黑格子，我们可以构造黑格子，令其令其和第一个小正方形一样，然后再进行递归求解； 合并 : 当n&#x3D;2的时候进行解的合并，如果子问题有解则原问题也有解。 2. 在一个已排序数组中找到对应的元素该问题也叫二分查找问题。即每次将数组的中间元素 a[mid] 和对应元素 k 比较，分三种情况：1. 若 a[mid] &#x3D;&#x3D; k，则返回mid；否则如果 a[mid] &gt; k，则 k 在数组前半段；如果 a[mid] &lt; k，则k在数组后半段，然后进行递归求解。 3. 最大最小值问题暂略 4. 归并排序归并排序是一种自底向上的分治算法。归并排序通过分治（递归）思想接触到子问题，然后在对子问题的合并中进行求解。归并排序的分治也是对数组进行不断二分的。到达最小的子问题（只有一个元素的时候）进行合并。合并结果先保存在一个临时数组中，然后再赋值到原数组。 5. 快速幂对于 ak，分为两个子问题： 当 k 为偶数的时候（k &amp; 1 &#x3D; 0），可以写成 ak-1*ak-1 当 k 为奇数的时候，可以写成 a* ak-1*ak-1 6. 逆序对问题只需考虑在归并排序的合并过程中，如果 a[leftLow] &gt; b[rightLow]，则说明 b[rightLow] 和 a[leftLow]… a[leftHigh] 构成逆序对，所以执行 count&#x3D; leftHigh - leftLow + 1 ; 代码实现1.在一个已排序数组中找到对应的元素递归实现： 123456789101112131415161718192021222324#include &lt;stdio.h&gt;//定义-1为没有找到指定元素，-2为异常//a为已排序数组，left和right为数组上下界，k为待查找元素int find(int* a, int left,int right,int k)&#123; if(a==NULL || left&lt;0) return -2; if(left&gt;right) return -1; int middle=left+((right-left)&gt;&gt;1); if(a[middle]==k) return middle; else if(a[middle]&gt;k) return find(a,left,middle-1,k); else if(a[middle&lt;k]) return find(a,middle+1,right,k);&#125;;int main()&#123; int a[10]=&#123;-1,2,3,4,5,6,7,8,9,15&#125;; printf(\"%d\\n\", find(a,0,9,8)); return 0;&#125; 迭代实现： 12345678910111213141516171819202122232425262728293031323334#include &lt;stdio.h&gt;//定义-1为没有找到指定元素，-2为异常//a为已排序数组，n为数组元素个数，k为待查找元素int find(int* a,int n,int k)&#123; if(a!=NULL &amp;&amp; n&gt;0) &#123; int low=0,high=n-1,middle; while(low&lt;=high) &#123; middle=low+((high-low)&gt;&gt;1); //避免溢出 if(a[middle]==k) return middle; else if(a[middle]&gt;k) high=middle-1; else if(a[middle]&lt;k) low=middle+1; &#125; return -1; &#125;else &#123; return -2; &#125;&#125;;int main()&#123; int a[10]=&#123;-1,2,3,4,5,6,7,8,9,15&#125;; int* b=NULL; printf(\"%d\\n\", find(a,sizeof(a)/sizeof(a[0]),11)); printf(\"%d %d\\n\", find(a,0,11),find(b,sizeof(b)/sizeof(b[0]),11)); return 0;&#125; 在用递归实现分治算法时，要注意段错误和栈溢出的问题。有的时候栈溢出不一定是递归调用太多，也可能是局部变量太大，所以建议较大的数组放在main函数外。 2. 归并排序也是采用了分治的思想。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;void merge(int a[],int left,int middle,int right)&#123; int* temp=(int*)malloc((right-left)*sizeof(int)); int leftLow=left,leftHigh=middle,rightLow=middle+1,rightHigh=right; int i=0; while(leftLow &lt;=leftHigh &amp;&amp; rightLow&lt;= rightHigh) &#123; if(a[leftLow]&lt;= a[rightLow]) temp[i++]=a[leftLow++]; else temp[i++]=a[rightLow++]; &#125; if(rightLow&lt;=rightHigh) &#123; while(rightLow&lt;=rightHigh) temp[i++]=a[rightLow++]; &#125; else &#123; while(leftLow&lt;= leftHigh) temp[i++]=a[leftLow++]; &#125; i=0; for(;i&lt;right-left+1; i++) a[left+i]=temp[i]; free(temp); return;&#125;;void mergeSort(int* a,int left,int right)&#123; if(left&lt;right) //不能left&lt;=right，考虑临界条件 &#123; int middle=left+((right-left)&gt;&gt;1); mergeSort(a,left,middle); mergeSort(a,middle+1,right); merge(a,left,middle,right); &#125; return;&#125;;int main()&#123; int a[]=&#123;1,4,3,6,8,7,3,9,0&#125;; mergeSort(a,0,8); int i=0; for(;i&lt;9;++i) printf(\"%d\\n\", a[i]); return 0;&#125; 3. 快速幂12345678910111213141516171819202122#include &lt;stdio.h&gt;int power(int a,int k)&#123; if(k==0) return 1; if(k &amp; 1) &#123; int m=power(a,(k-1)&gt;&gt;1); return m * m * a; &#125; else &#123; int m=power(a,(k&gt;&gt;1)); return m * m; &#125;&#125;int main()&#123; printf(\"%d\\n\", power(2,5)); return 0;&#125;","tags":[{"name":"分治","slug":"分治","permalink":"http://aeyoo.net/tags/分治/"}]},{"title":"并查集","date":"2016-11-23T14:36:53.000Z","path":"2016/11/23/并查集/","text":"假设第i条边的两个端点序号和权值分别保存在u[i],v[i],w[i]中，排序后第i小的边的序号保存在r[i]中。 1234567891011121314151617int cmp(const int i, const int j) &#123;return w[i]&lt;w[j];&#125;int find(int x) &#123; return p[x]==x ? x:p[x]=find(p[x]);&#125;int Kruskal()&#123; int ans=0; for(int i=0;i&lt;n;i++) p[i]=i; for(int i=0;i&lt;m;i++) r[i]=i; sorted(r,r+m,cmp); for(int i=0;i&lt;m;i++) &#123; int e=r[i]; int x=find(u[e]); int y=find(v[e]); if(x!=y) &#123;ans+=w[e];p[x]=y;&#125; &#125; return ans;&#125; 摘自白书","tags":[]},{"title":"ACRush 楼天成回忆录","date":"2016-10-13T15:52:37.000Z","path":"2016/10/13/ACRush 楼天成回忆录/","text":"利用假期空闲之时，将这几年 GCJ ， ACM ， TopCoder 参加的一些重要比赛作个回顾。首先是 GCJ2006 的回忆。 Google Code Jam 2006 一波三折： Google Code Jam 2006 是我第一次到美国参加现场的程序设计比赛。 Google Code Jam 2006 的比赛地点设在了纽约，这次纽约之行之前的签证出了不小的问题，这里非常感谢大家对我们的关心，特别感谢吴总（ wyy ）和鲁小石的帮助，使我最终踏上纽约之旅。 从北京到纽约的飞行时间是 13 个半小时，由于是第一次做超过 8 小时的飞机，没有什么必要的经验和准备，路途非常疲劳。一到宾馆就睡了，结果由于手机铃声的时间使用的是东方时间，差了 12 个小时，一觉把所有事情连晚饭一起都睡过了，随便吃点东西就继续睡了。之后的所有现场比赛我都养成了提前睡觉的习惯，以保证充足的体力。 比赛过程： 比赛时精神状态还算可以，但是分配了比赛房间之后发现自己和 tomek 分在一个房间，真是很不爽；在和旁边的 zhuzeyuan 抱怨的时候，发现他和 Petr 一个房间，彼此彼此吧。 下面就是比赛过程了，总体来说比赛过程比想象的艰苦，不过其实在 System Test 之前的结果还是很满意的，先简单描述一下 3 道题目吧。 250 分的题目是一道平面极值问题，给定 n 个点，求一条直线，使得 n 个点到这条直线的 y 方向截距总和最小。我回忆起金凯在 2003 年集训队论文中报告中讲到的很类似的一道题目，记得一个重要结论是这条直线一定经过两个点，虽然题目有些不同，但是很快得到了相同的重要性质：这条直线一定经过两个点。这样很容易得到一个 O(n3) 的算法。 500 分的题目是一道反 Hash 函数问题，给定一个 Hash 函数和 x ，求一个最小的非负数 y 使得 H[[yes]]&#x3D;x 。估计了一下，单向搜索需要 26^8 ，于是我改用双向搜索，这样就变成了 26^4 。但是实现过程比想象的复杂很多，提交了后只有 280 左右了。其实，这题有更简单的数学方法， tomek 的程序有 450+ 。 1000 分的题目是涉及卷积函数和计算反函数的问题，通过转化变成线性方程求解问题。当时受到现场气氛的影响有些紧张，浪费了不少时间，提交之后 550 分左右。其实，当时一些原理问题都没有想清楚，不过后来和 Ying （王颖）经过讨论验证都是正确的。 Coding 结束之前 Petr ， tomek ， Ying 和 andrewzta 都提交了 3 题，其中 Petr 领先得比较多，我和其余 3 人差距 50 分以内。 Challenge 阶段开始之后，我由于 500 分题自己使用的是双向搜索的算法，没有注意到有些单向的搜索加模线性方程的方法其实是正确，在 10 分钟以内 cha 错了 2 次。落后于上述的 4 个人，排在第五。 但是下面的 5 分钟发生了戏剧性的一幕，首先是 Petr 的 250 被 cha 了，接着 Ying 的 250 也被 cha 了，这样我面临这样一个情况： tomek 领先我 100+ 分， andrewzta 领先我 30+ 分，由于我和 tomek 处在一个房间，所以我做出了一个大胆的决定，就是 challenge tomek 的 1000 分题，我随机生成了一个随机大数据，在最后时刻提交了这个 challenge ，系统返回了一个令人窒息的结果： successfully challenge 。凭借这 50 分我一举超过了 tomek 和 andrewzta ，在 System Test 之前占据了榜首的位置。 戏剧性的结果： 我很有幸能够在第一次参加现场比赛时，就能够和冠军这么接近，如果 System Test 能够全部 Pass 的话，这可以认为是一场完美的比赛。 可是，整个故事就好像是被刻意设计的一样， System Test 之后的结果使我目瞪口呆：首先是 250 分的题目，我由于有一个地方没有及时使用 double ，而造成整数越界；然后， 1000 分的题目简直是悲剧的最高境界，我在高斯消元的时候没有及时把一个重要变量暂存，导致影响了结果，没有想到竟然躲过了那么多大数据，但是不能通过 System Test 。最后排在 50 名左右。这两个错误至今刻骨铭心。 最终 Petr 获得冠军， Ying 亚军， andrewzta 由于 500 挂了排在第 3 。 11 月的纽约有些冷，我随大队人马一同去了一趟帝国大厦，景色很迷人。第二天休息一下后与几个中国选手打了一会 “ 找朋友 ” ，第一次美国之行就结束了。 总结： 比赛结果虽然不是很理想，但是对于第一次参加世界比赛的我还算可以接受。也算是为今后的比赛留下一些教训吧。 在帝国大厦上见识了大家的拍摄功底，我由于技术差没有拍到任何合适的照片。 在比赛过程中，首次见识了 liympanda 的大将风度，和 panda 在一起总是笑口常开，他无论遇到什么情况都无所畏惧，这一点我一直在努力学习，不过一直做的不好。但是 panda 打牌的时候就不一样了，总是喜欢偷看别人的牌，还炫耀自己会说广东话，被 Ying 和 rocking 两位广东选手狠狠鄙视了一番。 Petr 加上之前的 TCO 和之后的 TCCC ，拿到了 2006 年的大满贯，可以算是历史性的突破吧。 Tomek 有些可惜，比完了还问我怎么 cha 他 1000 分的，呵呵。 其实这次比赛 Ying 挺可惜的，其实 Petr 的发挥并不很好，如果 Ying 运气再好一些的话，历史从那时就要重写了。不过 Ying 还是体现了他超强的数学功底，让人佩服。另外，来自复旦的同省队友 LemonTree 也获得了好成绩。 这好像是自己最后一次和 xreborner 同场竞技了（由于之后 xreborner 退役了很长时间，忘记 GCJ2008 我们又见面了，谢谢 Savior 的提醒），感谢您在我高中时期教授了我许多编程技巧，我一直沿用至今。 利用假期空闲之时，将这几年 GCJ ， ACM ， TopCoder 参加的一些重要比赛作个回顾。昨天是 GCJ2006 的回忆，今天时间上更早一些吧，我现在还清晰记得 3 年前，我刚刚参加 ACM 时参加北京赛区 2005 和杭州赛区 2005 的情况。 2005 年 ACM-ICPC —— 酸甜苦辣 我进入清华大学开始本科学习的时间是 2004 年 8 月，在进入清华大学的第一年里，由于基础课学习比较紧张，再加上计算机系不允许大一学生自带电脑，我没有参加 2004 年的 ACM 比赛。不过在大一一年中没有停止这方面的练习，对 ACM 还是热情高涨。 大概在 2005 年 7 月底，与同班同学 shell （贝小辉）和 superzn （张宁）一起决定组队参加 ACM 比赛。对于队名没有太多的想法，就随便取了一个字典序靠前一点的 bomber 。随后进行的几场训练中，我的编程状态一直保持得很好，训练比赛的主要方式都是：我主写程序， shell 和 superzn 负责翻译题目，思考算法和测试。这种组队模式一直沿用到我们后面的所有比赛中。 2005 年底，我们报名参加了 2005 年的北京赛区和杭州赛区的比赛。顺利通过了预赛进入了现场决赛。记得当时北京赛区预赛的时候，我和 superzn 一起在参加百度之星程序设计大赛， shell 依靠一人之力过了 6 题，最后以第二名的资格参加北京赛区现场比赛。 北京赛区： 2005 年的北京赛区地点设在隔壁的北京大学，由于交通非常方便，我们没有和大部分选手住在一起，不过也没有参加 Java-Challenge 和晚上的表演。 练习赛之前，说到比赛位置抽签，本身意义不是很大，可是邬老师神奇的 RP 把两只清华的队伍抽在一起，结果练习赛进行了一半，另一只清华的队伍 THU1 （队员是：吴景岳，栗师和金凯，好像后来队名改成了 DreamCatcher ，不是很确定）被要求换到一个比较远的地方，理由是有些学校觉得这样不合理。后来很多赛区也出现过队伍座位在一起的情况，邬老师的 RP 果然不是盖的。 记得练习赛时和复旦的 LemonTree （盛城）一起在场地里闲逛，结果果然不到 10 分钟就被要求回座位了。还有当时比赛场地是一个体育馆，有些队伍把气球放飞之后气球就飘在天花板下了，总裁判李文新老师还威胁我们说，如果明天正式比赛把气球放飞，就不算通过相应的题目，除非有办法把气球取下来。 然后就是比赛的过程了，下面有底纹的文字是我找到的当时留下的比赛总结： E ：快速排序。 5 分钟 1Y 。 我想 5 分钟的时间可以争取这几年 ACM 国内赛区的最快出题记录了吧。 G ：二分答案 + 最小生成树。 25 分钟 1Y 。 这题就是经典的最优比例生成树问题，我们一致认为这题比较简单。不过后来被李文新老师批评了，说法是误导其他的队伍。不过说到最优比例生成树问题， TCO2006 的时候 fwj 和 tomek 竟然都没有见过这道题目，这题可是源于 POI 呀。我想我们认为这道题目简单的主要原因是我们都在冬令营上见过这到题目，如果第一次看见，想出算法可能确实需要一些时间。在这里向被我们影响的队伍的道歉，最终 G 提交了 200 多次，但是只有 8 个队伍 AC 。 C ：二分图最大匹配。 42 分钟 1Y 题目要求计算一张图的最小覆盖集，可能唯一的 tricky 是发现图是二分图。 D ：遇到了一定的困难，发现 A 很简单，于是先放一下 D 是一道比较综合的题目，设计一些简单的计算几何和字符串处理的知识。 A ：简单的几何问题，出现了一个低级错误，提交了 3 次均为 WA 。 A 是北京赛区最简单的题目，我的程序里犯了一个很低级的错误，可能也是经验不足造成的吧。 D ：重新写，但是没有考虑一种情况， WA 了 1 次。 87 分钟，复旦的 Abuacus 过了 4 题占据了 Rank1 。由于队伍模式的原因，我们在还有很多简单题目的情况下卡住了长达 30 分钟。 A ： shell 突然发现了 A 程序中的低级错误， 105 分钟 AC ，重新夺回 Rank1 。 这是很重要的一步，现在想来如果没有这个发现，后果可能不堪设想。 B ：二分答案 +2SAT 。 129 分钟 AC 。 B 是一道明显的 2SAT 问题，由于题目比较长，我们没有很早发现这道简单题。 D ：发现了 D 的没有考虑的情况， 140 分钟 AC 。 看了一个 board ，那时 Abuacus ， Eccentric 都只有 4 题，能够在第一次参加正式比赛就做到 6-4 的领先，当时心情很激动，不过由于缺少经验，也影响了接下来的发挥。其实，现在回想起来，这次比赛其实是一个很好的 AK 的机会。 F ： DP 。程序比较复杂， WA 了 4 次。 F 是一道比较复杂的动态规划的题目，其实 WA 的原因是一个应该用 int64 的地方，我们使用了 int ，这个地方的确很难发现。 H ： F 一时无法 AC ，只好转功 H 。 H 就是普通的模拟题。开始没有考虑坦克和炮弹可能在 1&#x2F;3 秒相遇， WA 了 1 次。 比赛还有一个小时，封板。 H ： shell 发现了坦克和炮弹可能在 1&#x2F;3 秒相遇的情况， 250 分钟左右 AC 。 对于我们这种组队模式，当主写程序的选手状态不好的时候，很容易出现连续卡题的情况，这种情况的出现很不利于水平的正常发挥。在北京赛区的比赛中，我们很有幸没有出现连续卡处的情况。 记得，当时北京赛区的 Judge 的半自动的，就是说如果结果是 AC ，速度就会非常快，否则由于人的介入，不能 AC 的提交往往需要等一段时间。我们第 2 次提交 H 之后，没有得到很快的回复，以为已经 WA 了，于是我和 superzn 继续测试一些数据。但此时，突然有一个 mm 从左边走过来插气球，这个气球也成为了全场唯一的蓝色气球，这个意外之喜最后成就了第一个分区赛冠军。 F ：下面就是痛苦地提交 F ，一直战斗到最后一刻， WA 了 14 次，留下了北京赛区最大的遗憾。 在最后时刻我们似乎发现了那个 int64 的错误，不过当时思路已经比较混乱了，没能改对。 F 的问题也导致没有时间写 I ，当时如果直接重写后者换 superzn 来写 F ，完全可以在比赛结束前 AC 。 比赛的大致过程如上所述，那个神奇的气球，我现在仍然记忆犹新。最终有 4 个队伍攻破 7 题， Abacus 的组成应该是盛城， timegreen 和 suzhan 吧， Eccentric 中我只记得辛韬， ZSU_Panku 中我记得 Savior （陈实）。上述的老朋友之后见面的机会就很少了，分区比赛也成为了我好需要老同学重要的交流机会了。 我 ACRush 的 ID 估计就是那时开始使用的吧，转眼就已经 3 年多了。 比赛前后还记得经常与复旦大学的吴永辉老师聊天，在那之后的每次比赛我都能见到他年轻的身影。 现在回想起北京的分区赛，很有幸能够在第一次参加 ACM 正式比赛就获得分区比赛的冠军。我想是由于现场气氛对许多队伍都有不小的影响吧，当时许多队伍都卡在几道比较繁琐的题目上了，题目的算法性都不是很强。我大概从那时才刚刚接触 TopCoder ，如果能够早一些，相信会更适应这样的比赛。 杭州赛区： 2005 年的 ACM 杭州赛区比赛在浙江大学举行，杭州赛区的时间就在北京赛区结束后一周，最初选择杭州赛区的原因很飘逸：我自己家在杭州。实际上也差不多，我随队伍（当时 THU 派了 3 只队伍参加杭州赛区的比赛，除了我们队之外， b142857 （侯启明）， zhy （周源）， ysy （杨思雨）组队，另外一只由汪汀，王俊和黄源河组成）一同抵达杭州车站之后就马上回家休息了，直到比赛前才赶回。在北京到杭州赛区之间的一周中，我的状态就在不断下滑，在家中完全失去了比赛的气氛，回到赛场再也找不到感觉了。一场悲剧即将上演。我们先看看比赛过程吧，下面有底纹的文字是我找到的当时留下的比赛总结： G ：初看很简单，但是调试了 30 分钟没有结果。 G 是一道数学问题，其实《具体数学》书上有明确的公式，不过我们使用的递推方法应该也可以得到正确的结果。程序中犯了一些低级的错误，由于实在不在状态，调试了 30 分钟还没有找到错误。这里还暴露了一个组队模式的问题，在后来的组队模式中，如果像这样没有想清楚算法的题目队友是一定不允许我去写的。 A ：模拟。 41 分钟 AC ，当时肯定没有想到这是唯一一道 1Y 的题目。 A 是一道模拟题， 1Y 的时候已经很晚了，排名也很靠后。 C ：图论。但是由于堆栈逸出 RTE 了 5 次，浪费了大量的时间。 C 的问题关于树中祖先关心的判定，题目很简单，实现的方法也很容易，就是通过一遍 DFS 来计算。但是我们忽视了一个从来没有遇到过的问题：堆栈溢出。而且，堆栈在本地机器上运行过程中， Eclipse 提供了 8MB 左右的堆栈，所以没有溢出，但是在提交之后的环境下运行就溢出了。而且每次 RTE 之后，我们一直在尝试修改数组的大小，一直没有找到根本原因。调试 C 的同时，我也尝试修改 G ，结果 G 也错了 8 次之多，并且始终都是 WA 。 I ： shell 在我郁闷地调试 C 和 G 中 AC 了，之前 WA 了一次。 I 是动态规划问题， WA 一次可能是忽视了一些边界情况。 D ：网络流，没有想到先贪心进行优化。 TLE 了 5 次最终没有通过。 D 就是计算最小割，我们事先准备了先流推进算法，不过根据这道题目的模型，先流推进算法遇到最坏情况：二分图。由于当时 dinic 还不是很流行，我们 TLE 了 5 次还没有通过。 郁闷地调试 D 和 G 。 E,B ：都尝试过，但是都出现了不明的问题。 在随后的时间里，不断调试 D 和 G ，但是始终不能 AC 。之后又尝试 E 和 B ， E 通过分段的方法可以处理， B 是数学题目。正常的话 E 和 B 并不是很困难的题目，但是当时已经非常混乱，连样例都没有通过。 最终我们只过了 3 题，排在 21 名，经历了我参加 ACM 以来最惨痛的失败。这次失败主要归过与我状态太差，基本上什么题目都不能顺利通过。当然题目的选择也有很大的问题： G 确实不是难题，但是由于未知的原因始终不能通过，后来我把纸上的程序敲在 ZJU 上就 AC 了，至于现场为什么不能 AC 我现在还是不能明白。如果说第一题的选择直接影响了我们的信心，那么 D 的堆栈溢出则完全打乱了我们的节奏。对于我们的组队模式，卡出 2 题已经超出了极限，我们不可能再尝试其他题目。 Abacus 也来到了杭州，他们前期体现了强劲的先期优势，在 2 小时就达到了 6 题； b142857 （侯启明）， zhy （周源）， ysy （杨思雨）的队伍表现得相当神勇，在最后一小时超越了 Abacus ，夺得了冠军。 杭州赛区的失败至今仍是心中痛苦的回忆，不过这个教训也是对我今后的学习生活的一种警示。 总结： 2005 年是我第一年参加 ACM-ICPC 的比赛，两场 ACM 分区赛，我们经历了夺冠的兴奋，也经历了环顾四周等待比赛结束的无奈。 2004 年清华没有获得任何分区赛的冠军， 2005 年清华打了个漂亮的翻身仗，先后在成都，北京和杭州夺得冠军，而且是三支不同的队伍。 两个赛区的 G 都是有传奇色彩的题目。北京赛区中，我们 25 分钟 1Y 了 G ，导致许多队伍跟风失败，最终达到了 208 提交 8AC 的低通过率。但是，杭州赛区中， G 从比赛一开始就占用了我们大量的时间，直到最后都没有通过，估计至少浪费了两个小时左右。真所谓成也在 G ，败也在 G 。 北京赛区后， POJ 的论坛上传闻说我曾经说过 “ 起身去厕所，不许碰键盘。。。 ” ，很敬仰那些同学搞笑和扯淡的功底，我们虽然定下了以我主写程序的组队模式，但是也非常重视配合和每个人在队伍中的重要作用。 当时清华没有组织校内 PK 选拔，选择了成都赛区的冠军队 THU1 参加全球总决赛，当时总决赛队伍是以参考第二赛区的成绩决定的，现在回想起来也是很合理的。由于最终我们未能得到机会参加全球总决赛，接下来几个月我们情绪低落， bomber 从那时也就宣布解散了吧。 2005 年的比赛过程中，我见到了许许多多的老朋友。用吴永辉老师的话， ACM 竞赛可以看作一些老朋友一起进行的一场智力游戏。 利用假期空闲之时，将这几年 GCJ ， ACM ， TopCoder 参加的一些重要比赛作个回顾。回顾了 GCJ2006 和 2005 年的 ACM 之后，转向 TopCoder 的比赛吧。我参加的最早的 TopCoder 赛事是 TCCC2006 。 TCCC2006 —— 死亡之组 TopCoder Collegiate Challenge( 简称 TCCC) 是 TopCoder 一般在秋季举行的面向全世界在校学生的程序设计大赛， 2006 年的 TCCC 在圣地亚哥举行。从北京到旧金山的飞行只需要 11 个小时左右，所以不至于那么疲劳。路上一切都很顺利，很感谢 OpenGL 的提醒，对于超过 8 个小时飞行自带拖鞋和枕头对我来说还是很重要的。 TCCC2006 使用的标准的 TopCoder 现场比赛形式，比赛有 48 名选手参加，首先 48 名选手被分为 16 个人一组，每组分别进行半决赛，前 2 名直接晋级决赛， 3-6 名晋级 wildcard 比赛， wildcard 比赛 12 人中的前两名填补决赛的最后 2 个名额，决赛由 8 个选手参加。 TopCoder 现场比赛中很重要的一个创新是：每名比赛选手在观众席前都有一个同步的显示器，这样观众可以看到选手任何时刻做的事情，极大增强了互动性。 TCCC2006 的 Room 1 和后面的 Final Round 都可谓是死亡之组。现在就回忆一下这两场激烈的比赛吧。 Room 1 ： 至于 3 个房间的分配， TopCoder 按照注册截止时选手的 Rating 分布蛇形分配。但是 TCCC2006 的房间实力分布极不平衡，我与上届冠军 tomek ，著名选手 reid ， Egor ， halyavin 还有 Rating 不高但是实力极强的 Ying 和 ardiankp 同被分到了 Room 1 ，赛前 Room 1 成为公认的死亡之组。 在圣地亚哥，我和师兄 Macsy （张一飞）同一个房间，很感谢师兄的关心，我那几天休息的都很好。要知道如果同房的人有 10 小时左右的时差的话，一人必须很小心才能保证不影响另一人的休息。 Room 1 在我抵达美国的第二天早上进行，选手允许提前 30 分钟准备一些必要代码。不过现在大家都比较喜欢学习 Petr 那样一行代码都不打。下面就是比赛的过程： 250 分题目是：给定 n(n&lt;&#x3D;50) 个整数 AI 和一个阈值 d ，计算 n 个整数所有排列 PI 中满足 |API-API+1|&lt;&#x3D;d 的排列中，所有不同可能 AP1 的个数。这题最标准的方法是动态规划，基本思想是把 n 个整数排序之后，计算两条相邻元素不超过 d 的序列。我使用了一种更精巧的算法，把 n 个整数排序之后，对于 AI ，如果 AI 可能作为排列的第一个元素，那么 AI 必定在某一个方向（大小）连续而在另一个方向每间隔两个元素相连。这个算法比较容易实现，但是正确性证明比较难，甚至让人第一感觉是错的。我写完程序测试了所有样例都正确就提交了， 243 分。提交之后我又测试了许多数据，并在纸上尝试证明正确性。 赛后，我看了网络上的讨论记录。在我提交 250 分题之后，立刻遭到了 misof 的怀疑，他认为我的算法有问题。据 Macsy 学长的回忆， OpenGL 在我屏幕前看我写完程序，也认为我的算法是错的，不过后来他们讨论之后发现没有反例。 关掉 250 分题目之后，我刚刚意识到 Room 1 的 3 题分数不是 250-500-1000 ，而是 250-600-900 。现在看来，对于 250 比较顺利的情况，应该先做 500 ，若 250 不顺利或者想出奇制胜的话，可以先开 1000 分。当时没有什么经验，我认为 900 比 600 应该简单一些，于是就打开了 900 。 900 分题目是：给定一张 n(n&lt;&#x3D;10) 个点的带权有向完全图（也就是 n2 个实数）和一个衰减系数 p ，求一条经过 d(d&lt;&#x3D;10) 条边路径（不需要保证简单路径），要求这条路径的指数衰减长度（指数衰减是指第 i 段的长度乘以 pi-1 然后求和）最接近 1000 。这题如果使用穷举法，就需要 1010 左右的计算量，在 TopCoder 的测试机上也不能通过，由于路径长度很容易超过 1000 ，所以很难找到多项式时间的动态规划。我马上有了一个想法 —— 双向搜索。对于长度为 d 的路径，其实可以看作从某一个点 p 出发的一条反向的长度 [d&#x2F;2] 的路径和一条正向的 d-[d&#x2F;2] 的路径，对于固定的节点 v 来说，这种两个方向的路径都不超过 n[d&#x2F;2] ，这样只要枚举一个方向的路径然后二分查找另一个方向即可。复杂度是 O(dn2+[d&#x2F;2]) 。 现场比赛调试环境不是很好，我花了不少时间调试以发现程序中的错误。提交之后 690 多分，还不到 700 。不过对于 900 分的题目在那种压力下还可以接受。提交之后我花了 15 分钟左右测试，没有发现错误。于是就准备做 600 了。 600 分题目是：一道经典的数学题，给定一些盘子叠放的规则，计算顶层盘子的最大可能大小。其实算法不是很难，只要二分顶层盘子的大小，然后依次贪心计算来判断底层是否能够满足即可。只是贪心的时候要考虑两种情况，一时想不清楚。我当时已经感觉很疲劳，思路不是很清楚，最后 40 分钟时间也没能调试通过。这题过于琐碎， Room 1 中最终没有选手通过 600 分题，并且成就了一个刺激的 Challenge 阶段。 Coding 阶段我和 tomek 采用了截然不同的策略，我跳过 600 直攻 900 ，而 tomek 在 600 中挣扎了很长时间才放弃。 Coding 阶段结束时，有 4 名选手提交了 3 题。我依靠速度优势领先同样提交 250 和 900 的 tomek 35 分左右。 Challenge 阶段开始时，我盲 cha （ blind challenge ）了一个最后时刻提交的 900 分程序，但是由于我选择的数据实在太弱，失去了 25 分。这样我和后面的 tomek 只相差 10 分左右了，所以我决定只要 tomek 不动，我也不动了。其实，当时 tomek 已经知道自己的 900 是错的， Challenge 阶段他估计已经放弃了。我的 Challenge 阶段最终就以 -25 分结束。 之后的 Challenge 就是 Ying （王颖）展现勇气和智慧的舞台了。他 Challenge 掉了所有提交的 600 ，凭借 225 分的加分超过了我，排在榜首。这样比赛的形式也一目了然了， 7 位选手提交了 900 ，我依靠速度优势领先第四名 reid 超过 100 分。只要我两道题目能够 Passed System Test 就足以进入 Final Round 了。 System Test 之前，我和 Ying 讨论他 “ 超神 ” 的 Challenge 阶段。这是我第一次参加 TopCoder 的现场比赛，发现 System Test 结果显示是按照 System Test 之前的排名倒序进行的。测试到我时，除了 tomek 的 4 名选手的 900 都过了。显示我的结果时，两个绿框闪烁了很久终于显示出了两个大大的钩，我终于可以欢呼庆祝胜利了。我前面的 Ying 也两题全过了。这样我们两位中国选手得以在死亡之组携手出现，这场比赛真可谓是中国选手的胜利。 Reid 只能在 Wildcard 赛再作努力， tomek 则被直接淘汰出局了。 Final Round ： 接下来的两天里，我观看了 Room2 ， Room3 和 Wildcard 的比赛。第 2 天晚上我们参加了 TopCoder 赞助的 Laser Tag 游戏，我们所有中国人组成了一队，我的发挥很差，原因是这个游戏与 CS 不同，选手头上没有感光器，而我喜欢遇到人就攻击头部，所以狭路相逢多半是我失败。活动中，我有幸结识了许多 Dev 的神人，当时由于 vividmxx 没有参加， magicpig 和 PE 的竞争很激烈，最终 PE 获得了 “ 浙江大学建校 100 年来第一个 TCCC 冠军 ” 。记得赛后我 uncle 来到现场，我 uncle 是浙江大学本科毕业的， magicpig 见我 uncle 第一句话就是 “ 浙江大学建校有 100 年历史了吧？ ” 汗死了。另外 zjq 也获得了 Design 的亚军。 第三天中午 Championship Round 开始了。决赛时，场地里安装了很多摄像头，可以说我们的任何举动都在严密监视下了。这回我提前确认了题目分数是标准的 250-500-1000 的分布。参加决赛的选手除我之外有： andrewzta ， ardiankp ， bmerry ， Eryx ， mathijs ， Petr 和 Ying 。面对决赛选手的实力，我已经没有意义定一个类似于 “ 保几争几 ” 的目标了，努力发挥自己的水平是最应该做的。下面就是比赛的过程了： 250 分题目是：给定 n 个正三角形，每个顶点都有数字，选出 6 个三角形拼成一个正六边形，要求相邻的数字必须相同。三角形允许旋转，计算能够得到多少个本质不同的正六边形。题目很长，我仔细读了两遍才开始写，算法很清楚，就是枚举六边形中心和四周的 7 个数字，然后判断是否有足够的三角形。在判断本质不同的时候犯了一个错误，调试了几分钟，提交之后只有 215 分了，看了一下排名， Petr 有 232 分之高，其他选手都还没有提交。测试了几分钟发现程序的运行时间不是很稳健，很容易到达 0.8 秒左右，测试了 15 分钟之多才逐渐放心下来，因为基本上所有数据都 0.8 秒左右。赛后 Macsy 告诉我，我的程序速度瓶颈是在 set 的判断，所以时间比较稳定，不会超时。我当时的犹豫和没有经验浪费了至少 20 分钟的时间。 按照赛前的计划，我这时应该打开 1000 的题目的，但是由于自己对 250 没有信心，而且求稳思想比较重，我先打开了 500 分的题目。现在看来，开 500 分的题目并不算错误，其实在打开 500 分题目的时候，与 Petr 的差距不是很大。 500 分题目是：给定一个机器人的移动命令序列，要求计算结束时机器人的位置。由于移动序列中允许 () 这样的重复操作，直接模拟是超时的。这类题目的标准算法是利用矩阵乘法，由于之前对于此类题目没有经验，没有准备好就开始写了，导致矩阵处理失败。我果断放弃了调试，换用一种记录中间结果的搜索方法，写完的时候已经只有 280 分了。更重要的是我已经没有时间进攻 1000 分了。提交之后排在第 3 ，前面是 Petr 和 Eryx 。 1000 分题目是：给出一个排队取菜的模型，计算一个等待时间的排队序列。而且对于多种答案的情况，要求计算字典序最小的序列。题目其实不是很复杂，集合动态规划就可以解决，不过模拟取菜过程时需要非常注意细节。 Petr 提交了一个 660 分左右的程序， Ying 则在最后一分钟提交了 400+ 分，排在第 2 。 Challenge 阶段显得很枯燥无味，前两天大发神威的 Ying （ +225 ）和 Petr （ +300 ）都没有尝试 Challenge ，整个 Challenge 阶段没有任何一个 Successful Challenge 。 System Test 结果出来了，在 bmerry ， ardiankp 和 andrewzta 都只通过一题的结果出来之后，排在我后面的 mathijs 两题都 Pass ，随后我的 250 和 500 也都 Pass 了。但是，排名在我之前的 Eryx 和 Ying 的 500 分和 1000 分都 Failed System Test 了，我瞬间提升到了第二名的位置。不过虽然 Petr 的 1000 分挂了，但是他依旧凭借 250 和 500 的速度获得了冠军。 在这里说一下 1000 分的真实情况吧，因为这些时间来对于 TCCC2006 Final Round 的 1000 分题目有很多不同的说法。比赛结果中显示没有选手通过 1000 分题，如果仔细分析测试结果， Petr 的程序由于超时出错，而 Ying 的程序由于一个地方没有清 0 而导致错误，确实很可惜。因为如果 Ying 的 1000 能够 Pass 的话，他将是 TCCC 的冠军。不过 Ying 的算法犯了与造成 Petr 超时一样的错误，他们的动态规划程序比标准方法多出一个 n 倍的时间，我曾经成功生成了一个用例，可以让 Ying 和 Petr 的程序都超时，这个例子已经得到了 Ying 的认可。需要指出的是 TCCC2006 是 TopCoder 的测试机的速度还是很慢的，两个程序如果在现在的机子上运行可能只需要 1 秒左右了。 比赛之后和 uncle 到 downtown 游玩了一下，参加完颁奖晚会，第二天就回国了。 总结： TCCC2006 是我第一次参加 TopCoder 的现场比赛，很有幸能够在这么多的第一次中就进入决赛并且获得第 2 名的成绩。很感谢同参加比赛的同学 Macsy ， OpenGL ， Ying 还有 PMH 的关心和帮助，你们在我比赛时全程在场边，让我感觉很温暖。 另外，我还有幸认识了 visualage ，现在他已经是 arena 的负责人了吧。记得他和 OpenGL 在 Room 1 的 Challenge 阶段通过大声叫中文（在国外，这是最好的密码）告诉我 tomek 的 900 是错的，可惜我没有听见。 TCCC2006 对于中国来说是不小的收获，中国选手占领了 Dev 比赛， PE 获得 “ 浙江大学建校 100 年来第一个 TCCC 冠军 ” ， magicpig 和 zjq 分获 Dev 和 Design 的亚军，也就是说中国包揽了所有亚军。在比赛之余，我很高兴认识了众多 TopCoder 的朋友。 Petr 在决赛中表现了非常良好的状态， TCCC 的夺冠标志着 Petr 收获了 2006 年的大满贯。 Ying 也采用了很合理的策略，只可惜他的赌博由于运气差一些惜败。我采用了比较保守的策略，在所有决赛选手中排名第 2 ，这也是我在 TopCoder 的现场赛事中的最高名次了。 TCCC2006 我很感谢家人的关心，父母凌晨很早起床查看我的比赛结果，而 uncle 还特地赶来现场为我加油。这几年的 TopCoder 现场比赛的赞助商列表里都能找到 American Online(AOL) 的身影， TCCC2006 是 AOL 唯一一次进行了 3 个小时左右的全程直播，父母和 uncle 都在网络上观看了现场的影像直播。 TCCC2006 我神奇地保持了 100% 的正确率，我个人认为 TopCoder 现场比赛对正确率提出了更高的要求，我们不必太在意 Coding 阶段的那些高分，只要自己的程序是正确的，就是成功的。 利用假期空闲之时，将这几年 GCJ ， ACM ， TopCoder 参加的一些重要比赛作个回顾。回顾 GCJ2006 ， ACM2005 ， TCCC2006 和 ACM2006 之后，今天简要回顾一下国内个人赛场吧。 国内个人赛场 —— 百度之星 国内个人赛场中最重要的比赛要数每年一度的百度程序设计大赛，到今年为止已经举办了 4 届，每一届我都全身心地参加了比赛的全过程，百度程序设计大赛是中国举办的规模最大的公开程序设计比赛，其参加人数比许多世界范围的程序设计大赛的人数还要多得多。另外在 2006 年初， Google Beijing 举行了 Google Code Jam China 的比赛，刚刚开始参加 TopCoder 的我也加入了这次 GCJC 之旅。 第一届 baidu 程序设计大赛： 最早的国内个人程序设计比赛要回忆到 2005 年 9 月开始的第一届百度程序设计大赛了，源于宿舍走廊中的海报，我以尝试的心态报名参加了第一届百度程序设计大赛。每一届百度程序设计大赛都由初赛，复赛和现场决赛组成。 第一届百度程序设计大赛中，印象最深的复赛题目就是那道规模巨大的最小树形图问题了， 100000 的数据规模吓退了不少选手，我鼓足勇气提交了一个理论上能够运行的程序，顺利通过了复赛进入决赛。最小树形图算法在大多图论书上就接在最小生成树算法后面，但是其程序量远比最小生成树大，而且用途没有最小生成树广泛，在大多数竞赛中很少出现。我最早接触最小树形图算法是在 2003 年 4 月，当时正在复旦大学训练，记得关于这个问题和 xreborner 讨论了很长时间才得以证明算法的正确性并实现出高效的程序。 现场决赛于 2005 年 10 月底在北京举行，由于当年比赛的知名度不高，时间上还和 GCJ 冲突，没有太多的顶尖高手参加。清华大学除我之外只有 superzn （张宁，我们留 shell 一个人参加 ACM 北京赛区预赛 L ），当时 OpenGL 还是以高中生身份参加的，还有复旦大学的 xreborner 和 young （李阳）；中山大学的 magicpig ， Savior 和张子臻（不好意思，我不记得您的 ID 了，好像杭州 2008 的时候我们还说起此事）。我一直认为，现场比赛过程的一个重要的意义在于提供了一个老朋友重逢和结实新朋友的机会，选手之间的交流是比赛中最重要的组成部分之一，我很有幸能够在这些比赛中认识了众多牛人。 稍微回顾一下决赛的题目吧：决赛的题目是经典的 8 数码问题，给定初始状态和结束状态，计算最短需要的转移步数。对于分数相同的情况，按照程序的运行速度排名。比较容易想到的方法有： (1) 单向 BFS ：最坏情况需要 1s 左右。 (2) 双向 BFS ：如果先判断无解情况，这是 xreborner 使用的方法，平均情况大概 0.002 秒左右。 (3) A* 或者 IDA* ：先判断无解情况，然后通过距离启发函数搜索。平均情况大概 0.002 秒左右。我当时使用了 A* 的方法，但许多地方的实现不是很合理。 (4) 常量表，这是最有挑战的方法，因为决赛的提交量限制在 64K 以内。 现场比赛中， (2) 和 (3) 的使用人数比较多，速度相差无几，选手之间比拼的是各种细节和常数的处理。后来，我想出了一种速度非常快的方法： 首先使用 A* 加上 “ 卡节点 ” 技术，就是限制 A* 算法搜索过程中每层的节点个数上限，这种算法扩展节点个数在 100 左右。然后，由于上述算法的正确性不能保证，把所有反例打成常量，程序大概 50K 左右。很容易发现，这个程序的速度远比比赛过程中所有程序的速度都快得多。 最终我的程序以总时间 0.022 秒获得冠军， xreborner 和 Savior 以 0.026 分并列第二名。 xreborner 的程序很可惜，如果加入了无解判断，速度应该比我程序块， superzn 就更可惜了， superzn 的飘逸程序其实只有 0.020 秒，但是有一个数据错了。 记得颁奖之后，主持人邀请获奖选手发言，选手可以通过向前走一步选择优先发言。这时，我突然感觉大家把目光都聚焦到了我身上，向右一看，由于我站在最左边没有注意到右边的情况，可谁知其他选手都后退了一步，把我留在了看似向前一步的位置。 第二届 Astar-baidu 程序设计大赛： 第二届百度程序设计大赛没有等到 10 月，而是在 2006 年 6 月就拉开序幕。没有想到的是，第二届百度程序设计大赛竟然以我在一年前比赛中使用的 A* 算法的名字命名，感到非常荣幸。 记得复赛的题目非常正式，印象最深的要数 xreborner 招牌式的 Zuma ，我推了两个小时公式才得到了正确的动态规划方程，实现之后还由于 TLE 只有 30 分 (100 满分 ) 。还有 Ying 出的无向图最小割问题，我用网络流算法又超时了。不过最后一题，我的程序竟然比 xreborner 优化过的标程还快，真是不容易呀。清华的舍友 RealPlayer 在复赛中表现很兴奋，可惜由于一个很小的错误没能进入决赛。 参加第二次百度决赛的选手中有许多熟悉的面孔，清华的同学包括 shell ， OpenGL ， lympanda 还有 Macsy 。复旦大学也来了很多选手，其中除了 LemonTree 和 Topkiller （沈毅）之外，还有我刚到复旦时见过的 admin 和 funny 的身影。另外 magicpig 和 flymouse 也参加了，而且 magicpig 和我住一个房间，吃饭时记得他把桌上所有人的 Dev 功底全都鄙视了一遍，可惜 PE 不在场呀。比赛前还看到了 Srbga 的身影，据他说是被邀请一起来玩的，其实稍微用小脑判断一下就知道一定是参与出题的，有了 Srbga 的加盟，相信决赛题目绝对不会是一年前的风格了。 第二年决赛的题目是：著名的俄罗斯方块。写程序玩一个 10 列的标准 2 维俄罗斯方块游戏。 Srbga 设计了很有特色的记分方法和评分标准。对于记分方法，特别的地方是消去 1 行后没有得分，而同时消去 2 ， 3 ， 4 行的得分分别是 3 ， 6 ， 10 ，记分方法非常鼓励一次消去多行。评分标准则更奇怪了，有 50 种不同规模的数据，对于每组数据对所有选手的得分进行排名，前 8 名的选手依次得到 10 ， 7 ， 6 ， 5 ， 4 ， 3 ， 2 ， 1 分，也就是说，是存在可能性在测试结束之后分数仍然为 0 的。 比赛过程中，我花了许多时间来分析这个奇怪的评分标准。 对于这种评分标准，常见的策略有两大类： (1) 所有数据的成绩比较平均 (2) 在一种数据风格中特别突出呢。 根据数据描述， 50 个数据可以分为 10 种不同的风格。参加比赛的总共有 50 名选手，如果所有分数是完全平均分配的话，分数是 31 分，这个数字意义不大。但如果设想分数的 80% 会分配在前 10 名中（根据当时选手的水平，这个假设还是比较合理的），这样前 10 名的平均分数是 124 分左右，也就是说如果想挤进前 4 ，至少也要 100 分以上，如果想争取冠军估计需要 200 分左右。如果选择一种策略，使得它只在一种数据风格中特别突出，分数只有可怜的 50 分，而且很可能有许多有同样想法的选手，所以 (2) 不太可取。 在决定选择比较平衡的策略 (1) 的之后，需要再考虑一个问题，如果最终目标是 150 分，那么平均分数只需要 3 分，也就是说每个数据可以允许有 5 名选手超过自己。这些必要的分析帮助我明确了努力的方向，面对这种开放性的题目，多分析题目的特点往往可以达到事半功倍的效果。 还有一个重要环节是调整估价函数，机器学习其实是一个很好的策略，可惜我当时不会。其实当时我做的事情，本质上就是人工模拟机器学习，手工调整了 1 个半小时，眼都花了。而且我犯下了一个致命的错误，记得记分方法非常鼓励一次消去多行，也就是说对于平坦的数据，一次消去 1-3 行的权值应该可能设置为负数，而我只把他们设成了 0 ，使得程序对于平坦的数据分数不高。 Macsy 就考虑到了这一点，只可惜一个很奇怪的技术问题（在 Linux 和 Windows 下的 CLOCKS_PER_SEC 参数是不一样大的，想使用卡时策略时千万不能事先把这个数字取出来设置成 CONST ）使得 Macsy 没能成功。 由于 Macsy 和 LemonTree （同样的技术问题）的出局，我在许多数据中得到了很高的分数，最后的总分达到了是 255 ，领先了第 2 名有 99 分之多。其实现场的许多选手的程序风格相差并不大，可能我唯一多做的事情就是建立了一个博弈树，多搜索两层，这样比直接贪心的程序看得更远一些。后来事实也证明了，排名靠前的选手大多都是比较平衡的策略。记得 lympanda 洋洋洒洒写了 1800 多行程序，在其中一种数据中拿到了满分 50 分。不过可惜 panda 的程序平衡性稍差，总排名进入了前 10 ，但最终只有三等奖。 第二届 astar-baidu 程序设计大赛，复旦大学获得了丰收。记得许多复旦的选手由于考试提前回到学校，颁奖仪式的时候二等奖颁奖一片空场。 比赛的住宿条件可以用无与伦比来形容，很感谢 baidu 的大方与细心。记得第一天晚上还有机会和 Ikki 一起打沙壶球，面对球风完全对立的 Ikki 玩得很开心。 Google Code Jam China 2006 大概是 2005 年末，突然看到了名为 GCJC 的比赛，而且使用的是 TopCoder 的比赛模式，于是就报名参加了。当时估计只参加过几场 TopCoder 的比赛，帐号还是蓝色的， GCJC 第二轮预选赛由于经验不足差一点就被淘汰了。好在有惊无险地进入到了北京的现场赛。 GCJC 现场的选手中，我觉得至少认识 80% 吧，清华同学就有 7 人： b142857 ， fuwenjie ， lympanda ， Macsy ， zig 还有 hyyylr （李老师），复旦的 LemonTree 和 TopKiller 也都来了，浙大也来了许多 TopCoder 上的元老 xuchuan （徐串）， sghao126 。 记得，就在 GCJC 决赛的前一天晚上，我参加了 TopCoder 的 SRM 比赛，第一次踩住了 Petr ，不过也消耗了太多的 RP 。晚上的 SRM 比赛中没有人过 3 题，第二天早上 lympanda 还把我们统统鄙视了一遍。随后， b142857 还描述他 Challenge 过程中的囧事，由于 500 分题目的返回结果需要使用 long long 类型，所以 b142857 看到一个人提交的程序计算过程中只使用了 long 就果断 Challenge 了，结果失败了两次之后才发现，那个人用的语言是 Java 。 比赛中 250 分题目，简单的概率问题。我写完就交了 224 分，竟然是所有选手中最快的。后面的 500 分，我虽然提交是最快的，不过没有考虑一种情况。打开 1000 分题目之后网络就开始很不稳定了，时断时连， 1000 分题目其实算法很清楚，由于网络原因提交只有 600 分左右了。 Challenge 阶段开始时，我打开了房间中 lympanda 的 500 分程序，发现我们两人的程序基本过程完全一样。又打开了一个，也一样。但是在还没有反应过来的时候， lympanda 的 500 分程序被 Challenge 了，接着我的 500 分也被 Challenge 了。然后就没有什么斗志了，在无奈中等待比赛结束。 比赛结束之后的午饭过程中，我正好坐在 Google 中国掌门人李开复旁边。午餐快结束时，李开复问起 2 个月前的百度程序设计大赛，突然，鬼使神差地直接问我百度大赛的冠军是谁？这可是在 Google 的老巢呀，抖死了。我当时真害怕他听完回答之后直接把我赶下桌 tongueout 。 好在我的 250 分和 1000 分都 Pass 了，由于 TopKiller 的 1000 分超时了，我获得了第 3 名。冠军 xuchuan 和亚军 b142857 都顺利通过了 3 题。 POJ Monthly Contest 大概是从 2004 年 8 月开始， POJ 上开始举行每月一次的有奖月赛。 2005 年的月赛中，每次都有机会同 xreborner ， Ying 等高手切磋技艺。从 2006 年初开始，我已经比较熟悉了比赛的题风，连续获得了许多次比赛的冠军，并且保持了良好的个人比赛状态。 记得 2006 年 4 月底，在 POJ 的邮箱里突然发现了 hawk 的信，他问我五一长假回家的情况。我告诉 hawk 自己定在周五晚上出发。于是，第二天早上就看到比赛安排中： 2006 年 5 月份月赛安排在了周五晚上，太囧了。 后来， POJ 上直接出现了一系列奇怪的定义，但其实结论就是我不能以正式身份参加月赛了。现在这些定义早已成为笑料了，但是我不参加月赛之后，仍然有 ahyangyi 这样的选手夺走了绝大多数的冠军。 后两届 baidu 程序设计大赛： 从第二届开始，我们习惯了在每年 6 月等待 astar-baidu 的开赛。 2007 年最出乎意料的就要数 CS 这个决赛题目了，我在关键的买枪环节犯了重要错误，太迷恋 AK47 了。祝贺师兄 lympanda ， Macsy 还有 shell ，不愧是真金不怕火炼。 第四届百度大赛我参与了预赛和复赛的命题工作，但是没有参与决赛的命题。决赛题目是一道关于直升机的题目，印象最深的是 ahyangyi 使用了一个很有进攻性的策略，如果采用淘汰赛，可能就是冠军了。对我来说，通过现场比赛，有机会和老朋友重逢，并结识了许多新选手是我最大的幸事。 利用假期空闲之时，将这几年 GCJ ， ACM ， TopCoder 参加的一些重要比赛作个回顾。今天到了 2007 年初的东京，回顾一下 2007 世界总决赛发生的趣事吧。 ACM-ICPC World Final 2007 —— Mobile Robot 东京决战 2007 年的东京 ACM-ICPC 全球总决赛在樱花盛开的 3 月初拉开序幕。成立了一年的 Mobile Robot 凭借 2006 年 ACM 上海赛区的冠军，代表清华参加了此次 ACM 盛会。 记得黄金雄教授在杭州 2008 时说， ACM 总决赛的实力分布由原先的美洲独霸逐渐转向了现在的亚欧争霸。 2007 年，同样来自亚洲的上海交大具有很强的夺冠实力，欧洲 2007 年虽然没有顶尖高手 Petr 和 tomek 的参与，但是 ACM 传统名校 St. Petersburg ， St. Petersburg IMFO ， Warsaw ， Saratov ， Petrozavodsk 等都派出了极其豪华的阵容。虽然在 2000 年前后美洲队伍成绩不佳，但是近些年由于众多欧洲选手的加盟，美洲 MIT 等顶尖名校也在总决赛中表现得非常强势。 记得，每次世界总决赛之前， TopCoder 的论坛上都会罗列出所有参加总决赛的 TopCoder 选手名单。但是我不是很看重这些数据，因为在很多次与欧洲选手切磋之后，我发现了自己与欧洲选手相比的一个重大缺陷：我参加各类赛事以来，起初比赛过程中常常受压力的影响很大，很难正常发挥自己的水平。后来情况有所好转，在大多数比赛中都能正常发挥自己的水平。可是，令我感到意外的是，许多来自西方的选手在巨大的压力下，反而表现得极其兴奋而能超常发挥出自己的水平。来自西方的各队，我相信他们只要达到了兴奋的状态，都拥有获得冠军的实力。去年上海交大总决赛总结中，他们也提到了自己没有发挥出应有的水平，而 IMFO 即使在比赛压力下仍然能够做出 8 题，可见他们平时训练实力之强。但是我觉得现场比赛发挥受影响可能是少数中国选手的坏习惯，可能不适合用同样的思路分析欧洲的顶尖高手。 抵达东京： 出发的前一天晚上，我仍然熬夜参加了 TopCoder 上的 SRM 比赛，竟然是 Petr 出的题目。当时我与 Petr 的 Rating 差距很小，当时我 3 道题目都交出了很高的分数，在 System Tests 之前遥遥领先，但是 500 和 1000 分的题目都由于一些很小的粗心而失败了。我也失去了在总决赛之前超过 Petr 的大好机会。结果到达日本之后的第二天，吃早餐的时候，我就碰到了作为教练来到东京的 Petr ，他一看到我就扯前天比赛的事情，汗。现在回想起来，那场 SRM 对我的总决赛之旅确实有不小的负面影响。 抵达东京之后才发现，所有队伍中，只有我们选择了与所有志愿者衣服颜色相同的清华校色紫色，开幕式过程中，许多队伍都把我们当成志愿者了。 练习赛前一天的晚会很丰盛，大多食物都是中国风格的，水果也非常好吃。晚会期间，我见到了众多大陆学校的队伍，当年大陆至少有 15 支队伍参加总决赛，随处可以感觉到说着国语的选手。同时还见到了许多 TCCC 上出现过的面孔，随后发现 ardiankp 也来参加了，我们还聊起了 ACM 在新加坡（ ardiankp 是代表南洋理工大学参加的）的情况。类似总决赛这样的比赛，我觉得选手之间的交流则更重要了，因为每次总决赛都会集结众多熟悉的 ID 但陌生的面孔。晚一些之后，我们与北京大学的 T2 一起打牌，队友 geworm 和 wd.h 都抽签到了另一方，他们的牌太猛了，在加上我和李文新老师的牌都不好，结果我们惨败。 从正式比赛的前一天的中午开始，主办方组织我们游玩当地的 Disney 乐园。日本 3 月的景色很美，当地人也很热情，唯一的缺点就是无论用日语还是日式英语都很难交流。我们在 Disney 乐园中主要以观看表演为主，没有参与过多的活动。东京到了晚上有些冷，我嘴唇都有些结冰了，可是发现路上许多日本女高中生还穿着裙子，仰慕。 正式比赛： 总决赛的队伍是按照学校的音序排座位的，练习赛时我们发现自己坐在来自荷兰的上届亚军 Twente 大学旁边，刚打招呼就发现他们 3 人的最低身高也有 190 ，据说荷兰女子的平均身高也有 180 以上，似乎觉得自己是从小人国来的。 练习赛过程中，我已经丝毫感受不到娱乐的气息了，现场的紧张气氛已经笼罩了我们全队。所有队伍都在抓紧一分一秒熟悉比赛环境，赛场中敲击键盘的声音已经完全覆盖了观众鼓掌的声音。比赛中使用的 PC2 提交系统比想象得稳定，我们努力尝试各种功能以熟悉机子上的编程环境。东京的总决赛使用了一个形状奇特的键盘，由于当时早已养成了自带键盘的习惯，这次总决赛中奇形怪状的键盘对我编程的速度影响非常大。 总决赛正式比赛在第二天 9 点左右开始， Bill 想尽各种办法活跃气氛，不过比赛开始前几分钟现场还是静得可怕，比赛开始 5 分钟之后，现场就被键盘声笼罩直到结束。我们回顾一下比赛的过程吧，底纹的文字是我比赛后写下的总结： 这次 World Final 的题目又基本由编程题组成，可能是由于比赛时不够兴奋，比赛全程都非常不顺利。 大概从 2003 年开始，世界总决赛的题目风格已经完全倒向以编程题为主的特点，对此我们早有准备。不过由于时差问题，还有几天前 SRM 比赛由于错两题导致 Rating 跌停对我信心的影响，使我比赛中一直不是很兴奋。不过比赛过程中，我们仍然坚定的采用前面提到过的常用组队模式： (1) geworm 全程负责读题，思考算法和出数据； (2) wd.h 和我在比赛前 2 个小时一起攻简单的题目； (3) 2 小时后 wd.h 就开始死磕难题，我主写程序一直到 3 个半小时左右，结合 wd.h 对难题的把握，大家开始合攻难题。 25 分钟： Problem A ，简单地枚举。可是我生物没有学好，没有考虑父母基因的顺序问题，错了一次。 比赛开始时，正常情况我会从 B-I 中间寻找容易上手的题目。可是由于有些紧张，直到 geworm 给我翻译 A 题目内容时，我还没有读懂任何题目，这种情况很少发生。 题目 A 的描述，需要一些必要的生物知识帮助理解，可是这些东西我早已忘记。 geworm 花了不少时间帮助我理解这题，我还是由于没有考虑父母基因的顺序 WA 了一次。不过改过来之后，我们竟然是所有队伍中第一个通过 A 题的，可见当时很多队伍也没有完全放开。 43 分钟： Problem B ，最长上升子序列。开始算法没有想好，莫名其妙地错了一次。 如果说题 A 的 WA 是生物问题，那 B 的 WA 简直就是莫名其妙。 B 就是最长上升子序列问题，好像刚开始写时我和 wd.h 都没有想清楚，写了一个神鬼莫测的程序， WA 一次之后才改成正确算法。可是当时我们都没有想到的，总决赛中我们队伍莫名其妙的 WA 噩梦才刚刚开始。 97 分钟： Problem G ，枚举 + 模拟。这是很扯淡的一题，题目很容易看错，我们由于看错题目错了两次，等看到 Twente 大学过了之后才重读题目，找到了正确的理解，浪费了大量的时间。 G 的题目描述确实不是很清楚，许多队伍都发生了理解错误，我们也不例外。不过第 2 次提交错误就不能理解了，当时也不知道出于什么原因又提交了第二次，难道是想先抢一个提交冠军吗？当时我们确实受到了开局不顺利的影响，这样做在罚时本身就落后的情况更是下雪上加霜。 146 分钟： Problem F ， BFS 。其实这题是我发挥编程能力的机会，但是我开始用了一个很奇怪的搜索方法，错了一次才改用 BFS 过了。 在 G 题迷茫而放弃之后，我又尝试实现了 F 。 F 的第一次 WA 是我们 Final 之行的第三次 “ 莫名其妙 ” 了，我也不知道自己用了什么一种奇怪的搜索方法竟然过了样例，还马上提交了，面对这种情况我有些着急，表现得很不冷静。好在 geworm 及时提醒，我马上改成 BFS 过了。在这期间， wd.h 已经实现出了 I 题，并提交了一次，结果是 WA 。 178 分钟： Problem C ，排序 + 枚举。这题有一个阴险的地方，就是 theta&#x3D;0 的情况，还好我们考虑到了，这也是我们唯一一次 AC 的题目了。 C 题的算法其实非常清楚，阴险的情况我们也考虑到了，我终于没有再搞笑一次，这也是我们唯一一次 AC 的题目了。从通过 C 的时刻讲，我们的形式还是很有利的，因为难度很大的 I 我们已经实现得差不多了。 224 分钟： Problem D ，数学题。这题本是一道很简单的数学题目，但是不知出题人怎么想的，搞了一些没有任何意义的东西，真是这次题目的一大败笔。我们开始由于没有注意三点共线的情况错了 3-4 次，然后由于 int64 越界又错了 3-4 次，最后错了 7 次才 AC 。这题一共浪费了 1 个多小时。 在 BGF 各一次奇怪的 WA 之后，我们又完全陷在了 D 题的陷阱之中，如果顺利的话 D 题只需要 15 分钟就可以写完，可是我们忘记考虑了 D 题中很多的阴险情况，拖延了 1 个多小时，贡献了 7 个莫名其妙的 WA 。可是，当时我并没有想到，这已经是我 AC 的最后一道题目了。 227 分钟： Problem I ，数学 + 模拟。这题是 Jelly 写的，有很多特殊情况。 平心而论，我在总决赛上的状态不是很好，编程速度受到影响，而且有 10 次以上的错误提交。最后我们 7 题的罚时高达 1200 多，而上海赛区同样 7 题的罚时只有 700 多，从这一点上也可以看出当时实在不在状态。不过， wd.h 很好地执行了我们预定的组队模式，顺利完成了拖后中卫的角色。在我通过 D 题之后，他改正了 I 程序中的最后一个 bug 。 I 题最终也只有我们和华沙两支队伍通过，可是说是我们最终能够获得亚军的杀手锏。记得在颁奖仪式之前，基本上所有选手见到我都问 I 怎么做，我都统一回答：是胡伟栋做的。 我们依靠 I 题的 AC 首次排在了榜首。比赛进行了 227 分钟，能够在 200 分钟之后获得领跑的机会，我首次看到了夺冠的希望，上海和西安赛区的欢呼场面一次又一次从我眼前闪过。当时只有华沙大学通过 6 题，其他队伍都还不超过 5 题。 可是幸福只持续了短暂的 3 分钟，我们由于罚时太多而被华沙反超，华沙大学通过第 7 题时华沙队员的反应几乎疯狂， ICPC 的工作人员也用照片记录了这一时刻。 Problem E ，我们的算法应该是正确的：二分答案 + 最短路。但是不知程序犯了什么错误，没有 AC 。 Problem H ，很复杂的几何题目，我们的算法是：扫描。但是不知程序又哪里写错了，结果是 WA ，不是 TLE 。 虽然在接下来的 73 分钟时间内我们没有再过题，不过我们仍然拚杀到了最后一刻，拼尽全力而无怨无悔。无论是 E 还是 H ，我们都想出了正确的算法，并且成功写完了程序，但是 Judge 给出的结果一直是 WA 。我们不断测试数据，并修正了一些 bug ，但仍然不能通过第 8 题。在这种情况下的稳定过题能力我们确实特别没有训练过，华沙能够通过 8 题的超强实力确实很让人敬佩。比赛刚结束时， Petr 还特地赶来问我们有没有通过第 8 题， ICPC 的工作人员碰巧留下了照片。 当时我很希望能够借他的运气得到一个 Yes ，不过 PC2 还是不断返回 WA 直到最后。 后来， E 题就成了我写计算几何题目的一个巨大的心理障碍，直到 2 个月前在 Proxima 的一次训练中，在队友的支持下，我终于成功通过了一个更强版本的 E 题（题目在 UVA 上，题号是 11425 ，这题至今 2009.1 也还只有我和东京冠军队的 marek 通过）。 Problem J ，这是一道很复杂的算法题目，现在我还不能证明算法的正确性。更重要的是这题很容易实现一些看似正确的算法，可能没有做这题是我们这次比赛的唯一成功之处。 I 的算法大致如下： (1) X_i &#x3D; the mininum cut between V_i and V_0. (2) while (the graph is not empty) { (3) m &#x3D; min(X_i). (4) remove all nodes V_i whose X_i&#x3D;m. (5) let X_i &#x3D; min( X_i , m+ the mininum cut between V_i and V_0 ). } (6) return X_1. 这里提一个公开的秘密，最后显示华沙大学的结果时，他们成功通过了 E 题，可是比赛过程中，我们并没有看到他们挂起蓝色的气球，不知道来自浙江大学或者中山大学的选手能不能仔细回忆一下，当时你们应该坐在他们旁边。 颁奖： 最终，华沙大学以通过 8 题的成绩获得冠军， Mobile Robot 通过 7 题总用时 1200 分钟获得亚军。整场比赛，我们克服了开局的种种不利因素，成为全场第一支通过 7 题的队伍，亚军也是一个非常可喜的成绩了。由于华沙大学不来自亚洲，我们同时也获得了亚洲冠军。 颁奖仪式之后的表演很精彩，印象最深的要数那位 “ 神偷 ” 了，他在观众面前不断施展 “ 妙手空空 ” ，观众掌声不断。记得表演结束后大家等电梯时，那位演员从我们身边走过，我们都连忙确认自己的钱包和手机。 ACM-ICPC 东京总决赛在一片片掌声中落下帷幕。 总结： ACM-ICPC 总决赛结束后， Mobile Robot 又恢复了平静。 Mobile Robot 成立以来共获得了两个分区赛冠军和一个总决赛亚军，从那之后 Mobile Robot 就宣布解散了，也许唯一的遗憾就是没能获得一个真正的世界冠军。赛后，黄金雄教授也来向我们祝贺，从他的言语中，我们也感受到了一丝挥之不去的遗憾。 东京总决赛的几天里，我有机会结识了许多国内外朋友，也是这次日本之行的一大收获。同时也感谢众多 ACM 选手一年来对我们的关心和支持，当时 bbs.pku 上留下了一个很长的帖子，让我永生难忘。 在现场比赛中，我数次与欧洲选手直接交手，对他们的特点有一定的了解： (1) 欧洲选手的编程能力很强，很适应总决赛现有的题目风格。有些欧洲选手在 notepad 里写程序，然后直接提交的事迹绝非传说。 (2) 欧洲选手对于算法的灵活运用能力强，但是对于一些比较深的算法了解不多。例如此次总决赛的 J 题。 (3) 许多欧洲选手的现场抗压能力很强，即使在最后时刻仍然可以发挥出自己的水平。 在总结过复旦和 Srbga 出题的风格之后，总结一下我理解的总决赛题目风格吧： (1) Srbga 大哥出的题目和世界总决赛的题目风格近似，题目对编程能力提出了极高的要求。相比之下大多数题目对算法的要求不高。 (2) 总决赛题目对算法的考察范围非常广，但是对于某特殊的算法要求不高。 (3) 总决赛题目的时间限制很宽，出题人很提倡一题多解。而且数据没有想象得苛刻，随机算法有用武之地。 东京的总决赛已经结束快 2 年，今年寒假结束之后，我又要准备踏上总决赛征程了，希望这次我们 Proxima 能做的更好，将总决赛名次提高一位。 利用假期空闲之时，将这几年 GCJ ， ACM ， TopCoder 参加的一些重要比赛作个回顾。今天总结一下国际个人赛场吧。 国际个人赛场 —— 三大赛事 ACM-ICPC 总决赛结束后， Mobile Robot 就宣布解散了，也许唯一的遗憾就是没能获得一个真正的世界冠军。宣布退役 ACM 之后，我仍然连续参加了那之后的每一场世界范围的现场编程比赛，按照时间先后分别是： TopCoder Open( 简称 TCO)2007 ， TopCoder Collegiate Challenge ( 简称 TCCC)2007 ， TCO2008 以及 Google Code Jam( 简称 GCJ)2008 。每次比赛，我都度过了一段美好快乐的时光。 TopCoder 公司与三大赛事： TopCoder 公司大概在 9 年前成立，成立的原因有些让人匪夷所思，据说公司创立者原来是另一家 IT 公司的大股东，在把原来公司的股票转手之后换了一笔钱，开设了 TopCoder 公司。然而 Topcoder 和原来的 IT 公司有一个重要协议，就是 Topcoder 在创立之初的两年内不得从事软件开发的工作。于是 TopCoder 在前两年时间内以类似竞赛的方式从事软件开发的活动。经过 9 年的发展，现在 TopCoder 公司已经基本由算法竞赛转向软件开发了。 TopCoder 公司除了在网上举办 SRM 之外，每年还举办 TCO 和 TCCC 等现场赛事（当然还有 TCHS ，不过规模比较小，参与面也不是很大）， TCO 和 TCCC 分别在每年的 6 月和 11 月举行，每次大赛都能汇聚众多国际编程高手。另外， Google 公司从 2000 年开始，先在各大洲举办名为 Google Code Jam 的比赛，从 2002 年开始也举办全球范围的 Google Code Jam 。于是这些年来，大家一直把 TCO ， TCCC 和 GCJ 称为三大赛事。 2007 年之前的 GCJ 都是使用 TopCoder 的比赛形式， Topcoder 的算法竞赛有点类似于 IOI ， ACM-ICPC 之类的竞赛，题目是同一个类型的。每次比赛三道题目，一般分数分配为 250-500-1000 ，比赛分为 Coding ， Rest ， Challenge 和 System Test 四个阶段，时间各是 75 分钟（现场比赛 85 分钟）， 5 分钟， 15 分钟（现场比赛 10 分钟）和不定。 TopCoder 的现场比赛都由 3 个阶段组成：所有选手被分为 3 个组（称为 Room1 ， 2 ， 3 ），每组分别进行半决赛，每组前 2( 或 3) 名直接晋级决赛， 3-6 名晋级 wildcard 比赛， wildcard 比赛 12 人中的前两名填补决赛的最后 2( 或 1) 个名额，决赛由 8( 或 10) 名选手参加。由于三大赛事的比赛形式相差不大，每次现场决赛的选手中总是有许许多多熟悉的面孔。 三大赛事的波荡起伏： 可能细心的同学能够发现疑问，在文章最开始的一段中，我表明自己在 2007 年之后没有错过任何现场赛事，那为什么没有 GCJ2007 呢？其实原因很简单， Google 公司在 2007 年全年中只举办了面向美洲的比赛，没有举行面向全世界的公开赛。 GCJ2007 的搁浅也使得整个 2007 年只有 TopCoder 公司独自举办世界大赛。 但是，当大家以为 GCJ 将在记忆中淡去的时候， GCJ2008 重新登陆，而且新的比赛环境与形式给选手以焕然一新的感觉。这里先谈谈自己对这种新比赛环境的看法吧： GCJ2006 仍然使用的是 TopCoder 标准形式，也就是说和 TCO 以及 TCCC 完全一样，用一句话概括就是 Coding-250-500-1000-Challenge-SystemTests 。 GCJ2008 比赛环境结合了 ACM ， TopCoder 还有 IPSC(ipsc.ksp.sk) 等多种比赛的特色。 (1) 每道题目分为 Easy-Hard 两组数据，并且数据可以下载到本地，这点好像与 IPSC 很相似，另一个与 IPSC 的共同点就是，不限制选手使用的编程工具，包括肉眼观察或者人工搜索。 (2)Easy 数据则和 ACM 非常近似，即时提交评测，并且也设定了每次失败提交加 4 分钟的罚时。 (3)Hard 数据则更像 TopCoder 的形式了， Hard 数据由于是统一评测， System Tests 可以有效 地把悬念保留到最后一刻。 GCJ2008 的比赛形式是一种大胆的尝试，并且也已经有了很理想的结果。 另外，值得称赞的是， GCJ2008 中首次使用了分各大洲进行当地现场半决赛的赛制。使得排在前 500 名的选手得以参加各大洲的半决赛，也拉近了 Google 公司与选手之间的距离。从另一个角度来说，各大洲半决赛的方法很有效保证了决赛选手的水平。平心而论， TopCoder 现场比赛前的最后一轮网络淘汰赛对选手的压力很大，就连 Petr 在 2007 年都直接来了一个 “ 滑铁卢 ” ，连现场赛都没有进。而现场比赛的公平程度远超过网络赛，所以通过现场赛决定决赛选手可以一定程度上提高决赛选手的水平，至少我个人很赞同这种做法。 搁浅的比赛无独有偶，可能是受到了 2008 年全球经济危机的影响， TCCC2008 也停办了。而且我们都觉得， TCCC2007 很可能是 TopCoder 举行的最后一次 TCCC 了，当然 TopCoder 这样做没有不合理的地方。 TCO 则相对稳定一些，就连每年举行的地点都不变， TCO 连续 3 年在著名的赌城 Las Vegas 举行。今年应该也不会改变地点。 三大赛事的举办，我觉得选手最大的受益就是，比赛提供了一个到美国免费游玩的机会。我先后去过 7 次美国，其中 6 次都是参加编程比赛。通过比赛的机会，我们得以开阔眼界，结交朋友。我个人真心希望三大赛事能够继续举行，但是 2009 年秋天的 TCCC 和 GCJ 很可能同时停办，这也是一个不可回避的问题，让我们拭目以待吧。 美国之旅： 从 2007 年以来的 4 次现场比赛，虽然每次比赛过程中都有一些遗憾，但是现在回想起来都有不尽的乐趣。 TCO2007 是我第一次到达赌城，一下飞机就看到很多赌场 (CASINO) ，可谁知 TCO2007 整个比赛过程就是一场巨大的赌博。我当时由于不熟悉 Texas Hold’em 的规则，在半决赛中搞错了 Flush 和 Straight 的大小关系，结果初上赌场就倾家荡产而被淘汰出局。 TopCoder 比赛中竟然出赌博有关的题目，果然有 Las Vegas 的特色呀。不过在赌场里，我仔细研究了许多赌博游戏的规则，然后写了几个程序计算赌博的期望，但是发现标准概率模型下所有游戏的期望值全是负数（其实挺显然的），于是，也就以娱乐为目的和 lympanda 切磋了一下。 如果说 TCCC2006 的 Room1 是中国的胜利， TCO2007 的 Room1 则是中国的失败了，虽然 Ying 和 lympanda 都进入了 wildcard ，可是都由于一些小失误输掉了这次赌博。赛后 lympanda 请我去牛排馆吃饭，后来那个牛排馆也成为每次 TCO 比赛我们中国选手的主要聚会地点。 TCCC2007 的小组赛还比较顺利，我轻松击败了 gawry ， Per ， marek.cygan 获得小组第一挺进决赛。可是决赛中，我为了提高速度以超过 Petr ，再加上有些紧张，最后 500 分和 1000 分两题又都挂了，落到了第 5 名。 TCCC2007 地点设在了奥兰多，比赛结束后我们到附近的 Disney Land 去玩，那里的惊险游戏比国内刺激得多，有些远远超过我的极限，我们一行人一直玩到深夜才返回。许多选手还一起到奥兰多魔术队主场观看了 NBA 现场比赛，可惜最后一节成为了垃圾时间。 TCO2008 我也依靠飘逸的 1000 分题中 800+ 分的提交闯入决赛。决赛前我还和 visualage 聊天，夸耀自己从来没有所有题目全挂，更没有拿过负分。可是在随后的决赛中，这两个 “ 梦想 ” 就都实现了， PE 对我的评价是太紧张了。基本每次 TopCoder 现场比赛都能见到 PE ，谁知他每次怀疑我某些题目的正确性的时候，我的程序就一定是错的，如果下次我参加决赛，您就不要再看我程序了吧（呵呵，开个玩笑）。 不过在决赛 Challenge 阶段的最后时刻，我从第一视角目睹了 Petr 和 Tomek 的巅峰对决。在还有 15 秒钟结束时 Petr 还落后 Tomek 大概 30 分左右， Petr 成功 Challenge 了一个超过了 Tomek ，但是 Tomek 利用短短的 10 秒钟也提交了一个成功 Challenge 又超了回来，谁知 Petr 得到这个信息之后又提交了一个 Challenge ，可是运气稍差，如果那个数据用来 Challenge 我的程序的话， Petr 就能够在最后 1 秒再次夺回冠军的位置。能够到最后一秒还能有机会成功翻盘的一定是神一般的人物，能够把神一般的人物逼到最后一秒的也一定是神一般的人物，两个神一般的人物你来我往，为大家上演了一场精彩的比赛。 欧洲独霸： 又一次引用黄金雄教授在杭州 2008 时说的话， ACM 总决赛的实力分布由原先的美洲独霸逐渐转向了现在的亚欧争霸。但是，我根据这些年的比赛结果发现，从 2006 年开始，团体比赛和个人比赛，特别是个人比赛，欧洲选手一直保持着绝对的霸主地位，亚欧争霸的说法实在有些牵强。 从 2005 年开始，几乎所有三大赛事的冠军都是欧洲选手。成绩最好的要数俄罗斯，俄罗斯选手以 Petr ， andrewzta 等为代表。俄罗斯选手训练刻苦，编程能力极强。欧洲的另一霸主就是波兰，波兰选手具有很强的灵气，以 tomek ， marek 以及 Eryx 为代表，程序设计在他们手中体现出了艺术气息。 前几天我也看到关于取消 NOIP 保送 资格的文章，我没有发表评论，因为我没有看懂，为什么文章里把保送和保送资格混为一谈，让人觉得哭笑不得。这里我对 保送 资格还是想法不多，不过想比较一下我们中国选手与欧洲选手思维能力上的差别。 在高中时，吴文虎老师就常说中国选手的 IOI 成绩很优秀，的确这几年从 IOI 成绩上看，中国是绝对的霸主。可是 ACM-ICPC 的成绩，俄罗斯和波兰等强队的成绩却远在中国之上。于是我们总结的原因是：欧洲选手的编程能力强。我非常同意这个说法。 但是 “ 欧洲选手的编程能力强 ” 的说法并不说明他们的算法能力弱，相反他们的思维素质非常高，他们具有非常正统和严密的思维方式，体现出经过长期训练的思维能力和素质。 我觉得中国的 “ 高手 ” 和许多通过高考进入名校的 “ 神人 ” ，在大学之前接受的教育都是以选拔为目的的，并没有太多针对思维方式和能力的训练。记得小学要考重点初中，初中则拼搏重点高中，高中期间则梦想名牌大学，而在学习期间，我们并没有太多机会训练自己的思维能力，至少在我的中学阶段是这样的。虽然很多高中已经竭尽全力通过类似研究性学习的方法锻炼我们的创新能力，但是仍然不能改变选拔性考试 “ 高考 ” 这一事实。而在与西方选手交流的过程中，我觉得许多思维能力优秀的学生很早就有机会接受系统的思维能力训练，寻找最适合自己的思考方法。我一次有机会看 Eryx 留下的草稿，发现他考虑问题有非常严密的过程，从理解题目到想出算法每步都有根有据，并不是随机碰撞的结果。 现在欧洲选手与我们相比，思维能力上也并没有劣势。我有幸在投身 OI 竞赛之后，得到许多机会与其它选手交流，学习他们的思考方法，努力锻炼自己这方面的能力，试图与众多欧洲选手对抗。 Mountain View 登顶： GCJ2008 在 Google 总部 Mountain View 举行，赛前我想用 Ying 的一句话来表达我对比赛夺冠的渴望， “ 我虽然获过很多奖，但是缺少一个世界冠军 ” 。早在 GCJ2006 ，我就拥有机会获得冠军，但是在失去那次机会之后一等就是整整的两年。 比赛开始不久， bmerry 的强势起跑使我逐渐失去了夺冠的念头，只得一心做好眼前的题目。 bmerry 在不到 2 个小时的时间里就做出了除了 C- Hard 以外的所有题目，他只要在最后一小时做出 C- Hard ，就基本上可以锁定冠军了。 不过我克服开场的不顺利之后，磕磕碰碰地在 2 小时过 5 分顺利通过了 E-Easy 和 E-Hard 。摆在我面前的只有 B-Hard 和 C-Hard 。 B 题和 C 题相比之下， B 题我已经有了一定的想法，可是 C 则是完全没有想法。于是我决定先做 B ， GCJ2008 的 B 题简直是我的克星，我先后用了 100 分钟时间做这题都没有结果，可以说当时状态很差。大概到了 2:40 的时候，我查看 board 时突然发现了一件令人窒息的事情， bmerry 已经尝试了 C-Hard 并且超时了。由于 C-Hard 的分数略高于 B-Hard ，我最后想要超过 bmerry 就必须做出 C-Hard 。果断放弃 B-Hard 之后，并没有想出 C-Hard 的方法，写了一个搜索程序但是心里很没底， Hard 数据的提交时限是 8 分钟，于是到了 2 小时 52 分的时候，我毅然打开 C-Hard ，用搜索的程序运行 C-Hard ，在焦急的等待之后，程序在运行了 1 分多钟以后神奇地运行结束了。我依靠搜索方法通过了 C-Hard ，一举超过了 bmerry 。 1 分钟后 zhuzeyuan 也做出了同样的题目，超过了 bmerry ，由于罚时排在第 2 名。我和 zhuzeyuan 还有 bmerry 比赛过程中都有不小的失误，我很有幸把失误的损失降到了最低点，终于获得了第一个世界比赛的冠军。 这次 GCJ 的题目有非常详细的解答，可以在比赛的链接里找到。 GCJ2008 的比赛结果从一定意义上，打破了欧洲选手多年的独霸场面。加上原籍南非的 bmerry ，前五名中都没有出现欧洲选手的名字，这也是在多年现场比赛中没有出现过的。 这一年，我很高兴看到 OI 选手中出现了 ahyangyi ， yuhch123 ， Loner 等各方面都极为出色的新人，真心希望你们能够早日适应大学的学习生活，再创佳绩。 众多新人的加盟，大大提高了清华 ACM 团队的实力。在 2008 年，清华大学 ACM 队创纪录地获得了 4 个分区赛的冠军。明天最后一篇回忆中将分享 ACM-2008 中发生的趣事。 利用假期空闲之时，将这几年 GCJ ， ACM ， TopCoder 参加的一些重要比赛作个回顾。最后是 2008 年的杭州复出。 2008 年 ACM-ICPC —— 杭州复出 2006 年 ACM-ICPC 总决赛结束后， Mobile Robot 就宣布解散了，也许唯一的遗憾就是没能获得一个真正的世界冠军。宣布退役 ACM 之后，我并没有完全与 ACM 绝缘，每次 TopCoder 大赛之前还常常做一些 ACM 比赛调整状态。记得 08 年初，我也全程观看了总决赛，不过没有想过复出。 杭州复出： 一切事情要从一个 zhuzeyuan 的电话说起，时间是 11 月 8 日 晚上 10 点左右，当时我正在参加 UVA 在线比赛而为 GCJ2008 作准备。 zhuzeyuan 在电话里首先告知我 Loner 车祸的事情，好在现在 Loner 已经痊愈了，当时确实很担心。随后， zhuzeyuan 向我介绍了 2008 年 ACM 比赛的进行情况，当时北京和哈尔滨赛区已经结束。然后，邀请我加入 Proxima 参加杭州赛区的比赛。我想当时答应的原因主要有 3 个：(1) 我个人很喜欢 Coding ，虽然退出 ACM 已经快两年了，但是还经常参加个人比赛。刚刚结束的 GCJ2008 中国区半决赛，出人意料的夺冠增强了我的信心。另外， ACM 这样长达 5 个小时的团队比赛造就了很特别的环境，赛场上的气氛和激情是做裁判教练或者参加个人比赛中无法体会到的。(2) 3 年前的 2005 ACM 杭州赛区，我留下了我大学生活中的一大遗憾。对于杭州 2005 的惨败，我一直想寻找机会从那个跌倒的地方爬起来，彻底摆脱紫金港校区留下的阴影。(3) 其实还有一个原因就是我家在杭州，而且在本科期间我也曾经到杭州电子科技大学做过关于 ACM 的报告， lcy 老师的热情给我留下了深刻的印象。对于 Loner 的车祸，我也觉得非常意外。这也是对于我们常年在校园骑自行车里横冲直撞的警示。 Loner 现在能够恢复得这么好，我们都很高兴，祝你明年 ACM 好运。加入 Proxima 的手续很顺利，教练邬老师对我复出想法的回答简单扼要：研一学生可以参加 ACM 比赛。Proxima 的另外两名队友分别是 zhuzeyuan 和 zhouyuan （周源），我加入 Proxima 之后，新 Proxima 先后进行了 3 次训练比赛，随后就出发到杭州电子科技大学参加 2008 年 ACM 杭州赛区的比赛了。当时，我通过许多网上资料和 zhuzeyuan 的描述了解了当时清华的战绩。到杭州赛区之前，清华的 What ’ s Up 和 IronGods 已经分别获得了哈尔滨和北京赛区的冠军。其中 IronGods 还获得了哈尔滨赛区的亚军， What ’ s Up 则一起来到杭州参加比赛。 Proxima 在杭州赛区之前已经参加了北京赛区的比赛，成绩是第二名。就当时的形势讲，我们没有资格考虑太多事情，如果想保留悬念就必须获得杭州赛区的冠军。 杭州赛区现场赛： 在杭州赛区练习赛那天的上午，我们抓紧一切时间进行了模拟训练，选择的题目是 NEERC 的题目。题目难度有些大，我们做满整整 5 小时，直到 12 点 50 才急忙去吃午饭。结果很晚才到达比赛场地，到时候练习赛已经开始很久了。希望我们的迟到没有影响旁边队熟悉比赛坏境。杭电赛场的环境很好，在赛场里我找回了 2006 年上海赛区的感觉。队伍之间的空间很宽敞，电脑桌也很大，足以让 3 个人在上面一起推导公式。马上就见到了 lcy 老师，不过他带来了一个不太好的消息 —— 不允许自带键盘。好在杭电提供的键盘很标准，对我们影响不大。正式比赛在第二天早上 9 点开始，回顾一下比赛的过程吧：在 Proxima 队中，比赛开始时，仍然由我准备编程环境，然后从中间开始读题。我马上发现了 D 是一道看似简单的题目，并且也注意到了这句话： WARNING: a naive algorithm might not be sufficient to solve this problem. 但是没有想到的是 BFS 算法也算是 naive algorithm ，我交出了全场第一个提交，结果是理所当然的 TLE 。不过那句 WARNING 稍微有些飘逸。 zhuzeyuan 发现 A 是简单题目，于是我马上写 A 。 19 分钟， A ：判断两张图的修改距离。枚举全排列，统计即可。 A 是最简单的题目，由于开始 D 的耽搁，我们大概是全场第 4 个出题的队伍。 接着， zhouyuan 发现 J 也很简单，于是我转向 J 。 28 分钟， J ：允许删点的并查集问题。通过添加新点的方法实现删点。 过了 J 之后，排名暂时上升到第一位。随后， zhuzeyuan 发现没有新题可写，于是就开始写 C ，过程中，我和 zhouyuan 发现 G 比较简单，于是插空写 G 。 50 分钟， G ：简单图论问题。开始删点判断错误造成 WA 了一次。 59 分钟， C ：高精度计算和素数判定问题。这题是 zhuzeyuan 写的。 不到一个小时就通过了 4 题， Proxima 获得了一个很好的开局。对于杭州赛区难度的题目，能够在第一个小时通过 4 题已经很顺利了。对于许多分区赛中会出现更多的简单题目的情况，有时能够做到一小时 5 题。但是一小时 6 题实在太难了，记得我们在一次训练比赛中做到了一小时 6 题，已经是我们的能力极限了。 接下来我实现了一下 B ，可是由于发生了理解错误，计算结果与题目要求计算的结果直接存在重复排列问题，只好把程序放在一边。 随后， zhuzeyuan 开始实现 H ，提交之后我开始写 F 。 95 分钟， H ：计算几何，如果使用 O(n2) 的算法需要注意常数不易太大。 105 分钟， F ：自动机判断相等问题，通过计算差乘的方法能够在 O(n2*|Sigma|) 内解决 H 的提交等了很久， H 的 Yes 出来后不久我就写完了 F ，提交之后也 Yes 了。大概在 2 个小时左右我们做出了 6 题，其实如果不在 B 上浪费时间能够更早一些。在 2008 杭州赛区，我们又一次获得了 6-4 的领先优势。 下面我们面临一个比较困难的状况， E 和 I 看似都比较复杂，但明白题意的 B 和 D 都没有想出算法。 2008 年杭州赛区的题目中，基本没有中等难度的题目，所以我们通过 6 题之后就直接进入了比赛后期。当时我们分了一下工，我决定死磕 D 题， zhouyuan 负责推 B 题的公式。 zhuzeyuan 尝试新题目 E 或者 I 。 我的工作进行很不顺利，先实现了一个普通的 A* 算法，由于优化得不好还是 TLE 。现在回想起来， D 题标准 A* 算法中使用的那个优化还是挺巧妙的，至少很有艺术感。我放弃 A* 算法之后， zhouyuan 似乎已经推好了 B 题的公式，开始帮助我实现 D 题。 163 分钟， D ：状态最短路径问题，通过 A 算法加一些优化可以轻松通过。* zhouyuan 提出了一个很重要的优化方法，先通过解方程的方法判断是否有解，在确认有解的情况下使用双向广度优先搜索，程序写好之后又 TLE 了。不过我觉得运行时间已经差不多了。于是，我使用了卡节点的方法，终于在第 5 次提交通过了 D 。 D 题我们用了大概一个小时左右。这时 What ’ s Up 早已通过 5 题，不过由于他们卡在 H 题上，我们仍然以 7-5 领先。 zhuzeyuan 确认 E 和 I 比较复杂之后，我们开始合攻 B 题。 zhouyuan 其实受到了我原先错误算法的误导，他得到一些公式来计算繁衍函数，通过繁衍以及原先程序的结果得到正确结果。不过，从当时的形式看，这样也是很不错的选择。 程序很快就写好了，提交之后又是奇怪的 TLE 。 B 题的 TLE 和 D 的 TLE 本质完全不同， B 题我们算法的复杂度是 O(n4) 的，对于 n&lt;&#x3D;20 的数据范围，时间上应该没有问题。于是，我生成了 100 组测试数据，发现总共只需要 1 秒左右。 在 B 题的这一点上，我觉得命题人做的很不合理，虽然此题存在 O(n3) 的算法，但是既然把范围出到 20 ，就应该允许 O(n4) 的算法通过。可是命题人一共叠出了 6000 组测试数据，使得我们的程序超时了。而且在 Clarify 中的回答是 1000 多组，我们优化程序之后还是一直 TLE ，当时我们怎么会想到是 6000 多。至少这里的范围 20 极具误导性。幸好， zhuzeyuan 及时想出了一个解决方法 —— 打表。由于对程序没有信心，打表的 15 分钟时间内我们 3 人都只得通过手工计算简单数据来确认程序的正确性。 236 分钟， B ：比较复杂的动态规划，需要考虑 4 种情况。 打完表之后提交终于得到了第 8 个 Yes ，时间是 236 分钟，距离封版只有 4 分钟。由于 6000 组的阴险数据，我们从第一次提交 B 题到通过 B 整整用了 50 分钟，而且是 3 个人一直在一起做。 封版时，我们仍保持了 8-6 的领先优势。但是接下来，我们犯下了杭州 2008 最大的错误，如果类似的错误在总决赛中出现，我们将很可能失去领先位置。当时我们没有看到港大挂起 E 的气球，于是在 E 和 I 中选择了 I ，结果深深地陷在了 I 的无底洞中，直到结束都不能自拔。 I ：模拟题，需要考虑的情况比较多。 E ：计算几何。计算半平面的交。 现在回想起来， E 题的难度远没有 I 题大，我们错误估计了 I 的难度。非常敬佩赛场上通过 E 题的港大和 I 题的湖南大学，你们不愧为射雕英雄。 清华 2008 战况： 2008 年，清华延续自己在 ACM 大陆赛区中的霸主地位， 4 支不同的队伍获得了创纪录的 4 个不同赛区的冠军。分别是： What ’ s Up —— 哈尔滨赛区冠军 IronGods —— 北京赛区冠军 Proxima —— 杭州赛区冠军 ZCS —— 成都赛区冠军 从 ACM 的规则上讲 4 支队伍都获得了进军总决赛的资格，清华总决赛队伍的选拔过程在成都赛区结束的第二天就开始了。 从我的角度描述另 3 支队伍的情况吧： What ’ s Up 是清华第一个获得冠军的队伍，杭州赛区的过程中，他们以 amber 主写程序的模式进行，在比赛开始阶段体现出了很强的冲击力，不过卡住 H 后的慌乱略显出组队模式的缺陷。虽然他们在杭州赛区之后就选择放弃了总决赛资格的争夺，但是我们都深知他们的实力。后来 What ’ s Up 的成员担任了 PK 比赛的裁判工作。 ZCS 由刚进入清华学习的三名大一学生组成，成员是 yuhch123 ， Cheryl 和 ScaleRhyme 。我参加 Proxima 之后没有和 ZCS 交过手，不过在 Ural 和 SGU 上比赛时看到过 ZCS 的身影。在杭州赛区之后， ZCS 在成都赛区创造了 7&#x2F;7(7 提交 7 通过 ) 奇迹，不过和北京赛区相似的是后期略显经验不足。随后， ZCS 没有参加校内 PK 赛。 IronGods 的组成是 OpenGL ， ahyangyi 和 ghy 。在 IronGods 成立之初，我一直很看好这支队伍。哈尔滨赛区结束后，记得 ahyangyi 还来和我抱怨比赛中的失误，那道高精度题目确实有些过于复杂（呵呵，不过至少数据没有错误）。北京赛区的情况，我是事后听 dzx 介绍的， IronGods 依靠最后一小时的稳定发挥，通过 3 题，一举压倒 Proxima ， Carriage 和 ZCS 获得冠军。可是几天后，我惊奇的发现自己需要面对强大的 IronGods 了。 IronGods 的组合与新 Proxima 惊人得相似， IronGods 的 OpenGL 与 ahyangyi 还有我和 zhuzeyuan 都是 TopCoder 上的 Target （中国一共有 7 个 Target ，另外 3 个是前辈 haha ， lympanda 和 ZCS 队中的 yuhch123 ，看好 zhoujie 成为第 8 个，加油呀！），他们的编程能力与我和 zhuzeyuan 不相上下。从 TopCoder 的成绩上看，我们两人的速度略快。 另一名队员 ghy 和 zhouyuan 都很擅长思考算法， ghy 结束 OI 时间比较短，状态保持得很好， zhouyuan 对于深入的算法了解比较扎实（北京的 A 很赞呀！）。 从配合上说， IronGods 组队时间长，配合方面比我们默契许多。我们重组后虽然也进行了一些训练，不过在比赛中普遍交流偏少，特别是我和 zhouyuan 的交流，在后几场比赛中才有些成功的配合。 不过从稳定性角度看，我们稍占上风， TopCoder 上的 Volatility 值至少可以说明一些。而且 ACM 比赛时间长达 5 小时，稳定性的要求应该比 TopCoder 还高一些。 清华校内 PK ： 后来， zhuzeyuan 代表 Proxima 与 IronGods 协商之后，大家决定采用三局两胜的赛制，并定下了 3 场比赛的时间和题目安排。 关于总决赛队伍的选拔，我个人非常不赞成直接指定，可能与我的一些经历有关吧。已经进入研究生学习的我，对参加总决赛已经没有两三年前的激情了。不过我个人的观点是，如果学校指定，我对于 4 种结果都可以接受；如果进行 PK 选拔，赛场上我一定拼尽全力。 两场 PK 过程中，我们都在 bbs.pku 上发布了现场的即时排名情况。由于清华 ACM 团队有严格规定要求对两次 PK 中使用的题目保密，我这里就只留下了比赛的大致过程。 第一场 PK ，时间和吉隆坡赛区完全相同，过程大致如下： Proxima 启动比较快，到 2 小时左右就获得了 5:2 的领先优势。 题 F 是这场比赛中我们最大的失误， F 浪费了很多时间，而且最后都没有过。 IronGods 利用 Proxima 卡住 F 的时机连追 4 题，以 6:5 反超。 发现 IronGods 反超之后，我又尝试了几次 F 题，但还是不能通过。比赛还有 70 分钟结束，而且我们手上并没有其他题目。 zhuzeyuan 在关键时候毅然决定开始写 J ，记得他说的一句话是 “ 没有时间了，我必须开始写了 ” ，当时形势不容乐观。好在 J 成功 1Y ，士气大振。 Proxima 随后连过两题重新占据 7:6 优势。 最后， IronGods 追成 7:7 平，比赛又打得难解难分。 IronGods 最后时刻也还有机会，我们又一次目睹了 IronGods 的绝地反击实力，可能他们最后做 H 的选择值得商榷。 第一场 PK 过程中两支队都有明显失误的时期，我们由于失误在中期，所以罚时较少。最后依靠罚时险胜，在 PK 中占得先机。 第二场 PK ，时间设在 12 月 25 日 的晚上进行，题目编号从 A 到 L ，共有 12 题之多。第二场 PK 比前一场进行得更激烈，过程中两支队伍都长时间保持了很好的状态，比赛过程中多次交换领先位置： 开局 Proxima 起步略快， 65 分钟就通过了 5 题 BDEFK 。 开局看似顺利，不过我们都明白：真真的比拼还没有开始。 Proxima 卡在了 H 和 C 上， IronGods 通过了 BCDFK 追成 5:5 平，罚时 Proxima 领先。 IronGods 通过了 G ，首次反超 6:5 。 Proxima 经过 rejudge 通过了 H ，出现了 6:6 平，罚时 Proxima 领先。 Proxima 第 10 次提交才通过了 C ，再次获得题数领先 7 :6 。 如果输掉了这次 PK ，题 C 则是最大的败笔。 IronGods 通过了 J ，追成 7:7 平， IronGods 在罚时上领先。 此时的罚时落后就是 Proxima 在 C 题上出错 9 次的恶果。 Proxima 第 4 次提交才通过 G ，以 8:7 反超，但罚时还是很大。 IronGods 通过了 H ，又追成 8:8 平，利用罚时 IronGods 再次获得领先。 这已经是第 6 次出现平分了。这时还不到 3 个小时，校内 PK 赛的题目难度并不在 2008 杭州赛区的难度之下， 3 小时的 8:8 的高比分平局是现场比赛中很难看到的。而在高比分平局中罚时也是很重要的，此时 IronGods 占据明显的优势。 Proxima 经过 rejudge 通过了 I ，再次超出 9:8 。 Proxima 通过了 J ，优势扩大到 10:8 。 记得题 J 的第一次提交开始的返回结果是 “ Other-Contact Staff ” ，看到这个回复之后 zhuzeyuan 马上跑到 Judge 室，在被工作人员挡住之后， zhuzeyuan 很奇怪地问道 “ 难道不是你们让我来 Contact 的吗？ ” ，囧死了。不过很快就 rejudge 成 Yes 了，题 J 的通过也从一定意义上逆转了罚时的不利， IronGods 如果想翻盘就必须在最后一小时重新上演北京赛区封版通过 3 题一幕。 Proxima 通过了 A ，优势扩大到 11:8 。 记得最后提交 A 题的时候，我紧张得手都有些发抖了。当时只剩下 25 分钟， IronGods 还没有开始写 A 和 L 两题，所以在最后的时间里他们已经不可能通过余下的 4 题了。 A 题的 Yes 也就成为了这场 PK 的胜利宣言。 IronGods 最后时刻通过了 I ，最终题数为 11:9 。 此次校内 PK 的激烈程度决不亚于 2006 年上海赛区，能够最终赢得这场 PK 使得我们更有自信地站在总决赛的现场。 首先感谢关心我们的同学，记得第一场 PK 当天正在举行吉隆坡赛区比赛， bbs.pku 上还是出现了如此多的帖子为我们双方加油。第二场 PK 结束时已经是晚上 11 点，我们手机还不断收到祝贺短信。 向 IronGods 三位天王致敬，在 PK 过程中只需略微的变化，出现在斯德哥尔摩的就很可能是你们。棋逢对手是我 ACM 生涯的一大幸事，相信你们明年一定能够做得更好。 我想这是清华第一次使用公开的现场 PK 方式来选拔总决赛队伍，个人觉得 PK 的方式除了公平之外还有许多优点。首先， PK 方式可以使得各队伍能够更从容地选择和准备不同的分区赛赛区，有效提高学校的总体成绩。其次，通过 PK 的过程，可以加强各队之间的交流，队伍各方面水平能够得到全面提高。真是一举两得。 利用假期空闲之时，将这几年 GCJ ， ACM ， TopCoder 参加的一些重要比赛作个回顾，包括今天一共 10 篇。接下来的重要比赛就是世界总决赛了，纵观世界总决赛各队，虽然形势不容乐观，但我们一定会拼尽全力。 原文链接","tags":[{"name":"楼天城","slug":"楼天城","permalink":"http://aeyoo.net/tags/楼天城/"}]},{"title":"Java编程思想","date":"2015-05-08T05:48:06.000Z","path":"2015/05/08/Java编程思想/","text":"介绍一些Java语言的细节。 thisthis关键字只能在方法内部使用，表示对“调用这个方法的对象”的引用。如果在同一个方法内部调用同一个类的另一个方法，不必使用this。返回对当前对象的引用有的时候是一种有效的方法。经常在构造器中使用this。 staticstatic方法就是没有this的方法。在static方法的内部不能调用非静态方法，反过来是可以的。通过类本身调用static方法，实际上正是static方法的主要用途。 static确实具有全局语义。如果代码中出现大量的static方法，就该重新考虑自己的设计了。 无论创建多少个对象，静态数据都只占用一份内存区域。static关键字不能应用于局部变量，因此它只能作用于域（类的成员变量）。 构造器是静态方法。 初始化Java尽量保证，所有变量在使用前都能得到恰当的初始化。 对于方法的局部变量，Java以编译时错误的形式来贯彻这种保证。 对于类的数据成员则略有不同。如果类的数据成员是基本类型，则会被赋予一个初始值。 boolean -&gt; false char -&gt; 0（显示为空白） byte&#x2F;short&#x2F;int&#x2F;long -&gt; 0 float&#x2F;double -&gt; 0.0 对象引用 -&gt; null Set集合Set 转 String[]： String[] array = set.toArray(new String[0]); 但是这通常不是好的，摘自stackoverflow: When you pass toArray() an array of too small size, the toArray() method has to construct a new array of the right size using reflection. This has significantly worse performance than passing in an array of at least the size of the collection itself. Therefore [0] should be replaced with [myset.size()] as in the accepted answer. String[] array = set.toArray(new String[set.size()]);","tags":[{"name":"Java编程思想","slug":"Java编程思想","permalink":"http://aeyoo.net/tags/Java编程思想/"}]},{"title":"java 引用可能造成的一些小问题","date":"2015-04-27T11:32:49.000Z","path":"2015/04/27/java-引用可能造成的一些小问题/","text":"最近粗心导致项目出了一点bug，调试了一个小时才发现是java引用的问题。一般地，我们不在循环内进行变量的定义和分配内存，因为循环次数太多的话容易造成内存溢出。我通常也遵循这样的规则，但是在一些特殊情况下常常忘记变量的处理（重新初始化或别的）。常见的有两种情况： 将本该在循环内定义的Collection变量定义在循环外部，如下代码： 123456789101112131415dataRowToDataSet(List&lt;String&gt; windows)&#123; List&lt;List&lt;String&gt;&gt; dataSet=new LinkedList&lt;&gt;(); List&lt;String&gt; recond=new LinkedList&lt;&gt;(); for(int i=0;i&lt;windows.size();i++) &#123; String[] strs=windows.get(i).split(&quot;,&quot;); for(String s:strs) &#123; recond.add(s); &#125; dataSet.add(recond); &#125; return dataSet;&#125; 此种写法是错误的。会不断地加入新元素。即使在第一个循环结尾加上recond.clear()也是错误的，因为recond从始至终指向同一块内存。正确的写法应该把 1List&lt;String&gt; recond=new LinkedList&lt;&gt;(); 放到 12345678910111213141516public static List&lt;List&lt;String&gt;&gt; dataRowToDataSet(List&lt;String&gt; windows)&#123; List&lt;List&lt;String&gt;&gt; dataSet=new LinkedList&lt;&gt;(); List&lt;String&gt; recond=null; for(int i=0;i&lt;windows.size();i++) &#123; String[] strs=windows.get(i).split(&quot;,&quot;); recond=new LinkedList&lt;&gt;(); for(String s:strs) &#123; recond.add(s); &#125; dataSet.add(recond); &#125; return dataSet;&#125; 两个List之间的赋值方式如下（忌用&#x3D;进行引用赋值）： 12List&lt;String&gt; subLabels=new LinkedList&lt;&gt;();subLabels.addAll(labels); //labels is other list.","tags":[]},{"title":"C和C++基础语法集锦","date":"2014-12-07T08:55:08.000Z","path":"2014/12/07/C和C-基础语法集锦/","text":"不常用C&#x2F;C++，整理一些基础语法备忘。 编译器知识一般在苹果机之外的电脑，printf() 从左往右扫描，从右往左计算。在苹果机下，printf 从左往右扫描，从左往右计算。这其实和编译器用的c库有关。一般大家为了方便，直接通过在mac下安装xcode，进而达到安装c库的目的。所以在使用printf()的时候最好避免进行计算。下面代码在mac运行下为 2 2 2 2，别的电脑下运行为： 2 2 3 2。 1234567891011121314#include &lt;stdio.h&gt;int main()&#123; int a = 2; int *p = &amp;a, *q = &amp;a; printf(\"%d %d\\n\", *p++, *(q++)); p = &amp;a; q = &amp;a; printf(\"%d %d\\n\", *p, (*q)++); return 0;&#125; 类型转换1. int to charint a = 1; char b = a+&#39;0&#39;; 2. char to intC语言中每一个字符都是一个数字（ANSII码），int to char 只要减 ‘0’ 就好。char在技术实现上是整数类型， char a = &#39;1&#39;; int b = a-&#39;0&#39;; 待续。 函数 scanf()函数返回的值为：按指定格式正确地输入变量的个数。具有短路性质，即当第n个变量输入错误时，返回n-1，而不对之后的变量正确性做判断。出错时则返回EOF（-1）。 集合set和multiset会根据特定的排序准则，自动将元素进行排序。不同的是后者允许元素重复而前者不允许。 获取UNIX时间戳在Linux系统中，时间戳是一个绝对值，表示距离时间（1970-1-1, 00:00：00）的秒数。在C\\C++ 语言中，用数据类型 time_t 表示时间戳，time_t 本质上是一个long int。 目前许多操作系统使用32位二进制数字表示时间。此类系统的Unix时间戳最多可以使用到格林威治时间2038年01月19日03时14分07秒（二进制：01111111 11111111 11111111 11111111）。其后一秒，二进制数字会变为10000000 00000000 00000000 00000000，发生溢出错误，造成系统将时间误解为1901年12月13日20时45分52秒。这很可能会引起软件故障，甚至是系统瘫痪。使用64位二进制数字表示时间的系统（最多可以使用到格林威治时间292,277,026,596年12月04日15时30分08秒）则基本不会遇到这类溢出问题。[2] time(2) - Linux man page 1234567891011121314151617#include &lt;time.h&gt;time_t time(time_t *t);Descriptiontime() returns the time as the number of seconds since the Epoch, 1970-01-01 00:00:00 +0000 (UTC).If t is non-NULL, the return value is also stored in the memory pointed to by t.Return ValueOn success, the value of time in seconds since the Epoch is returned. On error, ((time_t) -1) is returned, and errno is set appropriately.ErrorsEFAULTt points outside your accessible address space.Conforming toSVr4, 4.3BSD, C89, C99, POSIX.1-2001. POSIX does not specify any error conditions. 实现代码如下： 12345678910111213141516171819#include&lt;iostream&gt;#include&lt;string&gt;#include&lt;time.h&gt;#include &lt;sstream&gt;using namespace std;int main()&#123; time_t now; time(&amp;now); cout&lt;&lt;now&lt;&lt;endl; //time_t转换为string类型 stringstream ss; ss &lt;&lt; now; string curtime = ss.str(); //c++11 可以使用to_string(now) cout&lt;&lt;v&lt;&lt;endl; return 0;&#125; 参考 1 c语言中的时间戳和时间格式 2 c++ 时间类型详解 time_t","tags":[{"name":"C/C++","slug":"C-C","permalink":"http://aeyoo.net/tags/C-C/"}]},{"title":"散列表","date":"2014-11-28T09:16:46.000Z","path":"2014/11/28/散列表/","text":"定义维基百科定义：[ 散列表（Hash table，也叫哈希表），是根据键（Key）而直接访问在内存存储位置的数据结构。也就是说，它通过计算一个关于键值的函数，将所需查询的数据映射到表中一个位置来访问记录，这加快了查找速度。这个映射函数称做散列函数，存放记录的数组称做散列表 ] 一句话说：散列的实质就是在元素的存储位置和它的关键码（key）之间建立一种函数映射关系。使得关键码和存储位置一一对应： Address=hash(key) 散列函数 取余法（或者叫除留余数法），常用 数字分析法 平方取中法(mid-square) 折叠法 取余法的散列函数表示为：hash ( key ) &#x3D; key % p p&lt;&#x3D;m 除数选择：设散列表允许的地址数为m，取一个不大于m，但是最接近或等于m的质数p作为除数。 冲突解决技术因为不同的key，可能散列之后映射到相同的地址，所以冲突解决是很有必要的。冲突解决可以分为两类： 开散列方法 ( open hashing，拉链法，separate chaining，链地址法) 闭散列方法 ( closed hashing，开地址方法，open addressing )。 线性探查法 (linaer probing） 二次探查法 (quadratic probing) 双散列法 区别：开散列法把发生冲突的关键码存储在散列表主表之外，而闭散列法把发生冲突的关键码存储在表中另一个槽内。 搜索成功的平均搜索长度ASL： 是指搜索到表中已有元素的平均探查次数； 搜索不成功的平均搜索长度ASL：是指在表中搜索不到待查的元素，但找到插入位置的平均探查次数。即从每个位置起到第一个为空的位置时的探查次数的和的平均数。 注：内容大部分是对《数据结构 &#x2F; 殷人昆》散列表的总结。","tags":[{"name":"hash","slug":"hash","permalink":"http://aeyoo.net/tags/hash/"},{"name":"散列","slug":"散列","permalink":"http://aeyoo.net/tags/散列/"}]},{"title":"Hexo如何添加多说评论分享组件","date":"2014-11-24T05:27:50.000Z","path":"2014/11/24/Hexo如何添加多说评论分享组件/","text":"添加多说组件，让每个人听到你的声音。 添加多说评论在站点配置文件_config.yml（根目录下）中添加多说的配置： 1duoshuo_shortname: 你站点的short_name #申请多说评论组件时设置的 然后在themes\\landscape\\layout_partial\\article.ejs文件中，将 1234567&lt;% if (!index &amp;&amp; post.comments &amp;&amp; config.disqus_shortname)&#123; %&gt; &lt;section id=\"comments\"&gt; &lt;div id=\"disqus_thread\"&gt; &lt;noscript&gt;Please enable JavaScript to view the &lt;a href=\"//disqus.com/?ref_noscript\"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt; &lt;/div&gt; &lt;/section&gt;&lt;% &#125; %&gt; 替换成 1234567891011121314151617181920&lt;% if (!index &amp;&amp; post.comments &amp;&amp; config.duoshuo_shortname)&#123; %&gt; &lt;section id=\"comments\"&gt; &lt;!-- 多说评论框 start --&gt; &lt;div class=\"ds-thread\" data-thread-key=\"&lt;%= post.layout %&gt;-&lt;%= post.slug %&gt;\" data-title=\"&lt;%= post.title %&gt;\" data-url=\"&lt;%= page.permalink %&gt;\"&gt;&lt;/div&gt; &lt;!-- 多说评论框 end --&gt; &lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt; &lt;script type=\"text/javascript\"&gt; var duoshuoQuery = &#123;short_name:'&lt;%= config.duoshuo_shortname %&gt;'&#125;; (function() &#123; var ds = document.createElement('script'); ds.type = 'text/javascript';ds.async = true; ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js'; ds.charset = 'UTF-8'; (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(ds); &#125;)(); &lt;/script&gt; &lt;!-- 多说公共JS代码 end --&gt; &lt;/section&gt;&lt;% &#125; %&gt; 添加多说分享在多说后台管理的左栏，有一个“+”的图标，复制右边面板的代码。粘贴到themes\\landscape\\layout_partial\\article.ejs文件的 &lt;footer&gt; &lt;\\footer&gt; 标签中。 如下图所示： 被我注释掉的是Disqus（Hexo默认的评论插件），关于data-thread-key等参数的值和多说评论代码的值一样，直接照我的写就好了；data-images和data-content的值我没细看，应该也是post.xx，感兴趣可以看一下post文件。 当添加了多说分享组件之后，会发现它会出现在home首页-每篇文章的摘要下面（关于如何设置摘要见下面），这是不科学的，所以我只想让它出现在每篇文章中。 Hexo设置摘要是通过 &lt;!--more--&gt; 实现的，如图标注1。你只需要在你的文章中添加此标志，则该标志之前的内容会被当做摘要。 所以我在文件起始处定义了一个flag&#x3D;0（标志3），当文章需要显示摘要的时候（即打开home首页），设置flag&#x3D;1（标志2）；设置当flag&#x3D;&#x3D;0的时候，加载多说分享组件（见第二幅图标志1）。如此便实现了显示全文加载多说分享组件，显示摘要不加载组件的功能。","tags":[]}]