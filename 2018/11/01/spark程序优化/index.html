<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="努力成为一名实力很强的小白"><title>spark程序设计优化 | TiuVe</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=2.0.1"><link rel="stylesheet" type="text/css" href="/css/highlight.css?v=2.0.1"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="stylesheet" type="text/css" href="/css/donate.css"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">spark程序设计优化</h1><a id="logo" href="/.">TiuVe</a><p class="description">气蒸云梦泽，波撼岳阳城</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/./archives/"><i class="fa fa-archive"> 归档</i></a><a href="/./about/about.html"><i class="fa fa-user"> 关于</i></a><a href="/./project/project.html"><i class="fa fa-archive"> work</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="搜索"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">spark程序设计优化</h1><div class="post-meta"><a href="/2018/11/01/spark程序优化/#comments" class="comment-count"></a><p><span class="date">Nov 01, 2018</span><span><a href="/categories/大数据/" class="category">大数据</a></span></p></div><div class="post-content"><p>本文介绍一下spark使用过程中的一些优化方法。内容完全转载自美团的技术文章《<a href="https://tech.meituan.com/spark_tuning_basic.html" target="_blank" rel="noopener">Spark性能优化指南——基础篇</a>》，酌情删减了一部分内容。建议查看原文，感觉原文的界面好看一些。</p>
<p>Spark的性能调优实际上是由很多部分组成的，不是调节几个参数就可以立竿见影提升作业性能的。需要根据不同的业务场景以及数据情况，对Spark作业进行综合性的分析，然后进行多个方面的调节和优化，才能获得最佳性能。</p>
<p>spark性能优化主要分为四个部分：</p>
<ul>
<li>开发调优</li>
<li>资源调优</li>
<li>数据倾斜调优</li>
<li>shuffle调优</li>
</ul>
<p>开发调优和资源调优是所有Spark作业都需要注意和遵循的一些基本原则，是高性能Spark作业的基础；数据倾斜调优，主要讲解了一套完整的用来解决Spark作业数据倾斜的解决方案；shuffle调优，面向的是对Spark的原理有较深层次掌握和研究的同学，主要讲解了如何对Spark作业的shuffle运行过程以及细节进行调优。</p>
<p>以下主要讲解<strong>开发调优以及资源调优</strong>。</p>
<h2 id="开发调优"><a href="#开发调优" class="headerlink" title="开发调优"></a>开发调优</h2><h3 id="调优概述"><a href="#调优概述" class="headerlink" title="调优概述"></a>调优概述</h3><p>Spark性能优化的第一步，就是要在开发Spark作业的过程中注意和应用一些性能优化的基本原则。开发调优，就是要让大家了解以下一些Spark基本开发原则，包括：RDD lineage设计、算子的合理使用、特殊操作的优化等。</p>
<h3 id="原则一：避免创建重复的RDD"><a href="#原则一：避免创建重复的RDD" class="headerlink" title="原则一：避免创建重复的RDD"></a>原则一：避免创建重复的RDD</h3><p>通常来说，我们在开发一个Spark作业时，首先是基于某个数据源（比如Hive表或HDFS文件）创建一个初始的RDD；接着对这个RDD执行某个算子操作，然后得到下一个RDD；以此类推，循环往复，直到计算出最终我们需要的结果。在这个过程中，多个RDD会通过不同的算子操作（比如map、reduce等）串起来，这个“RDD串”，就是RDD lineage，也就是“RDD的血缘关系链”。</p>
<blockquote>
<p>我们在开发过程中要注意：对于同一份数据，只应该创建一个RDD，不能创建多个RDD来代表同一份数据。</p>
</blockquote>
<p>一些Spark初学者在刚开始开发Spark作业时，或者是有经验的工程师在开发RDD lineage极其冗长的Spark作业时，可能会忘了自己之前对于某一份数据已经创建过一个RDD了，从而导致对于同一份数据，创建了多个RDD。这就意味着，我们的Spark作业会进行多次重复计算来创建多个代表相同数据的RDD，进而增加了作业的性能开销。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 需要对名为“hello.txt”的HDFS文件进行一次map操作，再进行一次reduce操作。也就是说，需要对一份数据执行两次算子操作。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 错误的做法：对于同一份数据执行多次算子操作时，创建多个RDD。</span></span><br><span class="line"><span class="comment">// 这里执行了两次textFile方法，针对同一个HDFS文件，创建了两个RDD出来，然后分别对每个RDD都执行了一个算子操作。</span></span><br><span class="line"><span class="comment">// 这种情况下，Spark需要从HDFS上两次加载hello.txt文件的内容，并创建两个单独的RDD；第二次加载HDFS文件以及创建RDD的性能开销，很明显是白白浪费掉的。</span></span><br><span class="line"><span class="keyword">val</span> rdd1 = sc.textFile(<span class="string">"hdfs://192.168.0.1:9000/hello.txt"</span>)</span><br><span class="line">rdd1.map(...)</span><br><span class="line"><span class="keyword">val</span> rdd2 = sc.textFile(<span class="string">"hdfs://192.168.0.1:9000/hello.txt"</span>)</span><br><span class="line">rdd2.reduce(...)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 正确的用法：对于一份数据执行多次算子操作时，只使用一个RDD。</span></span><br><span class="line"><span class="comment">// 这种写法很明显比上一种写法要好多了，因为我们对于同一份数据只创建了一个RDD，然后对这一个RDD执行了多次算子操作。</span></span><br><span class="line"><span class="comment">// 但是要注意到这里为止优化还没有结束，由于rdd1被执行了两次算子操作，第二次执行reduce操作的时候，还会再次从源头处重新计算一次rdd1的数据，因此还是会有重复计算的性能开销。</span></span><br><span class="line"><span class="comment">// 要彻底解决这个问题，必须结合“原则三：对多次使用的RDD进行持久化”，才能保证一个RDD被多次使用时只被计算一次。</span></span><br><span class="line"><span class="keyword">val</span> rdd1 = sc.textFile(<span class="string">"hdfs://192.168.0.1:9000/hello.txt"</span>)</span><br><span class="line">rdd1.map(...)</span><br><span class="line">rdd1.reduce(...)</span><br></pre></td></tr></table></figure>

<h3 id="原则二：尽可能复用同一个RDD"><a href="#原则二：尽可能复用同一个RDD" class="headerlink" title="原则二：尽可能复用同一个RDD"></a>原则二：尽可能复用同一个RDD</h3><p>除了要避免在开发过程中对一份完全相同的数据创建多个RDD之外，在对不同的数据执行算子操作时还要尽可能地复用一个RDD。比如说，有一个RDD的数据格式是key-value类型的，另一个是单value类型的，这两个RDD的value数据是完全一样的。那么此时我们可以只使用key-value类型的那个RDD，因为其中已经包含了另一个的数据。对于类似这种多个RDD的数据有重叠或者包含的情况，我们应该尽量复用一个RDD，这样可以尽可能地减少RDD的数量，从而尽可能减少算子执行的次数。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 错误的做法。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 有一个&lt;Long, String&gt;格式的RDD，即rdd1。</span></span><br><span class="line"><span class="comment">// 接着由于业务需要，对rdd1执行了一个map操作，创建了一个rdd2，而rdd2中的数据仅仅是rdd1中的value值而已，也就是说，rdd2是rdd1的子集。</span></span><br><span class="line"><span class="type">JavaPairRDD</span>&lt;<span class="type">Long</span>, <span class="type">String</span>&gt; rdd1 = ...</span><br><span class="line"><span class="type">JavaRDD</span>&lt;<span class="type">String</span>&gt; rdd2 = rdd1.map(...)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 分别对rdd1和rdd2执行了不同的算子操作。</span></span><br><span class="line">rdd1.reduceByKey(...)</span><br><span class="line">rdd2.map(...)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 正确的做法。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 上面这个case中，其实rdd1和rdd2的区别无非就是数据格式不同而已，rdd2的数据完全就是rdd1的子集而已，却创建了两个rdd，并对两个rdd都执行了一次算子操作。</span></span><br><span class="line"><span class="comment">// 此时会因为对rdd1执行map算子来创建rdd2，而多执行一次算子操作，进而增加性能开销。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 其实在这种情况下完全可以复用同一个RDD。</span></span><br><span class="line"><span class="comment">// 我们可以使用rdd1，既做reduceByKey操作，也做map操作。</span></span><br><span class="line"><span class="comment">// 在进行第二个map操作时，只使用每个数据的tuple._2，也就是rdd1中的value值，即可。</span></span><br><span class="line"><span class="type">JavaPairRDD</span>&lt;<span class="type">Long</span>, <span class="type">String</span>&gt; rdd1 = ...</span><br><span class="line">rdd1.reduceByKey(...)</span><br><span class="line">rdd1.map(tuple._2...)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 第二种方式相较于第一种方式而言，很明显减少了一次rdd2的计算开销。</span></span><br><span class="line"><span class="comment">// 但是到这里为止，优化还没有结束，对rdd1我们还是执行了两次算子操作，rdd1实际上还是会被计算两次。</span></span><br><span class="line"><span class="comment">// 因此还需要配合“原则三：对多次使用的RDD进行持久化”进行使用，才能保证一个RDD被多次使用时只被计算一次。</span></span><br></pre></td></tr></table></figure>

<h3 id="原则三：对多次使用的RDD进行持久化"><a href="#原则三：对多次使用的RDD进行持久化" class="headerlink" title="原则三：对多次使用的RDD进行持久化"></a>原则三：对多次使用的RDD进行持久化</h3><p>当你在Spark代码中多次对一个RDD做了算子操作后，恭喜，你已经实现Spark作业第一步的优化了，也就是尽可能复用RDD。此时就该在这个基础之上，进行第二步优化了，也就是要保证对一个RDD执行多次算子操作时，这个RDD本身仅仅被计算一次。</p>
<p>Spark中对于一个RDD执行多次算子的默认原理是这样的：每次你对一个RDD执行一个算子操作时，都会重新从源头处计算一遍，计算出那个RDD来，然后再对这个RDD执行你的算子操作。这种方式的性能是很差的。</p>
<p>因此对于这种情况，我们的建议是：对多次使用的RDD进行持久化。此时Spark就会根据你的持久化策略，将RDD中的数据保存到内存或者磁盘中。以后每次对这个RDD进行算子操作时，都会直接从内存或磁盘中提取持久化的RDD数据，然后执行算子，而不会从源头处重新计算一遍这个RDD，再执行算子操作。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">对多次使用的<span class="type">RDD</span>进行持久化的代码示例</span><br><span class="line"><span class="comment">// 如果要对一个RDD进行持久化，只要对这个RDD调用cache()和persist()即可。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 正确的做法。</span></span><br><span class="line"><span class="comment">// cache()方法表示：使用非序列化的方式将RDD中的数据全部尝试持久化到内存中。</span></span><br><span class="line"><span class="comment">// 此时再对rdd1执行两次算子操作时，只有在第一次执行map算子时，才会将这个rdd1从源头处计算一次。</span></span><br><span class="line"><span class="comment">// 第二次执行reduce算子时，就会直接从内存中提取数据进行计算，不会重复计算一个rdd。</span></span><br><span class="line"><span class="keyword">val</span> rdd1 = sc.textFile(<span class="string">"hdfs://192.168.0.1:9000/hello.txt"</span>).cache()</span><br><span class="line">rdd1.map(...)</span><br><span class="line">rdd1.reduce(...)</span><br><span class="line"></span><br><span class="line"><span class="comment">// persist()方法表示：手动选择持久化级别，并使用指定的方式进行持久化。</span></span><br><span class="line"><span class="comment">// 比如说，StorageLevel.MEMORY_AND_DISK_SER表示，内存充足时优先持久化到内存中，内存不充足时持久化到磁盘文件中。</span></span><br><span class="line"><span class="comment">// 而且其中的_SER后缀表示，使用序列化的方式来保存RDD数据，此时RDD中的每个partition都会序列化成一个大的字节数组，然后再持久化到内存或磁盘中。</span></span><br><span class="line"><span class="comment">// 序列化的方式可以减少持久化的数据对内存/磁盘的占用量，进而避免内存被持久化数据占用过多，从而发生频繁GC。</span></span><br><span class="line"><span class="keyword">val</span> rdd1 = sc.textFile(<span class="string">"hdfs://192.168.0.1:9000/hello.txt"</span>).persist(<span class="type">StorageLevel</span>.<span class="type">MEMORY_AND_DISK_SER</span>)</span><br><span class="line">rdd1.map(...)</span><br><span class="line">rdd1.reduce(...)</span><br></pre></td></tr></table></figure>

<p>对于persist()方法而言，我们可以根据不同的业务场景选择不同的持久化级别。</p>
<h4 id="Spark的持久化级别"><a href="#Spark的持久化级别" class="headerlink" title="Spark的持久化级别"></a>Spark的持久化级别</h4><p><img src="/images/20181104_1.png"></p>
<h4 id="如何选择一种最合适的持久化策略"><a href="#如何选择一种最合适的持久化策略" class="headerlink" title="如何选择一种最合适的持久化策略"></a>如何选择一种最合适的持久化策略</h4><ul>
<li>默认情况下，性能最高的当然是MEMORY_ONLY，但前提是你的内存必须足够足够大，可以绰绰有余地存放下整个RDD的所有数据。因为不进行序列化与反序列化操作，就避免了这部分的性能开销；对这个RDD的后续算子操作，都是基于纯内存中的数据的操作，不需要从磁盘文件中读取数据，性能也很高；而且不需要复制一份数据副本，并远程传送到其他节点上。但是这里必须要注意的是，在实际的生产环境中，恐怕能够直接用这种策略的场景还是有限的，如果RDD中数据比较多时（比如几十亿），直接用这种持久化级别，会导致JVM的OOM内存溢出异常。</li>
<li>如果使用MEMORY_ONLY级别时发生了内存溢出，那么建议尝试使用MEMORY_ONLY_SER级别。该级别会将RDD数据序列化后再保存在内存中，此时每个partition仅仅是一个字节数组而已，大大减少了对象数量，并降低了内存占用。这种级别比MEMORY_ONLY多出来的性能开销，主要就是序列化与反序列化的开销。但是后续算子可以基于纯内存进行操作，因此性能总体还是比较高的。此外，可能发生的问题同上，如果RDD中的数据量过多的话，还是可能会导致OOM内存溢出的异常。</li>
<li>如果纯内存的级别都无法使用，那么建议使用MEMORY_AND_DISK_SER策略，而不是MEMORY_AND_DISK策略。因为既然到了这一步，就说明RDD的数据量很大，内存无法完全放下。序列化后的数据比较少，可以节省内存和磁盘的空间开销。同时该策略会优先尽量尝试将数据缓存在内存中，内存缓存不下才会写入磁盘。</li>
<li>通常不建议使用DISK_ONLY和后缀为_2的级别：因为完全基于磁盘文件进行数据的读写，会导致性能急剧降低，有时还不如重新计算一次所有RDD。后缀为_2的级别，必须将所有数据都复制一份副本，并发送到其他节点上，数据复制以及网络传输会导致较大的性能开销，除非是要求作业的高可用性，否则不建议使用。</li>
</ul>
<h3 id="原则四：尽量避免使用shuffle类算子"><a href="#原则四：尽量避免使用shuffle类算子" class="headerlink" title="原则四：尽量避免使用shuffle类算子"></a>原则四：尽量避免使用shuffle类算子</h3><p>如果有可能的话，要尽量避免使用shuffle类算子。因为Spark作业运行过程中，最消耗性能的地方就是shuffle过程。shuffle过程，简单来说，就是将分布在集群中多个节点上的同一个key，拉取到同一个节点上，进行聚合或join等操作。比如reduceByKey、join等算子，都会触发shuffle操作。</p>
<p>shuffle过程中，各个节点上的相同key都会先写入本地磁盘文件中，然后其他节点需要通过网络传输拉取各个节点上的磁盘文件中的相同key。而且相同key都拉取到同一个节点进行聚合操作时，还有可能会因为一个节点上处理的key过多，导致内存不够存放，进而溢写到磁盘文件中。因此在shuffle过程中，可能会发生大量的磁盘文件读写的IO操作，以及数据的网络传输操作。磁盘IO和网络数据传输也是shuffle性能较差的主要原因。</p>
<p>因此在我们的开发过程中，能避免则尽可能避免使用reduceByKey、join、distinct、repartition等会进行shuffle的算子，尽量使用map类的非shuffle算子。这样的话，没有shuffle操作或者仅有较少shuffle操作的Spark作业，可以大大减少性能开销。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Broadcast</span>与map进行join代码示例</span><br><span class="line"><span class="comment">// 传统的join操作会导致shuffle操作。</span></span><br><span class="line"><span class="comment">// 因为两个RDD中，相同的key都需要通过网络拉取到一个节点上，由一个task进行join操作。</span></span><br><span class="line"><span class="keyword">val</span> rdd3 = rdd1.join(rdd2)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Broadcast+map的join操作，不会导致shuffle操作。</span></span><br><span class="line"><span class="comment">// 使用Broadcast将一个数据量较小的RDD作为广播变量。</span></span><br><span class="line"><span class="keyword">val</span> rdd2Data = rdd2.collect()</span><br><span class="line"><span class="keyword">val</span> rdd2DataBroadcast = sc.broadcast(rdd2Data)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在rdd1.map算子中，可以从rdd2DataBroadcast中，获取rdd2的所有数据。</span></span><br><span class="line"><span class="comment">// 然后进行遍历，如果发现rdd2中某条数据的key与rdd1的当前数据的key是相同的，那么就判定可以进行join。</span></span><br><span class="line"><span class="comment">// 此时就可以根据自己需要的方式，将rdd1当前数据与rdd2中可以连接的数据，拼接在一起（String或Tuple）。</span></span><br><span class="line"><span class="keyword">val</span> rdd3 = rdd1.map(rdd2DataBroadcast...)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注意，以上操作，建议仅仅在rdd2的数据量比较少（比如几百M，或者一两G）的情况下使用。</span></span><br><span class="line"><span class="comment">// 因为每个Executor的内存中，都会驻留一份rdd2的全量数据。</span></span><br></pre></td></tr></table></figure>

<h3 id="原则五：使用map-side预聚合的shuffle操作"><a href="#原则五：使用map-side预聚合的shuffle操作" class="headerlink" title="原则五：使用map-side预聚合的shuffle操作"></a>原则五：使用map-side预聚合的shuffle操作</h3><p>如果因为业务需要，一定要使用shuffle操作，无法用map类的算子来替代，那么尽量使用可以map-side预聚合的算子。</p>
<p>所谓的map-side预聚合，说的是在每个节点本地对相同的key进行一次聚合操作，类似于MapReduce中的本地combiner。map-side预聚合之后，每个节点本地就只会有一条相同的key，因为多条相同的key都被聚合起来了。其他节点在拉取所有节点上的相同key时，就会大大减少需要拉取的数据数量，从而也就减少了磁盘IO以及网络传输开销。通常来说，在可能的情况下，建议使用reduceByKey或者aggregateByKey算子来替代掉groupByKey算子。因为reduceByKey和aggregateByKey算子都会使用用户自定义的函数对每个节点本地的相同key进行预聚合。而groupByKey算子是不会进行预聚合的，全量的数据会在集群的各个节点之间分发和传输，性能相对来说比较差。</p>
<p>比如如下两幅图，就是典型的例子，分别基于reduceByKey和groupByKey进行单词计数。其中第一张图是groupByKey的原理图，可以看到，没有进行任何本地聚合时，所有数据都会在集群节点之间传输；第二张图是reduceByKey的原理图，可以看到，每个节点本地的相同key数据，都进行了预聚合，然后才传输到其他节点上进行全局聚合。</p>
<p><img src="/images/20181104_2.png"><br>groupByKey实现wordcount原理</p>
<p><img src="/images/20181104_3.png"><br>reduceByKey实现wordcount原理</p>
<h3 id="原则六：使用高性能的算子"><a href="#原则六：使用高性能的算子" class="headerlink" title="原则六：使用高性能的算子"></a>原则六：使用高性能的算子</h3><p>除了shuffle相关的算子有优化原则之外，其他的算子也都有着相应的优化原则。</p>
<p><strong>使用reduceByKey&#x2F;aggregateByKey替代groupByKey</strong><br>详情见“原则五：使用map-side预聚合的shuffle操作”。</p>
<p><strong>使用mapPartitions替代普通map</strong><br>mapPartitions类的算子，一次函数调用会处理一个partition所有的数据，而不是一次函数调用处理一条，性能相对来说会高一些。但是有的时候，使用mapPartitions会出现OOM（内存溢出）的问题。因为单次函数调用就要处理掉一个partition所有的数据，如果内存不够，垃圾回收时是无法回收掉太多对象的，很可能出现OOM异常。所以使用这类操作时要慎重！</p>
<p><strong>使用foreachPartitions替代foreach</strong><br>原理类似于“使用mapPartitions替代map”，也是一次函数调用处理一个partition的所有数据，而不是一次函数调用处理一条数据。在实践中发现，foreachPartitions类的算子，对性能的提升还是很有帮助的。比如在foreach函数中，将RDD中所有数据写MySQL，那么如果是普通的foreach算子，就会一条数据一条数据地写，每次函数调用可能就会创建一个数据库连接，此时就势必会频繁地创建和销毁数据库连接，性能是非常低下；但是如果用foreachPartitions算子一次性处理一个partition的数据，那么对于每个partition，只要创建一个数据库连接即可，然后执行批量插入操作，此时性能是比较高的。实践中发现，对于1万条左右的数据量写MySQL，性能可以提升30%以上。</p>
<p><strong>使用filter之后进行coalesce操作</strong><br>通常对一个RDD执行filter算子过滤掉RDD中较多数据后（比如30%以上的数据），建议使用coalesce算子，手动减少RDD的partition数量，将RDD中的数据压缩到更少的partition中去。因为filter之后，RDD的每个partition中都会有很多数据被过滤掉，此时如果照常进行后续的计算，其实每个task处理的partition中的数据量并不是很多，有一点资源浪费，而且此时处理的task越多，可能速度反而越慢。因此用coalesce减少partition数量，将RDD中的数据压缩到更少的partition之后，只要使用更少的task即可处理完所有的partition。在某些场景下，对于性能的提升会有一定的帮助。</p>
<p><strong>使用repartitionAndSortWithinPartitions替代repartition与sort类操作</strong><br>repartitionAndSortWithinPartitions是Spark官网推荐的一个算子，官方建议，如果需要在repartition重分区之后，还要进行排序，建议直接使用repartitionAndSortWithinPartitions算子。因为该算子可以一边进行重分区的shuffle操作，一边进行排序。shuffle与sort两个操作同时进行，比先shuffle再sort来说，性能可能是要高的。</p>
<h3 id="原则七：广播大变量"><a href="#原则七：广播大变量" class="headerlink" title="原则七：广播大变量"></a>原则七：广播大变量</h3><p>有时在开发过程中，会遇到需要在算子函数中使用外部变量的场景（尤其是大变量，比如100M以上的大集合），那么此时就应该使用Spark的广播（Broadcast）功能来提升性能。</p>
<p>在算子函数中使用到外部变量时，默认情况下，Spark会将该变量复制多个副本，通过网络传输到task中，此时每个task都有一个变量副本。如果变量本身比较大的话（比如100M，甚至1G），那么大量的变量副本在网络中传输的性能开销，以及在各个节点的Executor中占用过多内存导致的频繁GC，都会极大地影响性能。</p>
<p>因此对于上述情况，如果使用的外部变量比较大，建议使用Spark的广播功能，对该变量进行广播。广播后的变量，会保证每个Executor的内存中，只驻留一份变量副本，而Executor中的task执行时共享该Executor中的那份变量副本。这样的话，可以大大减少变量副本的数量，从而减少网络传输的性能开销，并减少对Executor内存的占用开销，降低GC的频率。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">广播大变量的代码示例</span><br><span class="line"><span class="comment">// 以下代码在算子函数中，使用了外部的变量。</span></span><br><span class="line"><span class="comment">// 此时没有做任何特殊操作，每个task都会有一份list1的副本。</span></span><br><span class="line"><span class="keyword">val</span> list1 = ...</span><br><span class="line">rdd1.map(list1...)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 以下代码将list1封装成了Broadcast类型的广播变量。</span></span><br><span class="line"><span class="comment">// 在算子函数中，使用广播变量时，首先会判断当前task所在Executor内存中，是否有变量副本。</span></span><br><span class="line"><span class="comment">// 如果有则直接使用；如果没有则从Driver或者其他Executor节点上远程拉取一份放到本地Executor内存中。</span></span><br><span class="line"><span class="comment">// 每个Executor内存中，就只会驻留一份广播变量副本。</span></span><br><span class="line"><span class="keyword">val</span> list1 = ...</span><br><span class="line"><span class="keyword">val</span> list1Broadcast = sc.broadcast(list1)</span><br><span class="line">rdd1.map(list1Broadcast...)</span><br></pre></td></tr></table></figure>

<h3 id="原则八：使用Kryo优化序列化性能"><a href="#原则八：使用Kryo优化序列化性能" class="headerlink" title="原则八：使用Kryo优化序列化性能"></a>原则八：使用Kryo优化序列化性能</h3><p>在Spark中，主要有三个地方涉及到了序列化：</p>
<ul>
<li>在算子函数中使用到外部变量时，该变量会被序列化后进行网络传输（见“原则七：广播大变量”中的讲解）。</li>
<li>自定义的类型作为RDD的泛型类型时（比如JavaRDD，Student是自定义类型），所有自定义类型对象，都会进行序列化。因此这种情况下，也要求自定义的类必须实现Serializable接口。</li>
<li>使用可序列化的持久化策略时（比如MEMORY_ONLY_SER），Spark会将RDD中的每个partition都序列化成一个大的字节数组。</li>
</ul>
<p>对于这三种出现序列化的地方，我们都可以通过使用Kryo序列化类库，来优化序列化和反序列化的性能。Spark默认使用的是Java的序列化机制，也就是ObjectOutputStream&#x2F;ObjectInputStream API来进行序列化和反序列化。但是Spark同时支持使用Kryo序列化库，Kryo序列化类库的性能比Java序列化类库的性能要高很多。官方介绍，Kryo序列化机制比Java序列化机制，性能高10倍左右。Spark之所以默认没有使用Kryo作为序列化类库，是因为Kryo要求最好要注册所有需要进行序列化的自定义类型，因此对于开发者来说，这种方式比较麻烦。</p>
<p>以下是使用Kryo的代码示例，我们只要设置序列化类，再注册要序列化的自定义类型即可（比如算子函数中使用到的外部变量类型、作为RDD泛型类型的自定义类型等）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 创建SparkConf对象。</span><br><span class="line">val conf = new SparkConf().setMaster(...).setAppName(...)</span><br><span class="line">// 设置序列化器为KryoSerializer。</span><br><span class="line">conf.set(&quot;spark.serializer&quot;, &quot;org.apache.spark.serializer.KryoSerializer&quot;)</span><br><span class="line">// 注册要序列化的自定义类型。</span><br><span class="line">conf.registerKryoClasses(Array(classOf[MyClass1], classOf[MyClass2]))</span><br></pre></td></tr></table></figure>

<h3 id="原则九：优化数据结构"><a href="#原则九：优化数据结构" class="headerlink" title="原则九：优化数据结构"></a>原则九：优化数据结构</h3><p>Java中，有三种类型比较耗费内存：</p>
<ul>
<li>对象，每个Java对象都有对象头、引用等额外的信息，因此比较占用内存空间。</li>
<li>字符串，每个字符串内部都有一个字符数组以及长度等额外信息。</li>
<li>集合类型，比如HashMap、LinkedList等，因为集合类型内部通常会使用一些内部类来封装集合元素，比如Map.Entry。</li>
</ul>
<p>因此Spark官方建议，在Spark编码实现中，特别是对于算子函数中的代码，尽量不要使用上述三种数据结构，尽量使用字符串替代对象，使用原始类型（比如Int、Long）替代字符串，使用数组替代集合类型，这样尽可能地减少内存占用，从而降低GC频率，提升性能。</p>
<p>但是在笔者的编码实践中发现，要做到该原则其实并不容易。因为我们同时要考虑到代码的可维护性，如果一个代码中，完全没有任何对象抽象，全部是字符串拼接的方式，那么对于后续的代码维护和修改，无疑是一场巨大的灾难。同理，如果所有操作都基于数组实现，而不使用HashMap、LinkedList等集合类型，那么对于我们的编码难度以及代码可维护性，也是一个极大的挑战。因此笔者建议，在可能以及合适的情况下，使用占用内存较少的数据结构，但是前提是要保证代码的可维护性。</p>
<h2 id="资源调优"><a href="#资源调优" class="headerlink" title="资源调优"></a>资源调优</h2><h3 id="调优概述-1"><a href="#调优概述-1" class="headerlink" title="调优概述"></a>调优概述</h3><p>在开发完Spark作业之后，就该为作业配置合适的资源了。Spark的资源参数，基本都可以在spark-submit命令中作为参数设置。很多Spark初学者，通常不知道该设置哪些必要的参数，以及如何设置这些参数，最后就只能胡乱设置，甚至压根儿不设置。资源参数设置的不合理，可能会导致没有充分利用集群资源，作业运行会极其缓慢；或者设置的资源过大，队列没有足够的资源来提供，进而导致各种异常。总之，无论是哪种情况，都会导致Spark作业的运行效率低下，甚至根本无法运行。因此我们必须对Spark作业的资源使用原理有一个清晰的认识，并知道在Spark作业运行过程中，有哪些资源参数是可以设置的，以及如何设置合适的参数值。</p>
<h3 id="Spark作业基本运行原理"><a href="#Spark作业基本运行原理" class="headerlink" title="Spark作业基本运行原理"></a>Spark作业基本运行原理</h3><p><img src="/images/20181104_4.png"></p>
<p>详细原理见上图。我们使用spark-submit提交一个Spark作业之后，这个作业就会启动一个对应的Driver进程。根据你使用的部署模式（deploy-mode）不同，Driver进程可能在本地启动，也可能在集群中某个工作节点上启动。Driver进程本身会根据我们设置的参数，占有一定数量的内存和CPU core。而Driver进程要做的第一件事情，就是向集群管理器（可以是Spark Standalone集群，也可以是其他的资源管理集群，美团•大众点评使用的是YARN作为资源管理集群）申请运行Spark作业需要使用的资源，这里的资源指的就是Executor进程。YARN集群管理器会根据我们为Spark作业设置的资源参数，在各个工作节点上，启动一定数量的Executor进程，每个Executor进程都占有一定数量的内存和CPU core。</p>
<p>在申请到了作业执行所需的资源之后，Driver进程就会开始调度和执行我们编写的作业代码了。Driver进程会将我们编写的Spark作业代码分拆为多个stage，每个stage执行一部分代码片段，并为每个stage创建一批task，然后将这些task分配到各个Executor进程中执行。task是最小的计算单元，负责执行一模一样的计算逻辑（也就是我们自己编写的某个代码片段），只是每个task处理的数据不同而已。一个stage的所有task都执行完毕之后，会在各个节点本地的磁盘文件中写入计算中间结果，然后Driver就会调度运行下一个stage。下一个stage的task的输入数据就是上一个stage输出的中间结果。如此循环往复，直到将我们自己编写的代码逻辑全部执行完，并且计算完所有的数据，得到我们想要的结果为止。</p>
<p>Spark是根据shuffle类算子来进行stage的划分。如果我们的代码中执行了某个shuffle类算子（比如reduceByKey、join等），那么就会在该算子处，划分出一个stage界限来。可以大致理解为，shuffle算子执行之前的代码会被划分为一个stage，shuffle算子执行以及之后的代码会被划分为下一个stage。因此一个stage刚开始执行的时候，它的每个task可能都会从上一个stage的task所在的节点，去通过网络传输拉取需要自己处理的所有key，然后对拉取到的所有相同的key使用我们自己编写的算子函数执行聚合操作（比如reduceByKey()算子接收的函数）。这个过程就是shuffle。</p>
<p>当我们在代码中执行了cache&#x2F;persist等持久化操作时，根据我们选择的持久化级别的不同，每个task计算出来的数据也会保存到Executor进程的内存或者所在节点的磁盘文件中。</p>
<p>因此Executor的内存主要分为三块：第一块是让task执行我们自己编写的代码时使用，默认是占Executor总内存的20%；第二块是让task通过shuffle过程拉取了上一个stage的task的输出后，进行聚合等操作时使用，默认也是占Executor总内存的20%；第三块是让RDD持久化时使用，默认占Executor总内存的60%。</p>
<p>task的执行速度是跟每个Executor进程的CPU core数量有直接关系的。一个CPU core同一时间只能执行一个线程。而每个Executor进程上分配到的多个task，都是以每个task一条线程的方式，多线程并发运行的。如果CPU core数量比较充足，而且分配到的task数量比较合理，那么通常来说，可以比较快速和高效地执行完这些task线程。</p>
<p>以上就是Spark作业的基本运行原理的说明，大家可以结合上图来理解。理解作业基本原理，是我们进行资源参数调优的基本前提。</p>
<h3 id="资源参数调优"><a href="#资源参数调优" class="headerlink" title="资源参数调优"></a>资源参数调优</h3><p>了解完了Spark作业运行的基本原理之后，对资源相关的参数就容易理解了。所谓的Spark资源参数调优，其实主要就是对Spark运行过程中各个使用资源的地方，通过调节各种参数，来优化资源使用的效率，从而提升Spark作业的执行性能。以下参数就是Spark中主要的资源参数，每个参数都对应着作业运行原理中的某个部分，我们同时也给出了一个调优的参考值。</p>
<h4 id="num-executors"><a href="#num-executors" class="headerlink" title="num-executors"></a>num-executors</h4><ul>
<li>参数说明：该参数用于设置Spark作业总共要用多少个Executor进程来执行。Driver在向YARN集群管理器申请资源时，YARN集群管理器会尽可能按照你的设置来在集群的各个工作节点上，启动相应数量的Executor进程。这个参数非常之重要，如果不设置的话，默认只会给你启动少量的Executor进程，此时你的Spark作业的运行速度是非常慢的。</li>
<li>参数调优建议：每个Spark作业的运行一般设置50~100个左右的Executor进程比较合适，设置太少或太多的Executor进程都不好。设置的太少，无法充分利用集群资源；设置的太多的话，大部分队列可能无法给予充分的资源。</li>
</ul>
<h4 id="executor-memory"><a href="#executor-memory" class="headerlink" title="executor-memory"></a>executor-memory</h4><ul>
<li>参数说明：该参数用于设置每个Executor进程的内存。Executor内存的大小，很多时候直接决定了Spark作业的性能，而且跟常见的JVM OOM异常，也有直接的关联。</li>
<li>参数调优建议：每个Executor进程的内存设置4G<del>8G较为合适。但是这只是一个参考值，具体的设置还是得根据不同部门的资源队列来定。可以看看自己团队的资源队列的最大内存限制是多少，num-executors乘以executor-memory，是不能超过队列的最大内存量的。此外，如果你是跟团队里其他人共享这个资源队列，那么申请的内存量最好不要超过资源队列最大总内存的1&#x2F;3</del>1&#x2F;2，避免你自己的Spark作业占用了队列所有的资源，导致别的同学的作业无法运行。</li>
</ul>
<h4 id="executor-cores"><a href="#executor-cores" class="headerlink" title="executor-cores"></a>executor-cores</h4><ul>
<li>参数说明：该参数用于设置每个Executor进程的CPU core数量。这个参数决定了每个Executor进程并行执行task线程的能力。因为每个CPU core同一时间只能执行一个task线程，因此每个Executor进程的CPU core数量越多，越能够快速地执行完分配给自己的所有task线程。</li>
<li>参数调优建议：Executor的CPU core数量设置为2<del>4个较为合适。同样得根据不同部门的资源队列来定，可以看看自己的资源队列的最大CPU core限制是多少，再依据设置的Executor数量，来决定每个Executor进程可以分配到几个CPU core。同样建议，如果是跟他人共享这个队列，那么num-executors * executor-cores不要超过队列总CPU core的1&#x2F;3</del>1&#x2F;2左右比较合适，也是避免影响其他同学的作业运行。</li>
</ul>
<h4 id="driver-memory"><a href="#driver-memory" class="headerlink" title="driver-memory"></a>driver-memory</h4><ul>
<li>参数说明：该参数用于设置Driver进程的内存。</li>
<li>参数调优建议：Driver的内存通常来说不设置，或者设置1G左右应该就够了。唯一需要注意的一点是，如果需要使用collect算子将RDD的数据全部拉取到Driver上进行处理，那么必须确保Driver的内存足够大，否则会出现OOM内存溢出的问题。</li>
</ul>
<h4 id="spark-default-parallelism"><a href="#spark-default-parallelism" class="headerlink" title="spark.default.parallelism"></a>spark.default.parallelism</h4><ul>
<li>参数说明：该参数用于设置每个stage的默认task数量。这个参数极为重要，如果不设置可能会直接影响你的Spark作业性能。</li>
<li>参数调优建议：Spark作业的默认task数量为500<del>1000个较为合适。很多同学常犯的一个错误就是不去设置这个参数，那么此时就会导致Spark自己根据底层HDFS的block数量来设置task的数量，默认是一个HDFS block对应一个task。通常来说，Spark默认设置的数量是偏少的（比如就几十个task），如果task数量偏少的话，就会导致你前面设置好的Executor的参数都前功尽弃。试想一下，无论你的Executor进程有多少个，内存和CPU有多大，但是task只有1个或者10个，那么90%的Executor进程可能根本就没有task执行，也就是白白浪费了资源！因此Spark官网建议的设置原则是，设置该参数为num-executors * executor-cores的2</del>3倍较为合适，比如Executor的总CPU core数量为300个，那么设置1000个task是可以的，此时可以充分地利用Spark集群的资源。</li>
</ul>
<h4 id="spark-storage-memoryFraction"><a href="#spark-storage-memoryFraction" class="headerlink" title="spark.storage.memoryFraction"></a>spark.storage.memoryFraction</h4><ul>
<li>参数说明：该参数用于设置RDD持久化数据在Executor内存中能占的比例，默认是0.6。也就是说，默认Executor 60%的内存，可以用来保存持久化的RDD数据。根据你选择的不同的持久化策略，如果内存不够时，可能数据就不会持久化，或者数据会写入磁盘。</li>
<li>参数调优建议：如果Spark作业中，有较多的RDD持久化操作，该参数的值可以适当提高一些，保证持久化的数据能够容纳在内存中。避免内存不够缓存所有的数据，导致数据只能写入磁盘中，降低了性能。但是如果Spark作业中的shuffle类操作比较多，而持久化操作比较少，那么这个参数的值适当降低一些比较合适。此外，如果发现作业由于频繁的gc导致运行缓慢（通过spark web ui可以观察到作业的gc耗时），意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。</li>
</ul>
<h4 id="spark-shuffle-memoryFraction"><a href="#spark-shuffle-memoryFraction" class="headerlink" title="spark.shuffle.memoryFraction"></a>spark.shuffle.memoryFraction</h4><ul>
<li>参数说明：该参数用于设置shuffle过程中一个task拉取到上个stage的task的输出后，进行聚合操作时能够使用的Executor内存的比例，默认是0.2。也就是说，Executor默认只有20%的内存用来进行该操作。shuffle操作在进行聚合时，如果发现使用的内存超出了这个20%的限制，那么多余的数据就会溢写到磁盘文件中去，此时就会极大地降低性能。</li>
<li>参数调优建议：如果Spark作业中的RDD持久化操作较少，shuffle操作较多时，建议降低持久化操作的内存占比，提高shuffle操作的内存占比比例，避免shuffle过程中数据过多时内存不够用，必须溢写到磁盘上，降低了性能。此外，如果发现作业由于频繁的gc导致运行缓慢，意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。</li>
</ul>
<p>资源参数的调优，没有一个固定的值，需要同学们根据自己的实际情况（包括Spark作业中的shuffle操作数量、RDD持久化操作数量以及spark web ui中显示的作业gc情况），同时参考本篇文章中给出的原理以及调优建议，合理地设置上述参数。</p>
<h3 id="资源参数参考示例"><a href="#资源参数参考示例" class="headerlink" title="资源参数参考示例"></a>资源参数参考示例</h3><p>以下是一份spark-submit命令的示例，大家可以参考一下，并根据自己的实际情况进行调节：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-submit \</span><br><span class="line">  --master yarn-cluster \</span><br><span class="line">  --num-executors 100 \</span><br><span class="line">  --executor-memory 6G \</span><br><span class="line">  --executor-cores 4 \</span><br><span class="line">  --driver-memory 1G \</span><br><span class="line">  --conf spark.default.parallelism=1000 \</span><br><span class="line">  --conf spark.storage.memoryFraction=0.5 \</span><br><span class="line">  --conf spark.shuffle.memoryFraction=0.3 \</span><br></pre></td></tr></table></figure>

<h2 id="写在最后的话"><a href="#写在最后的话" class="headerlink" title="写在最后的话"></a>写在最后的话</h2><p>根据实践经验来看，大部分Spark作业经过本次基础篇所讲解的开发调优与资源调优之后，一般都能以较高的性能运行了，足以满足我们的需求。但是在不同的生产环境和项目背景下，可能会遇到其他更加棘手的问题（比如各种数据倾斜），也可能会遇到更高的性能要求。为了应对这些挑战，需要使用更高级的技巧来处理这类问题。在后续的《Spark性能优化指南——高级篇》中，我们会详细讲解数据倾斜调优以及Shuffle调优。</p>
</div><div class="tags"><a href="/tags/spark/">spark</a></div><script type="text/javascript" src="/js/jquery.js?v=2.0.1" async></script><div class="post-donate"><div id="donate_board" class="donate_bar center"><a id="btn_donate" href="javascript:;" title="打赏" class="btn_donate"></a><div class="donate_txt"> &uarr;<br>谢谢~ 您的支持将鼓励我继续创作！<br></div></div><div id="donate_guide" class="donate_bar center hidden pay"><img src="/img/weChatMoney.png" title="微信打赏" alt="微信打赏"><img src="/img/alipayMoney.png" title="支付宝打赏" alt="支付宝打赏"></div><script type="text/javascript">document.getElementById('btn_donate').onclick = function(){
    $('#donate_board').addClass('hidden');
    $('#donate_guide').removeClass('hidden');
}</script></div><div class="post-share"><div class="bdsharebuttonbox"><span style="float:left;line-height: 28px;height: 28px;font-size:16px;font-weight:blod">分享到：</span><a href="#" data-cmd="more" class="bds_more"></a><a href="#" data-cmd="mshare" title="分享到一键分享" class="bds_mshare"></a><a href="#" data-cmd="fbook" title="分享到Facebook" class="bds_fbook"></a><a href="#" data-cmd="twi" title="分享到Twitter" class="bds_twi"></a><a href="#" data-cmd="linkedin" title="分享到linkedin" class="bds_linkedin"></a><a href="#" data-cmd="youdao" title="分享到有道云笔记" class="bds_youdao"></a><a href="#" data-cmd="evernotecn" title="分享到印象笔记" class="bds_evernotecn"></a><a href="#" data-cmd="weixin" title="分享到微信" class="bds_weixin"></a><a href="#" data-cmd="qzone" title="分享到QQ空间" class="bds_qzone"></a><a href="#" data-cmd="tsina" title="分享到新浪微博" class="bds_tsina"></a></div></div><div class="post-nav"><a href="/2018/11/06/Hive基础教程/" class="pre">Hive基础教程</a><a href="/2018/10/31/朴素贝叶斯与拉普拉斯平滑简介/" class="next">朴素贝叶斯与拉普拉斯平滑简介</a></div><div id="comments"><div id="lv-container" data-id="city" data-uid="MTAyMC80MTIyOC8xNzc3Ng=="></div></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">文章目录</i></div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#开发调优"><span class="toc-text">开发调优</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#调优概述"><span class="toc-text">调优概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#原则一：避免创建重复的RDD"><span class="toc-text">原则一：避免创建重复的RDD</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#原则二：尽可能复用同一个RDD"><span class="toc-text">原则二：尽可能复用同一个RDD</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#原则三：对多次使用的RDD进行持久化"><span class="toc-text">原则三：对多次使用的RDD进行持久化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Spark的持久化级别"><span class="toc-text">Spark的持久化级别</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#如何选择一种最合适的持久化策略"><span class="toc-text">如何选择一种最合适的持久化策略</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#原则四：尽量避免使用shuffle类算子"><span class="toc-text">原则四：尽量避免使用shuffle类算子</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#原则五：使用map-side预聚合的shuffle操作"><span class="toc-text">原则五：使用map-side预聚合的shuffle操作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#原则六：使用高性能的算子"><span class="toc-text">原则六：使用高性能的算子</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#原则七：广播大变量"><span class="toc-text">原则七：广播大变量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#原则八：使用Kryo优化序列化性能"><span class="toc-text">原则八：使用Kryo优化序列化性能</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#原则九：优化数据结构"><span class="toc-text">原则九：优化数据结构</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#资源调优"><span class="toc-text">资源调优</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#调优概述-1"><span class="toc-text">调优概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark作业基本运行原理"><span class="toc-text">Spark作业基本运行原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#资源参数调优"><span class="toc-text">资源参数调优</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#num-executors"><span class="toc-text">num-executors</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#executor-memory"><span class="toc-text">executor-memory</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#executor-cores"><span class="toc-text">executor-cores</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#driver-memory"><span class="toc-text">driver-memory</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#spark-default-parallelism"><span class="toc-text">spark.default.parallelism</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#spark-storage-memoryFraction"><span class="toc-text">spark.storage.memoryFraction</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#spark-shuffle-memoryFraction"><span class="toc-text">spark.shuffle.memoryFraction</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#资源参数参考示例"><span class="toc-text">资源参数参考示例</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#写在最后的话"><span class="toc-text">写在最后的话</span></a></li></ol></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2023/03/29/《Contrastive-Learning-for-Cold-Start-Recommendation》阅读笔记/">《ACM MM2021 Contrastive Learning for Cold-Start Recommendation》阅读笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/09/07/《KDD2018-Perceive-Your-Users-in-Depth-Learning-Universal-User-Representations-from-Multiple-E-commerce-Tasks》阅读笔记/">《KDD2018 Perceive Your Users in Depth Learning Universal User Representations from Multiple E-commerce Tasks》阅读笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/08/10/《Parameter-Efficient-Transfer-from-Sequential-Behaviors-for-User-Modeling-and-Recommendation》论文阅读/">《Parameter-Efficient Transfer from Sequential Behaviors for User Modeling and Recommendation》论文阅读</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/07/03/《Towards-Universal-Sequence-Representation-Learning-for-Recommender-Systems》论文阅读笔记/">《Towards Universal Sequence Representation Learning for Recommender Systems》论文阅读笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/01/07/NLP相关资料整理/">NLP相关资料整理</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/01/05/hexo博客链接在微信被屏蔽的解决办法/">hexo博客链接在微信被屏蔽的解决办法</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/01/05/TensorFlow的自动求导具体是在哪部分代码里实现的？/">TensorFlow的自动求导具体是在哪部分代码里实现的？</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/01/05/tf中如何修改tensor的值/">tf中如何修改tensor的值</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/01/04/解决tf1-15中tf-scatter-update-函数没有定义梯度的问题/">解决tf1.15中tf.scatter_update()函数没有定义梯度的问题</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/12/31/解决hexo博客代码在IOS下字体过大的问题/">解决hexo博客代码在IOS下字体过大的问题</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-gui"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Algorithm/">Algorithm</a><span class="category-list-count">22</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/DMMLAI/">DMMLAI</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo主题/">Hexo主题</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hive/">Hive</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/PL/">PL</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Story/">Story</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/hole/">hole</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/linux/">linux</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/mac/">mac</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/pytorch/">pytorch</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/sklearn/">sklearn</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/tensorflow/">tensorflow</a><span class="category-list-count">10</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/例行化/">例行化</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/大数据/">大数据</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/开发/">开发</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/开发工具/">开发工具</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/推荐/">推荐</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/摄影/">摄影</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据获取/">数据获取</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/深度学习/">深度学习</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/游记/">游记</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/爬虫/">爬虫</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/统计学/">统计学</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/计划/">计划</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/计算广告/">计算广告</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/高并发/">高并发</a><span class="category-list-count">1</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> 标签</i></div><div class="tagcloud"><a href="/tags/思考/" style="font-size: 15px;">思考</a> <a href="/tags/cold/" style="font-size: 15px;">cold</a> <a href="/tags/gwen/" style="font-size: 15px;">gwen</a> <a href="/tags/C-C/" style="font-size: 15px;">C/C++</a> <a href="/tags/FTRL/" style="font-size: 15px;">FTRL</a> <a href="/tags/hive/" style="font-size: 15px;">hive</a> <a href="/tags/Java编程思想/" style="font-size: 15px;">Java编程思想</a> <a href="/tags/kmp/" style="font-size: 15px;">kmp</a> <a href="/tags/字符串匹配/" style="font-size: 15px;">字符串匹配</a> <a href="/tags/L2范数，范数/" style="font-size: 15px;">L2范数，范数</a> <a href="/tags/linux性能管理/" style="font-size: 15px;">linux性能管理</a> <a href="/tags/NLP/" style="font-size: 15px;">NLP</a> <a href="/tags/tensorflow/" style="font-size: 15px;">tensorflow</a> <a href="/tags/自动求导，自动微分/" style="font-size: 15px;">自动求导，自动微分</a> <a href="/tags/sublime/" style="font-size: 15px;">sublime</a> <a href="/tags/TFRecord/" style="font-size: 15px;">TFRecord</a> <a href="/tags/FM/" style="font-size: 15px;">FM</a> <a href="/tags/指标/" style="font-size: 15px;">指标</a> <a href="/tags/auc/" style="font-size: 15px;">auc</a> <a href="/tags/zookepper/" style="font-size: 15px;">zookepper</a> <a href="/tags/centos7/" style="font-size: 15px;">centos7</a> <a href="/tags/cpm/" style="font-size: 15px;">cpm</a> <a href="/tags/opcm/" style="font-size: 15px;">opcm</a> <a href="/tags/ecpm/" style="font-size: 15px;">ecpm</a> <a href="/tags/hexo，微信屏蔽/" style="font-size: 15px;">hexo，微信屏蔽</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/tf/" style="font-size: 15px;">tf</a> <a href="/tags/正则表达式/" style="font-size: 15px;">正则表达式</a> <a href="/tags/leetcode/" style="font-size: 15px;">leetcode</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/重装系统/" style="font-size: 15px;">重装系统</a> <a href="/tags/maven/" style="font-size: 15px;">maven</a> <a href="/tags/OJ/" style="font-size: 15px;">OJ</a> <a href="/tags/dfs/" style="font-size: 15px;">dfs</a> <a href="/tags/递归/" style="font-size: 15px;">递归</a> <a href="/tags/poj/" style="font-size: 15px;">poj</a> <a href="/tags/回文字符串/" style="font-size: 15px;">回文字符串</a> <a href="/tags/dp/" style="font-size: 15px;">dp</a> <a href="/tags/暴力/" style="font-size: 15px;">暴力</a> <a href="/tags/棋盘规则/" style="font-size: 15px;">棋盘规则</a> <a href="/tags/状态压缩/" style="font-size: 15px;">状态压缩</a> <a href="/tags/BFS/" style="font-size: 15px;">BFS</a> <a href="/tags/位运算/" style="font-size: 15px;">位运算</a> <a href="/tags/pytorch/" style="font-size: 15px;">pytorch</a> <a href="/tags/module/" style="font-size: 15px;">module</a> <a href="/tags/爬虫/" style="font-size: 15px;">爬虫</a> <a href="/tags/shell/" style="font-size: 15px;">shell</a> <a href="/tags/质数/" style="font-size: 15px;">质数</a> <a href="/tags/素数/" style="font-size: 15px;">素数</a> <a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/sklearn/" style="font-size: 15px;">sklearn</a> <a href="/tags/hole/" style="font-size: 15px;">hole</a> <a href="/tags/spark/" style="font-size: 15px;">spark</a> <a href="/tags/打散/" style="font-size: 15px;">打散</a> <a href="/tags/roc-auc-score/" style="font-size: 15px;">roc_auc_score</a> <a href="/tags/svm多类别分类/" style="font-size: 15px;">svm多类别分类</a> <a href="/tags/网格搜索/" style="font-size: 15px;">网格搜索</a> <a href="/tags/textFile/" style="font-size: 15px;">textFile</a> <a href="/tags/源码剖析/" style="font-size: 15px;">源码剖析</a> <a href="/tags/rdd计算/" style="font-size: 15px;">rdd计算</a> <a href="/tags/smoothing/" style="font-size: 15px;">smoothing</a> <a href="/tags/tensorboard/" style="font-size: 15px;">tensorboard</a> <a href="/tags/test-in-ubuntu/" style="font-size: 15px;">test in ubuntu</a> <a href="/tags/tf-nn/" style="font-size: 15px;">tf.nn</a> <a href="/tags/tensor/" style="font-size: 15px;">tensor</a> <a href="/tags/gather/" style="font-size: 15px;">gather</a> <a href="/tags/cnn/" style="font-size: 15px;">cnn</a> <a href="/tags/transformer/" style="font-size: 15px;">transformer</a> <a href="/tags/nlp/" style="font-size: 15px;">nlp</a> <a href="/tags/trie/" style="font-size: 15px;">trie</a> <a href="/tags/推荐，对比学习，冷启动/" style="font-size: 15px;">推荐，对比学习，冷启动</a> <a href="/tags/word2vec/" style="font-size: 15px;">word2vec</a> <a href="/tags/torch/" style="font-size: 15px;">torch</a> <a href="/tags/torch-geometric/" style="font-size: 15px;">torch-geometric</a> <a href="/tags/多任务学习/" style="font-size: 15px;">多任务学习</a> <a href="/tags/图网络/" style="font-size: 15px;">图网络</a> <a href="/tags/矩阵补全/" style="font-size: 15px;">矩阵补全</a> <a href="/tags/推荐/" style="font-size: 15px;">推荐</a> <a href="/tags/NAS/" style="font-size: 15px;">NAS</a> <a href="/tags/网络修剪/" style="font-size: 15px;">网络修剪</a> <a href="/tags/知识迁移/" style="font-size: 15px;">知识迁移</a> <a href="/tags/神经架构搜索/" style="font-size: 15px;">神经架构搜索</a> <a href="/tags/async/" style="font-size: 15px;">async</a> <a href="/tags/异步/" style="font-size: 15px;">异步</a> <a href="/tags/多进程/" style="font-size: 15px;">多进程</a> <a href="/tags/流数据/" style="font-size: 15px;">流数据</a> <a href="/tags/概念漂移/" style="font-size: 15px;">概念漂移</a> <a href="/tags/二分搜索/" style="font-size: 15px;">二分搜索</a> <a href="/tags/univesal-embedding/" style="font-size: 15px;">univesal embedding</a> <a href="/tags/机器学习工具/" style="font-size: 15px;">机器学习工具</a> <a href="/tags/universal-embedding/" style="font-size: 15px;">universal embedding</a> <a href="/tags/迁移学习/" style="font-size: 15px;">迁移学习</a> <a href="/tags/逻辑/" style="font-size: 15px;">逻辑</a> <a href="/tags/github-blog/" style="font-size: 15px;">github blog</a> <a href="/tags/例行化/" style="font-size: 15px;">例行化</a> <a href="/tags/协同过滤/" style="font-size: 15px;">协同过滤</a> <a href="/tags/GCN/" style="font-size: 15px;">GCN</a> <a href="/tags/图卷积/" style="font-size: 15px;">图卷积</a> <a href="/tags/github/" style="font-size: 15px;">github</a> <a href="/tags/在线学习/" style="font-size: 15px;">在线学习</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> 归档</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/03/">三月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/09/">九月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/08/">八月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/07/">七月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/01/">一月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/12/">十二月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">十一月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/10/">十月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/09/">九月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/08/">八月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/02/">二月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/12/">十二月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/11/">十一月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/10/">十月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">九月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">七月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">六月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">四月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">三月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">二月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">十一月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">十月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">八月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">七月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">五月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">十二月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">十一月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">十月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">七月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">四月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">十一月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">八月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">四月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">十二月 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">十一月 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">十月 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/05/">五月 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/04/">四月 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/12/">十二月 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/11/">十一月 2014</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-you"> 友情链接</i></div><ul></ul><a href="https://petr-mitrichev.blogspot.com/" title="petr" target="_blank">petr</a><ul></ul><a href="http://blog.pluskid.org/" title="Free Mind" target="_blank">Free Mind</a><ul></ul><a href="http://www.flickering.cn/" title="火光摇曳" target="_blank">火光摇曳</a><ul></ul><a href="https://recsys.acm.org/" title="recsys" target="_blank">recsys</a><ul></ul><a href="https://sites.google.com/site/xreborner/" title="Xreborner" target="_blank">Xreborner</a><ul></ul><a href="http://blog.watashi.ws/" title="watashi" target="_blank">watashi</a><ul></ul><a href="https://toc.csail.mit.edu/user/306" title="WJMZBMR" target="_blank">WJMZBMR</a><ul></ul><a href="http://dongxicheng.org/" title="dongxicheng" target="_blank">dongxicheng</a><ul></ul><a href="https://www.byvoid.com/zht/" title="byvoid" target="_blank">byvoid</a></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p><a href="/baidusitemap.xml">Baidu Site Haritası</a> |  <a href="/atom.xml">订阅</a> |  <a href="/about/">关于</a></p><p><span> Copyright &copy;<a href="/." rel="nofollow">TiuVe.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/chaooo/hexo-theme-BlueLake"> BlueLake.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script type="text/javascript" src="/js/search.json.js?v=2.0.1"></script><!-- 页面点击小红心，在末尾添加，避免找不到 -->
<script type="text/javascript" src="/js/love.js"></script>
<!-- 背景彩带, true打开，false关闭 --><script type="text/javascript" src="/js/toctotop.js?v=2.0.1" async></script><script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":["mshare","weixin","tsina","qzone","linkedin","fbook","twi","print","renren","sqq","evernotecn","bdysc","tqq","tqf","bdxc","kaixin001","tieba","douban","bdhome","thx","ibaidu","meilishuo","mogujie","diandian","huaban","duitang","hx","fx","youdao","sdo","qingbiji","people","xinhua","mail","isohu","yaolan","wealink","ty","iguba","h163","copy"],"bdPic":"","bdStyle":"1","bdSize":"16"},"share":{},"image":{"viewList":["tsina","qzone","weixin","fbook","twi","linkedin","youdao","evernotecn","mshare"],"viewText":"分享到：","viewSize":"16"},"selectShare":{"bdContainerClass":null,"bdSelectMiniList":["tsina","qzone","weixin","fbook","twi","linkedin","youdao","evernotecn","mshare"]}};with(document)0[(getElementsByTagName('head')[0]||head).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
</script><script>(function(d, s) {
  var j, e = d.getElementsByTagName('body')[0];
  if (typeof LivereTower === 'function') { return; }
  j = d.createElement(s);
  j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
  j.async = true;
  e.appendChild(j);
})(document, 'script');
</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/Epsilon2.1.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>